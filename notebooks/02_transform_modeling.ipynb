{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Montaje de drive y carga de requerimientos\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# !pip install -r '/content/drive/MyDrive/tfm_data_scientist/requirements_colab.txt' -q\n",
    "\n",
    "# # Insert the directory\n",
    "# import sys\n",
    "# sys.path.insert(0,'/content/drive/MyDrive/tfm_data_scientist/notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01. Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import warnings\n",
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import boxplot_stats\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datasist.structdata import detect_outliers\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer, IterativeImputer, SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MultiLabelBinarizer , LabelEncoder , OrdinalEncoder\n",
    "from sklearn.metrics import roc_auc_score, confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# cargamos los modelos\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from common.utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "WARNING:tensorflow:From C:\\Users\\jarl1\\AppData\\Local\\Temp\\ipykernel_5972\\4175302263.py:4: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__, tf.__version__\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "tf.test.is_gpu_available(cuda_only=False, min_cuda_compute_capability=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = os.path.join(os.path.dirname(os.getcwd()), 'data/input/')\n",
    "path_output = os.path.join(os.path.dirname(os.getcwd()), 'data/output/')\n",
    "path_model = os.path.join(os.path.dirname(os.getcwd()), 'data/model/')\n",
    "\n",
    "# # colab path\n",
    "# path_input = '/content/drive/MyDrive/tfm_data_scientist/data/input/'\n",
    "# path_output = '/content/drive/MyDrive/tfm_data_scientist/data/output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [path_input, path_output, path_model]\n",
    "for path in paths:\n",
    "    os.makedirs(path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(path_output + 'fixes_train.csv' , low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03. Tratamiento y transformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Age                       100000 non-null  float64\n",
      " 1   Occupation                100000 non-null  object \n",
      " 2   Annual_Income             100000 non-null  float64\n",
      " 3   Monthly_Inhand_Salary     84998 non-null   float64\n",
      " 4   Num_Bank_Accounts         100000 non-null  float64\n",
      " 5   Num_Credit_Card           100000 non-null  float64\n",
      " 6   Interest_Rate             100000 non-null  float64\n",
      " 7   Num_of_Loan               100000 non-null  float64\n",
      " 8   Type_of_Loan              100000 non-null  object \n",
      " 9   Delay_from_due_date       100000 non-null  float64\n",
      " 10  Num_of_Delayed_Payment    92998 non-null   float64\n",
      " 11  Changed_Credit_Limit      97909 non-null   float64\n",
      " 12  Num_Credit_Inquiries      98035 non-null   float64\n",
      " 13  Credit_Mix                79805 non-null   object \n",
      " 14  Outstanding_Debt          100000 non-null  float64\n",
      " 15  Credit_Utilization_Ratio  100000 non-null  float64\n",
      " 16  Credit_History_Age        90970 non-null   float64\n",
      " 17  Payment_of_Min_Amount     100000 non-null  object \n",
      " 18  Total_EMI_per_month       100000 non-null  float64\n",
      " 19  Amount_invested_monthly   91216 non-null   float64\n",
      " 20  Payment_Behaviour         92400 non-null   object \n",
      " 21  Monthly_Balance           98791 non-null   float64\n",
      " 22  Credit_Score              100000 non-null  object \n",
      "dtypes: float64(17), object(6)\n",
      "memory usage: 17.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03.01. Codificación de variables categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 6 columns):\n",
      " #   Column                 Non-Null Count   Dtype \n",
      "---  ------                 --------------   ----- \n",
      " 0   Occupation             100000 non-null  object\n",
      " 1   Type_of_Loan           100000 non-null  object\n",
      " 2   Credit_Mix             79805 non-null   object\n",
      " 3   Payment_of_Min_Amount  100000 non-null  object\n",
      " 4   Payment_Behaviour      92400 non-null   object\n",
      " 5   Credit_Score           100000 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 4.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.select_dtypes(include=['object']).info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.01.01. MultiLabelBinarizer Encoder: Type_of_Loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.Type_of_Loan = data_train.Type_of_Loan.str.split(',').apply(lambda x: [j.strip() for j in x])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train.join(pd.DataFrame(mlb.fit_transform(data_train.pop('Type_of_Loan')),\n",
    "                                                            index=data_train.index,\n",
    "                                                            columns=mlb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuenta la cantidad de tipos de creditos, variable adicional (potencial multicolinealidad)\n",
    "data_train['Distinct_Type_Loan'] = data_train.iloc[:, 22:].sum(axis=1, numeric_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # se utiliza para eliminar las columnas generadas por el MultiLabelBinarazer\n",
    "# drop_cols = data_train.iloc[:, 22:-1].columns\n",
    "# data_train.drop(drop_cols, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comprobación: se usa para comparar entre la lista y la codificación multinivel\n",
    "# DataTypeLoan = data_train.Type_of_Loan.apply(len)\n",
    "# data_train.iloc[DataTypeLoan.compare(data_train.iloc[:, 22:].sum(axis=1, numeric_only=True)).index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.01.02. Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbl = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['Occupation', 'Payment_of_Min_Amount']\n",
    "for col in label_cols:\n",
    "    data_train[col] = lbl.fit_transform(data_train[col])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03.01.03. Ordinal Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listado organizado de codificación\n",
    "payment_order = ['low_spent_small_value_payments',\n",
    "                 'low_spent_medium_value_payments',\n",
    "                 'low_spent_large_value_payments',\n",
    "                 'high_spent_small_value_payments',\n",
    "                 'high_spent_medium_value_payments',\n",
    "                 'high_spent_large_value_payments',\n",
    "                 np.nan]\n",
    "credit_mix_order = ['good', 'standard', 'poor', np.nan]\n",
    "credit_score_order = ['good', 'standard', 'poor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en el listado credit score va de último dado que se utiliza el \n",
    "# modelo 'ordinal' para revertir la codificación\n",
    "ordinal_cols = ['Credit_Mix', 'Payment_Behaviour', 'Credit_Score']\n",
    "cat_list = [credit_mix_order, payment_order, credit_score_order]\n",
    "\n",
    "for cat, col in zip(cat_list, ordinal_cols):\n",
    "    ordinal = OrdinalEncoder(categories=[cat])\n",
    "    data_train[col] = ordinal.fit_transform(data_train[[col]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # codificación variable objetivo\n",
    "# ordinal_cols = ['Credit_Score', 'Credit_Mix', 'Payment_Behaviour']\n",
    "\n",
    "# ordinal = OrdinalEncoder()\n",
    "# data_train[ordinal_cols] = ordinal.fit_transform(data_train[ordinal_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Valores atipicos (outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de outliers detectados 27014\n"
     ]
    }
   ],
   "source": [
    "# detección de outliers\n",
    "outlieres_identificados = detect_outliers(data_train, 0, data_train.columns)\n",
    "print(f'Número de outliers detectados {len(outlieres_identificados)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 se eliminan los duplicados\n",
    "data_train.drop(outlieres_identificados, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 02 técnica de winsorización / función dada en mineria de datos\n",
    "# data_train = data_train.apply(lambda x: gestion_outliers(x, clase='winsor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 03 se reemplazan por la mediana\n",
    "# for col in data_train.columns :\n",
    "#     outlieres_index = detect_outliers(data_train, 0 , [col])\n",
    "#     col_median = data_train[col].median()\n",
    "#     data_train.loc[outlieres_index, col] = col_median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. Valores perdidos (missings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 imputación KNN vecinos más cercanos\n",
    "imputer = KNNImputer(n_neighbors=8)\n",
    "Dataset = imputer.fit_transform(data_train.drop('Credit_Score', axis=1))\n",
    "Dataset = pd.DataFrame(Dataset, columns=data_train.drop('Credit_Score', axis=1).columns, index=data_train.drop('Credit_Score', axis=1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 02 imputación simple por la mediana\n",
    "# median = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "# Dataset = median.fit_transform(data_train.drop('Credit_Score', axis=1))\n",
    "# Dataset = pd.DataFrame(Dataset, columns=data_train.drop('Credit_Score', axis=1).columns, index=data_train.drop('Credit_Score', axis=1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 03 imputación multivariante iterativa\n",
    "# iterative = IterativeImputer(max_iter=100, initial_strategy='median', random_state=42)\n",
    "# Dataset = iterative.fit_transform(data_train.drop('Credit_Score', axis=1))\n",
    "# Dataset = pd.DataFrame(Dataset, columns=data_train.drop('Credit_Score', axis=1).columns, index=data_train.drop('Credit_Score', axis=1).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>Annual_Income</th>\n",
       "      <th>Monthly_Inhand_Salary</th>\n",
       "      <th>Num_Bank_Accounts</th>\n",
       "      <th>Num_Credit_Card</th>\n",
       "      <th>Interest_Rate</th>\n",
       "      <th>Num_of_Loan</th>\n",
       "      <th>Delay_from_due_date</th>\n",
       "      <th>Num_of_Delayed_Payment</th>\n",
       "      <th>...</th>\n",
       "      <th>auto loan</th>\n",
       "      <th>credit-builder loan</th>\n",
       "      <th>debt consolidation loan</th>\n",
       "      <th>home equity loan</th>\n",
       "      <th>mortgage loan</th>\n",
       "      <th>not specified</th>\n",
       "      <th>payday loan</th>\n",
       "      <th>personal loan</th>\n",
       "      <th>student loan</th>\n",
       "      <th>Distinct_Type_Loan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43691</th>\n",
       "      <td>54.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>117851.07</td>\n",
       "      <td>9870.922500</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68941</th>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40167.84</td>\n",
       "      <td>3552.730521</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22325</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>118875.69</td>\n",
       "      <td>9964.451458</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52580</th>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27395.53</td>\n",
       "      <td>2414.960833</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84265</th>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>62152.59</td>\n",
       "      <td>5188.382500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age  Occupation  Annual_Income  Monthly_Inhand_Salary  \\\n",
       "43691  54.0         4.0      117851.07            9870.922500   \n",
       "68941  21.0         1.0       40167.84            3552.730521   \n",
       "22325  21.0         0.0      118875.69            9964.451458   \n",
       "52580  28.0         1.0       27395.53            2414.960833   \n",
       "84265  19.0         8.0       62152.59            5188.382500   \n",
       "\n",
       "       Num_Bank_Accounts  Num_Credit_Card  Interest_Rate  Num_of_Loan  \\\n",
       "43691               -1.0              6.0            7.0          0.0   \n",
       "68941                7.0              5.0            5.0          1.0   \n",
       "22325                0.0              4.0           12.0          2.0   \n",
       "52580                5.0              3.0            5.0          4.0   \n",
       "84265                8.0              4.0           12.0          2.0   \n",
       "\n",
       "       Delay_from_due_date  Num_of_Delayed_Payment  ...  auto loan  \\\n",
       "43691                 27.0                     1.0  ...        0.0   \n",
       "68941                  5.0                    18.0  ...        0.0   \n",
       "22325                 10.0                     5.0  ...        1.0   \n",
       "52580                 15.0                    11.0  ...        0.0   \n",
       "84265                 14.0                    18.0  ...        0.0   \n",
       "\n",
       "       credit-builder loan  debt consolidation loan  home equity loan  \\\n",
       "43691                  0.0                      0.0               0.0   \n",
       "68941                  0.0                      1.0               0.0   \n",
       "22325                  0.0                      0.0               0.0   \n",
       "52580                  1.0                      0.0               0.0   \n",
       "84265                  1.0                      0.0               0.0   \n",
       "\n",
       "       mortgage loan  not specified  payday loan  personal loan  student loan  \\\n",
       "43691            0.0            1.0          0.0            0.0           0.0   \n",
       "68941            0.0            0.0          0.0            0.0           0.0   \n",
       "22325            0.0            1.0          0.0            0.0           0.0   \n",
       "52580            1.0            1.0          1.0            0.0           0.0   \n",
       "84265            0.0            0.0          0.0            0.0           0.0   \n",
       "\n",
       "       Distinct_Type_Loan  \n",
       "43691                 1.0  \n",
       "68941                 1.0  \n",
       "22325                 2.0  \n",
       "52580                 4.0  \n",
       "84265                 1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dataset.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # comprobación: conteo de variables multinivel\n",
    "# for col in Dataset.iloc[:,21:-1].columns:\n",
    "#     print(Dataset[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06. Tramificación (Binning)\n",
    "**Nota**: Esta técnica se utilizo en pro de mejorar la precisión del modelo. Sin embargo fue descartado, debido a que todas las variables sometidas a este procedimiento redujeron su participación en el ranking de importancia de características."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06.01 Tramificación univariable*\n",
    "***Evaluación si el Binning mejora el rendimiento de la predicción***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from optbinning import Scorecard, BinningProcess, OptimalBinning, ContinuousOptimalBinning\n",
    "# from optbinning.scorecard import plot_auc_roc, plot_cap, plot_ks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # prueba univariable\n",
    "# variable= 'Total_EMI_per_month'\n",
    "# V_vals = Dataset[variable].values\n",
    "# O_vals = data_train.Credit_Score.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optb = OptimalBinning(name=variable, dtype=\"numerical\", solver=\"cp\")\n",
    "# optb.fit(V_vals, O_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning_table = optb.binning_table\n",
    "# binning_table.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset[variable] = optb.transform(Dataset[variable].values, metric=\"indices\") # indices, woe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06.02. Tramificacion multivariables\n",
    "***Solución multivariante***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opt_num = ['Num_Credit_Card',\n",
    "#            'Num_Bank_Accounts',\n",
    "#            'Num_of_Delayed_Payment',\n",
    "#            'Monthly_Balance',\n",
    "#            'Monthly_Inhand_Salary',\n",
    "#            'Age',\n",
    "#            'Amount_invested_monthly',\n",
    "#            'Num_of_Loan',\n",
    "#            'Annual_Income',\n",
    "#            'Credit_Utilization_Ratio',\n",
    "#            'Total_EMI_per_month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y = data_train['Credit_Score'].values\n",
    "# X = data_train[opt_num]\n",
    "# list_variables = X.columns.values.tolist()\n",
    "# list_categorical = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # se debe indentificar un criterio de selección para variables objetivo multivariable\n",
    "# selection_criteria = {\n",
    "#     \"iv\": {\"min\": 0.02}\n",
    "# }\n",
    "# binning_fit_params={\n",
    "#     \"purpose\":{\"cat_cutoff\": 0.10}\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binning_process = BinningProcess(categorical_variables=list_categorical,\n",
    "#                                  variable_names=list_variables,\n",
    "#                                 #  selection_criteria=selection_criteria,\n",
    "#                                  binning_fit_params=binning_fit_params\n",
    "#                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_binned = binning_process.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_train_binned.get_support()\n",
    "# data_train_woe = data_train_binned.transform(X, metric=\"mean_woe\")\n",
    "# data_train_woe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. Preparación de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07.01. Variable de control\n",
    "**Nota**: Se introducen dos variables aletaorias para la relacion de las variables con respecto a la respuestas.  Si estas variables aleatorias presentan relación con la variable respuesta serán debidas puramente al azar, con lo que se pueden considerar relaciones espurias, es decir, falsas. Por tanto, las variables que presenten una menor relación con la respuesta que las variables de control, tendrán una sombra de sospecha sobre la veracidad de esa relación y por ende serán descartas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset['VarAleatoria_01'] = np.random.uniform(0,1,size=Dataset.shape[0])\n",
    "# Dataset['VarAleatoria_02'] = np.random.uniform(0,1,size=Dataset.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listado de variable descartadas\n",
    "VarDrop = [\n",
    "        #    'VarAleatoria_01',\n",
    "        #    'VarAleatoria_02',\n",
    "           'Credit_Utilization_Ratio',\n",
    "           'Occupation',\n",
    "           'Payment_Behaviour',\n",
    "           'Distinct_Type_Loan',\n",
    "           'not specified',\n",
    "           'debt consolidation loan',\n",
    "           'payday loan',\n",
    "           'personal loan',\n",
    "           'mortgage loan',\n",
    "           'auto loan',\n",
    "           'student loan',\n",
    "           'credit-builder loan',\n",
    "           'home equity loan'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dataset.drop(VarDrop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# escalado de variables\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(Dataset)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=Dataset.columns, index=Dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 72986 entries, 0 to 99999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   Age                      72986 non-null  float64\n",
      " 1   Annual_Income            72986 non-null  float64\n",
      " 2   Monthly_Inhand_Salary    72986 non-null  float64\n",
      " 3   Num_Bank_Accounts        72986 non-null  float64\n",
      " 4   Num_Credit_Card          72986 non-null  float64\n",
      " 5   Interest_Rate            72986 non-null  float64\n",
      " 6   Num_of_Loan              72986 non-null  float64\n",
      " 7   Delay_from_due_date      72986 non-null  float64\n",
      " 8   Num_of_Delayed_Payment   72986 non-null  float64\n",
      " 9   Changed_Credit_Limit     72986 non-null  float64\n",
      " 10  Num_Credit_Inquiries     72986 non-null  float64\n",
      " 11  Credit_Mix               72986 non-null  float64\n",
      " 12  Outstanding_Debt         72986 non-null  float64\n",
      " 13  Credit_History_Age       72986 non-null  float64\n",
      " 14  Payment_of_Min_Amount    72986 non-null  float64\n",
      " 15  Total_EMI_per_month      72986 non-null  float64\n",
      " 16  Amount_invested_monthly  72986 non-null  float64\n",
      " 17  Monthly_Balance          72986 non-null  float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 10.6 MB\n"
     ]
    }
   ],
   "source": [
    "scaled_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07.03. PCA\n",
    "**Nota**: Se utilizó para probar si la reduccion de dimensionalidad mejoraba el rendimiento de la predicción del modelo. Este procedimiento fue descartado deido a la reducción del rendimiento.<br>\n",
    "Objetivos: Reducir dimensionalidad, evitar overfiting y manejar la posible multicolinealidad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load library\n",
    "# from pca import pca\n",
    "\n",
    "# # Initialize pca with default parameters\n",
    "# pca_model = pca(normalize=True,n_components=0.8)\n",
    "\n",
    "# # Fit transform\n",
    "# results = pca_model.fit_transform(scaled_data)\n",
    "\n",
    "# # Plot the explained variance\n",
    "# pca_model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_model.results['PC'].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07.04 División del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaled_data # pca_model.results['PC']\n",
    "y = data_train.Credit_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((72986,), (72986, 18))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Oversampling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=42)\n",
    "# resampleo con respecto a la variable objetivo\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separación en entrenamiento y prueba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, stratify=y_res, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 08. Modelamiento de ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric: accuracy , KFold \n",
      "Logistic: 0.698861 (0.002786) \n",
      "Metric: accuracy , KFold \n",
      "GaussianNB: 0.691747 (0.002441) \n",
      "Metric: accuracy , KFold \n",
      "XGB: 0.827969 (0.001932) \n",
      "Metric: accuracy , KFold \n",
      "RF: 0.880595 (0.001469) \n",
      "Metric: accuracy , KFold \n",
      "Tree: 0.809136 (0.001321) \n",
      "Metric: accuracy , KFold \n",
      "SGD: 0.691564 (0.006093) \n",
      "Metric: accuracy , KFold \n",
      "OvO: 0.880862 (0.001457) \n"
     ]
    }
   ],
   "source": [
    "# definimos los modelos y generamos una lista con cada uno de ellos:\n",
    "models = [\n",
    "         (\"Logistic\", LogisticRegression(n_jobs=-1, random_state=42)),\n",
    "         (\"GaussianNB\", GaussianNB()),\n",
    "         (\"XGB\", XGBClassifier(n_jobs=-1, random_state=42)), # , scale_pos_weight=pos_weight, class_weight=class_weights\n",
    "         (\"RF\", RandomForestClassifier(n_jobs=-1, random_state=42)),\n",
    "         (\"Tree\", DecisionTreeClassifier(random_state=42)),\n",
    "         (\"SGD\", SGDClassifier(n_jobs=-1, random_state=42)),\n",
    "         (\"OvO\", OneVsOneClassifier(n_jobs=-1, estimator=RandomForestClassifier(random_state=42)))\n",
    "]\n",
    "\n",
    "evaluation_score = \"accuracy\"\n",
    "\n",
    "results, names = model_evaluation(models, evaluation_score, X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# realizamos una visualización de comparativa de modelos\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.boxplot(results)\n",
    "\n",
    "plt.xticks(np.arange(1,len(names)+1),names)\n",
    "plt.title('Box-plot de modelos')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;RandomForestClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(n_jobs=-1, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(n_jobs=-1, random_state=42)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_jobs=-1, random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.89      0.94      0.92      8003\n",
      "    standard       0.87      0.79      0.83      8004\n",
      "        poor       0.88      0.91      0.90      8004\n",
      "\n",
      "    accuracy                           0.88     24011\n",
      "   macro avg       0.88      0.88      0.88     24011\n",
      "weighted avg       0.88      0.88      0.88     24011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred, target_names=['good', 'standard', 'poor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 09. Modelamiento con NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_res.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 512)               9728      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 512)              2048      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 256)              1024      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 220,291\n",
      "Trainable params: 217,859\n",
      "Non-trainable params: 2,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(512, input_shape=(input_shape,), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=150, restore_best_weights=True)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "188/188 [==============================] - 3s 10ms/step - loss: 0.8949 - accuracy: 0.6462 - val_loss: 0.7573 - val_accuracy: 0.7018\n",
      "Epoch 2/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.7489 - accuracy: 0.7112 - val_loss: 0.7140 - val_accuracy: 0.7218\n",
      "Epoch 3/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.7209 - accuracy: 0.7219 - val_loss: 0.6914 - val_accuracy: 0.7295\n",
      "Epoch 4/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.7080 - accuracy: 0.7262 - val_loss: 0.6848 - val_accuracy: 0.7316\n",
      "Epoch 5/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.7004 - accuracy: 0.7286 - val_loss: 0.6806 - val_accuracy: 0.7318\n",
      "Epoch 6/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6951 - accuracy: 0.7298 - val_loss: 0.6743 - val_accuracy: 0.7340\n",
      "Epoch 7/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6887 - accuracy: 0.7323 - val_loss: 0.6695 - val_accuracy: 0.7360\n",
      "Epoch 8/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6851 - accuracy: 0.7327 - val_loss: 0.6685 - val_accuracy: 0.7364\n",
      "Epoch 9/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6797 - accuracy: 0.7349 - val_loss: 0.6627 - val_accuracy: 0.7376\n",
      "Epoch 10/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6754 - accuracy: 0.7365 - val_loss: 0.6603 - val_accuracy: 0.7385\n",
      "Epoch 11/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6730 - accuracy: 0.7374 - val_loss: 0.6564 - val_accuracy: 0.7398\n",
      "Epoch 12/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6679 - accuracy: 0.7379 - val_loss: 0.6493 - val_accuracy: 0.7407\n",
      "Epoch 13/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6647 - accuracy: 0.7390 - val_loss: 0.6493 - val_accuracy: 0.7430\n",
      "Epoch 14/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6612 - accuracy: 0.7397 - val_loss: 0.6439 - val_accuracy: 0.7435\n",
      "Epoch 15/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6566 - accuracy: 0.7413 - val_loss: 0.6414 - val_accuracy: 0.7440\n",
      "Epoch 16/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6535 - accuracy: 0.7423 - val_loss: 0.6345 - val_accuracy: 0.7480\n",
      "Epoch 17/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6486 - accuracy: 0.7432 - val_loss: 0.6297 - val_accuracy: 0.7480\n",
      "Epoch 18/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6444 - accuracy: 0.7460 - val_loss: 0.6225 - val_accuracy: 0.7496\n",
      "Epoch 19/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6410 - accuracy: 0.7458 - val_loss: 0.6194 - val_accuracy: 0.7516\n",
      "Epoch 20/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6374 - accuracy: 0.7464 - val_loss: 0.6151 - val_accuracy: 0.7541\n",
      "Epoch 21/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6329 - accuracy: 0.7497 - val_loss: 0.6106 - val_accuracy: 0.7565\n",
      "Epoch 22/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6291 - accuracy: 0.7495 - val_loss: 0.6042 - val_accuracy: 0.7590\n",
      "Epoch 23/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6236 - accuracy: 0.7517 - val_loss: 0.6057 - val_accuracy: 0.7589\n",
      "Epoch 24/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.6188 - accuracy: 0.7538 - val_loss: 0.5948 - val_accuracy: 0.7615\n",
      "Epoch 25/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6133 - accuracy: 0.7548 - val_loss: 0.5877 - val_accuracy: 0.7638\n",
      "Epoch 26/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6108 - accuracy: 0.7558 - val_loss: 0.5855 - val_accuracy: 0.7634\n",
      "Epoch 27/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6070 - accuracy: 0.7588 - val_loss: 0.5809 - val_accuracy: 0.7686\n",
      "Epoch 28/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.6022 - accuracy: 0.7611 - val_loss: 0.5697 - val_accuracy: 0.7712\n",
      "Epoch 29/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5978 - accuracy: 0.7620 - val_loss: 0.5660 - val_accuracy: 0.7754\n",
      "Epoch 30/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5959 - accuracy: 0.7626 - val_loss: 0.5610 - val_accuracy: 0.7760\n",
      "Epoch 31/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5903 - accuracy: 0.7657 - val_loss: 0.5578 - val_accuracy: 0.7751\n",
      "Epoch 32/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5855 - accuracy: 0.7664 - val_loss: 0.5474 - val_accuracy: 0.7836\n",
      "Epoch 33/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5806 - accuracy: 0.7689 - val_loss: 0.5416 - val_accuracy: 0.7863\n",
      "Epoch 34/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5789 - accuracy: 0.7693 - val_loss: 0.5423 - val_accuracy: 0.7845\n",
      "Epoch 35/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5721 - accuracy: 0.7714 - val_loss: 0.5385 - val_accuracy: 0.7849\n",
      "Epoch 36/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5717 - accuracy: 0.7721 - val_loss: 0.5309 - val_accuracy: 0.7890\n",
      "Epoch 37/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5670 - accuracy: 0.7754 - val_loss: 0.5238 - val_accuracy: 0.7950\n",
      "Epoch 38/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5621 - accuracy: 0.7778 - val_loss: 0.5208 - val_accuracy: 0.7950\n",
      "Epoch 39/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5594 - accuracy: 0.7783 - val_loss: 0.5163 - val_accuracy: 0.7975\n",
      "Epoch 40/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5547 - accuracy: 0.7801 - val_loss: 0.5157 - val_accuracy: 0.7952\n",
      "Epoch 41/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5516 - accuracy: 0.7812 - val_loss: 0.5119 - val_accuracy: 0.7955\n",
      "Epoch 42/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5479 - accuracy: 0.7826 - val_loss: 0.5072 - val_accuracy: 0.8016\n",
      "Epoch 43/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5480 - accuracy: 0.7833 - val_loss: 0.5012 - val_accuracy: 0.8030\n",
      "Epoch 44/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5436 - accuracy: 0.7857 - val_loss: 0.5002 - val_accuracy: 0.8021\n",
      "Epoch 45/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5403 - accuracy: 0.7856 - val_loss: 0.4985 - val_accuracy: 0.8041\n",
      "Epoch 46/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5379 - accuracy: 0.7873 - val_loss: 0.4925 - val_accuracy: 0.8069\n",
      "Epoch 47/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5355 - accuracy: 0.7866 - val_loss: 0.4869 - val_accuracy: 0.8083\n",
      "Epoch 48/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5315 - accuracy: 0.7895 - val_loss: 0.4879 - val_accuracy: 0.8107\n",
      "Epoch 49/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5283 - accuracy: 0.7898 - val_loss: 0.4833 - val_accuracy: 0.8118\n",
      "Epoch 50/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5290 - accuracy: 0.7911 - val_loss: 0.4807 - val_accuracy: 0.8129\n",
      "Epoch 51/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5281 - accuracy: 0.7920 - val_loss: 0.4737 - val_accuracy: 0.8170\n",
      "Epoch 52/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5241 - accuracy: 0.7935 - val_loss: 0.4749 - val_accuracy: 0.8154\n",
      "Epoch 53/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5219 - accuracy: 0.7934 - val_loss: 0.4781 - val_accuracy: 0.8141\n",
      "Epoch 54/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5182 - accuracy: 0.7954 - val_loss: 0.4704 - val_accuracy: 0.8158\n",
      "Epoch 55/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5166 - accuracy: 0.7966 - val_loss: 0.4666 - val_accuracy: 0.8180\n",
      "Epoch 56/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5143 - accuracy: 0.7972 - val_loss: 0.4674 - val_accuracy: 0.8188\n",
      "Epoch 57/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5128 - accuracy: 0.7977 - val_loss: 0.4643 - val_accuracy: 0.8196\n",
      "Epoch 58/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.5105 - accuracy: 0.7983 - val_loss: 0.4632 - val_accuracy: 0.8201\n",
      "Epoch 59/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5103 - accuracy: 0.7987 - val_loss: 0.4585 - val_accuracy: 0.8212\n",
      "Epoch 60/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5087 - accuracy: 0.7993 - val_loss: 0.4561 - val_accuracy: 0.8230\n",
      "Epoch 61/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5072 - accuracy: 0.8011 - val_loss: 0.4571 - val_accuracy: 0.8228\n",
      "Epoch 62/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5029 - accuracy: 0.8027 - val_loss: 0.4544 - val_accuracy: 0.8238\n",
      "Epoch 63/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5044 - accuracy: 0.8015 - val_loss: 0.4499 - val_accuracy: 0.8253\n",
      "Epoch 64/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.5005 - accuracy: 0.8026 - val_loss: 0.4488 - val_accuracy: 0.8279\n",
      "Epoch 65/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4980 - accuracy: 0.8028 - val_loss: 0.4485 - val_accuracy: 0.8256\n",
      "Epoch 66/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4993 - accuracy: 0.8041 - val_loss: 0.4441 - val_accuracy: 0.8278\n",
      "Epoch 67/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4950 - accuracy: 0.8053 - val_loss: 0.4460 - val_accuracy: 0.8274\n",
      "Epoch 68/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4966 - accuracy: 0.8052 - val_loss: 0.4454 - val_accuracy: 0.8289\n",
      "Epoch 69/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4916 - accuracy: 0.8073 - val_loss: 0.4450 - val_accuracy: 0.8289\n",
      "Epoch 70/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4943 - accuracy: 0.8065 - val_loss: 0.4441 - val_accuracy: 0.8298\n",
      "Epoch 71/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4902 - accuracy: 0.8068 - val_loss: 0.4422 - val_accuracy: 0.8290\n",
      "Epoch 72/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4880 - accuracy: 0.8088 - val_loss: 0.4408 - val_accuracy: 0.8299\n",
      "Epoch 73/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4869 - accuracy: 0.8080 - val_loss: 0.4370 - val_accuracy: 0.8333\n",
      "Epoch 74/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4887 - accuracy: 0.8080 - val_loss: 0.4369 - val_accuracy: 0.8314\n",
      "Epoch 75/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4859 - accuracy: 0.8092 - val_loss: 0.4332 - val_accuracy: 0.8343\n",
      "Epoch 76/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4834 - accuracy: 0.8113 - val_loss: 0.4319 - val_accuracy: 0.8363\n",
      "Epoch 77/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4852 - accuracy: 0.8105 - val_loss: 0.4358 - val_accuracy: 0.8330\n",
      "Epoch 78/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4823 - accuracy: 0.8107 - val_loss: 0.4336 - val_accuracy: 0.8356\n",
      "Epoch 79/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4800 - accuracy: 0.8131 - val_loss: 0.4302 - val_accuracy: 0.8343\n",
      "Epoch 80/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4805 - accuracy: 0.8119 - val_loss: 0.4272 - val_accuracy: 0.8369\n",
      "Epoch 81/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4767 - accuracy: 0.8137 - val_loss: 0.4285 - val_accuracy: 0.8355\n",
      "Epoch 82/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4771 - accuracy: 0.8140 - val_loss: 0.4267 - val_accuracy: 0.8355\n",
      "Epoch 83/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4760 - accuracy: 0.8139 - val_loss: 0.4264 - val_accuracy: 0.8364\n",
      "Epoch 84/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4754 - accuracy: 0.8136 - val_loss: 0.4280 - val_accuracy: 0.8357\n",
      "Epoch 85/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4777 - accuracy: 0.8130 - val_loss: 0.4271 - val_accuracy: 0.8371\n",
      "Epoch 86/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4695 - accuracy: 0.8160 - val_loss: 0.4228 - val_accuracy: 0.8389\n",
      "Epoch 87/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4731 - accuracy: 0.8151 - val_loss: 0.4255 - val_accuracy: 0.8371\n",
      "Epoch 88/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4689 - accuracy: 0.8177 - val_loss: 0.4227 - val_accuracy: 0.8372\n",
      "Epoch 89/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4676 - accuracy: 0.8169 - val_loss: 0.4182 - val_accuracy: 0.8398\n",
      "Epoch 90/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4694 - accuracy: 0.8174 - val_loss: 0.4233 - val_accuracy: 0.8396\n",
      "Epoch 91/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4671 - accuracy: 0.8180 - val_loss: 0.4225 - val_accuracy: 0.8406\n",
      "Epoch 92/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4693 - accuracy: 0.8179 - val_loss: 0.4195 - val_accuracy: 0.8404\n",
      "Epoch 93/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4691 - accuracy: 0.8163 - val_loss: 0.4221 - val_accuracy: 0.8399\n",
      "Epoch 94/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4668 - accuracy: 0.8179 - val_loss: 0.4164 - val_accuracy: 0.8425\n",
      "Epoch 95/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4644 - accuracy: 0.8202 - val_loss: 0.4153 - val_accuracy: 0.8439\n",
      "Epoch 96/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4663 - accuracy: 0.8178 - val_loss: 0.4189 - val_accuracy: 0.8397\n",
      "Epoch 97/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4637 - accuracy: 0.8201 - val_loss: 0.4167 - val_accuracy: 0.8417\n",
      "Epoch 98/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4635 - accuracy: 0.8194 - val_loss: 0.4139 - val_accuracy: 0.8437\n",
      "Epoch 99/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4617 - accuracy: 0.8204 - val_loss: 0.4148 - val_accuracy: 0.8427\n",
      "Epoch 100/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4598 - accuracy: 0.8219 - val_loss: 0.4144 - val_accuracy: 0.8432\n",
      "Epoch 101/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4595 - accuracy: 0.8205 - val_loss: 0.4121 - val_accuracy: 0.8447\n",
      "Epoch 102/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4577 - accuracy: 0.8209 - val_loss: 0.4100 - val_accuracy: 0.8458\n",
      "Epoch 103/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4586 - accuracy: 0.8222 - val_loss: 0.4139 - val_accuracy: 0.8429\n",
      "Epoch 104/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4585 - accuracy: 0.8222 - val_loss: 0.4090 - val_accuracy: 0.8450\n",
      "Epoch 105/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4556 - accuracy: 0.8228 - val_loss: 0.4107 - val_accuracy: 0.8454\n",
      "Epoch 106/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4555 - accuracy: 0.8243 - val_loss: 0.4113 - val_accuracy: 0.8458\n",
      "Epoch 107/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4559 - accuracy: 0.8228 - val_loss: 0.4070 - val_accuracy: 0.8466\n",
      "Epoch 108/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4547 - accuracy: 0.8231 - val_loss: 0.4070 - val_accuracy: 0.8454\n",
      "Epoch 109/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.4539 - accuracy: 0.8230 - val_loss: 0.4077 - val_accuracy: 0.8457\n",
      "Epoch 110/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.4522 - accuracy: 0.8237 - val_loss: 0.4086 - val_accuracy: 0.8447\n",
      "Epoch 111/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4530 - accuracy: 0.8239 - val_loss: 0.4061 - val_accuracy: 0.8461\n",
      "Epoch 112/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4525 - accuracy: 0.8236 - val_loss: 0.4096 - val_accuracy: 0.8456\n",
      "Epoch 113/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4498 - accuracy: 0.8245 - val_loss: 0.4033 - val_accuracy: 0.8479\n",
      "Epoch 114/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4495 - accuracy: 0.8261 - val_loss: 0.4039 - val_accuracy: 0.8482\n",
      "Epoch 115/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4487 - accuracy: 0.8259 - val_loss: 0.4031 - val_accuracy: 0.8484\n",
      "Epoch 116/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4477 - accuracy: 0.8252 - val_loss: 0.4044 - val_accuracy: 0.8459\n",
      "Epoch 117/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4481 - accuracy: 0.8258 - val_loss: 0.4042 - val_accuracy: 0.8471\n",
      "Epoch 118/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4477 - accuracy: 0.8257 - val_loss: 0.4035 - val_accuracy: 0.8472\n",
      "Epoch 119/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4465 - accuracy: 0.8268 - val_loss: 0.4027 - val_accuracy: 0.8470\n",
      "Epoch 120/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.4471 - accuracy: 0.8262 - val_loss: 0.4030 - val_accuracy: 0.8478\n",
      "Epoch 121/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4454 - accuracy: 0.8286 - val_loss: 0.4014 - val_accuracy: 0.8473\n",
      "Epoch 122/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4461 - accuracy: 0.8273 - val_loss: 0.4000 - val_accuracy: 0.8496\n",
      "Epoch 123/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4456 - accuracy: 0.8282 - val_loss: 0.3972 - val_accuracy: 0.8510\n",
      "Epoch 124/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.4447 - accuracy: 0.8281 - val_loss: 0.4005 - val_accuracy: 0.8497\n",
      "Epoch 125/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4448 - accuracy: 0.8283 - val_loss: 0.4022 - val_accuracy: 0.8498\n",
      "Epoch 126/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4448 - accuracy: 0.8275 - val_loss: 0.4008 - val_accuracy: 0.8503\n",
      "Epoch 127/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4424 - accuracy: 0.8277 - val_loss: 0.3985 - val_accuracy: 0.8533\n",
      "Epoch 128/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4451 - accuracy: 0.8270 - val_loss: 0.4002 - val_accuracy: 0.8501\n",
      "Epoch 129/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4420 - accuracy: 0.8295 - val_loss: 0.3981 - val_accuracy: 0.8512\n",
      "Epoch 130/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4449 - accuracy: 0.8290 - val_loss: 0.3983 - val_accuracy: 0.8507\n",
      "Epoch 131/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4415 - accuracy: 0.8300 - val_loss: 0.3963 - val_accuracy: 0.8517\n",
      "Epoch 132/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4399 - accuracy: 0.8307 - val_loss: 0.3960 - val_accuracy: 0.8509\n",
      "Epoch 133/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4428 - accuracy: 0.8280 - val_loss: 0.3966 - val_accuracy: 0.8534\n",
      "Epoch 134/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4381 - accuracy: 0.8305 - val_loss: 0.3947 - val_accuracy: 0.8536\n",
      "Epoch 135/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4389 - accuracy: 0.8301 - val_loss: 0.3942 - val_accuracy: 0.8529\n",
      "Epoch 136/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4381 - accuracy: 0.8307 - val_loss: 0.3960 - val_accuracy: 0.8523\n",
      "Epoch 137/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4393 - accuracy: 0.8308 - val_loss: 0.3982 - val_accuracy: 0.8511\n",
      "Epoch 138/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4380 - accuracy: 0.8308 - val_loss: 0.3961 - val_accuracy: 0.8508\n",
      "Epoch 139/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4352 - accuracy: 0.8321 - val_loss: 0.3952 - val_accuracy: 0.8526\n",
      "Epoch 140/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4359 - accuracy: 0.8308 - val_loss: 0.3951 - val_accuracy: 0.8522\n",
      "Epoch 141/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4393 - accuracy: 0.8297 - val_loss: 0.3913 - val_accuracy: 0.8536\n",
      "Epoch 142/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4360 - accuracy: 0.8319 - val_loss: 0.3915 - val_accuracy: 0.8553\n",
      "Epoch 143/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4361 - accuracy: 0.8317 - val_loss: 0.3934 - val_accuracy: 0.8512\n",
      "Epoch 144/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4361 - accuracy: 0.8321 - val_loss: 0.3946 - val_accuracy: 0.8540\n",
      "Epoch 145/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4341 - accuracy: 0.8328 - val_loss: 0.3937 - val_accuracy: 0.8535\n",
      "Epoch 146/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4361 - accuracy: 0.8307 - val_loss: 0.3927 - val_accuracy: 0.8552\n",
      "Epoch 147/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4314 - accuracy: 0.8341 - val_loss: 0.3934 - val_accuracy: 0.8537\n",
      "Epoch 148/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4341 - accuracy: 0.8329 - val_loss: 0.3898 - val_accuracy: 0.8551\n",
      "Epoch 149/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4353 - accuracy: 0.8313 - val_loss: 0.3913 - val_accuracy: 0.8548\n",
      "Epoch 150/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4307 - accuracy: 0.8349 - val_loss: 0.3905 - val_accuracy: 0.8549\n",
      "Epoch 151/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4320 - accuracy: 0.8332 - val_loss: 0.3899 - val_accuracy: 0.8546\n",
      "Epoch 152/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4311 - accuracy: 0.8345 - val_loss: 0.3892 - val_accuracy: 0.8551\n",
      "Epoch 153/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4318 - accuracy: 0.8331 - val_loss: 0.3864 - val_accuracy: 0.8563\n",
      "Epoch 154/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4326 - accuracy: 0.8330 - val_loss: 0.3911 - val_accuracy: 0.8544\n",
      "Epoch 155/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4298 - accuracy: 0.8360 - val_loss: 0.3851 - val_accuracy: 0.8588\n",
      "Epoch 156/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4322 - accuracy: 0.8328 - val_loss: 0.3885 - val_accuracy: 0.8545\n",
      "Epoch 157/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4287 - accuracy: 0.8371 - val_loss: 0.3854 - val_accuracy: 0.8569\n",
      "Epoch 158/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4273 - accuracy: 0.8350 - val_loss: 0.3882 - val_accuracy: 0.8553\n",
      "Epoch 159/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4291 - accuracy: 0.8345 - val_loss: 0.3893 - val_accuracy: 0.8545\n",
      "Epoch 160/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4281 - accuracy: 0.8356 - val_loss: 0.3867 - val_accuracy: 0.8570\n",
      "Epoch 161/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4262 - accuracy: 0.8365 - val_loss: 0.3859 - val_accuracy: 0.8567\n",
      "Epoch 162/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4250 - accuracy: 0.8370 - val_loss: 0.3903 - val_accuracy: 0.8554\n",
      "Epoch 163/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4271 - accuracy: 0.8366 - val_loss: 0.3870 - val_accuracy: 0.8558\n",
      "Epoch 164/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4253 - accuracy: 0.8364 - val_loss: 0.3833 - val_accuracy: 0.8587\n",
      "Epoch 165/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4267 - accuracy: 0.8354 - val_loss: 0.3879 - val_accuracy: 0.8576\n",
      "Epoch 166/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4259 - accuracy: 0.8368 - val_loss: 0.3824 - val_accuracy: 0.8574\n",
      "Epoch 167/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4260 - accuracy: 0.8359 - val_loss: 0.3834 - val_accuracy: 0.8563\n",
      "Epoch 168/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4254 - accuracy: 0.8349 - val_loss: 0.3838 - val_accuracy: 0.8581\n",
      "Epoch 169/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4249 - accuracy: 0.8364 - val_loss: 0.3843 - val_accuracy: 0.8582\n",
      "Epoch 170/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4269 - accuracy: 0.8355 - val_loss: 0.3837 - val_accuracy: 0.8579\n",
      "Epoch 171/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4231 - accuracy: 0.8365 - val_loss: 0.3820 - val_accuracy: 0.8592\n",
      "Epoch 172/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4246 - accuracy: 0.8380 - val_loss: 0.3827 - val_accuracy: 0.8588\n",
      "Epoch 173/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4234 - accuracy: 0.8363 - val_loss: 0.3833 - val_accuracy: 0.8571\n",
      "Epoch 174/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4214 - accuracy: 0.8390 - val_loss: 0.3817 - val_accuracy: 0.8569\n",
      "Epoch 175/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4236 - accuracy: 0.8364 - val_loss: 0.3841 - val_accuracy: 0.8566\n",
      "Epoch 176/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4225 - accuracy: 0.8384 - val_loss: 0.3809 - val_accuracy: 0.8592\n",
      "Epoch 177/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4214 - accuracy: 0.8381 - val_loss: 0.3821 - val_accuracy: 0.8581\n",
      "Epoch 178/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4212 - accuracy: 0.8378 - val_loss: 0.3798 - val_accuracy: 0.8586\n",
      "Epoch 179/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4215 - accuracy: 0.8376 - val_loss: 0.3855 - val_accuracy: 0.8571\n",
      "Epoch 180/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4203 - accuracy: 0.8382 - val_loss: 0.3815 - val_accuracy: 0.8589\n",
      "Epoch 181/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4227 - accuracy: 0.8377 - val_loss: 0.3812 - val_accuracy: 0.8594\n",
      "Epoch 182/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4218 - accuracy: 0.8388 - val_loss: 0.3806 - val_accuracy: 0.8581\n",
      "Epoch 183/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4219 - accuracy: 0.8377 - val_loss: 0.3840 - val_accuracy: 0.8598\n",
      "Epoch 184/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4225 - accuracy: 0.8378 - val_loss: 0.3794 - val_accuracy: 0.8593\n",
      "Epoch 185/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4194 - accuracy: 0.8385 - val_loss: 0.3811 - val_accuracy: 0.8585\n",
      "Epoch 186/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4206 - accuracy: 0.8394 - val_loss: 0.3794 - val_accuracy: 0.8588\n",
      "Epoch 187/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4194 - accuracy: 0.8392 - val_loss: 0.3821 - val_accuracy: 0.8571\n",
      "Epoch 188/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4187 - accuracy: 0.8385 - val_loss: 0.3803 - val_accuracy: 0.8582\n",
      "Epoch 189/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4170 - accuracy: 0.8404 - val_loss: 0.3773 - val_accuracy: 0.8601\n",
      "Epoch 190/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4164 - accuracy: 0.8412 - val_loss: 0.3794 - val_accuracy: 0.8575\n",
      "Epoch 191/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4189 - accuracy: 0.8384 - val_loss: 0.3785 - val_accuracy: 0.8595\n",
      "Epoch 192/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4182 - accuracy: 0.8388 - val_loss: 0.3798 - val_accuracy: 0.8596\n",
      "Epoch 193/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4178 - accuracy: 0.8394 - val_loss: 0.3805 - val_accuracy: 0.8589\n",
      "Epoch 194/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4184 - accuracy: 0.8389 - val_loss: 0.3789 - val_accuracy: 0.8596\n",
      "Epoch 195/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4169 - accuracy: 0.8402 - val_loss: 0.3788 - val_accuracy: 0.8588\n",
      "Epoch 196/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4164 - accuracy: 0.8408 - val_loss: 0.3755 - val_accuracy: 0.8616\n",
      "Epoch 197/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4162 - accuracy: 0.8394 - val_loss: 0.3810 - val_accuracy: 0.8605\n",
      "Epoch 198/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4177 - accuracy: 0.8396 - val_loss: 0.3760 - val_accuracy: 0.8600\n",
      "Epoch 199/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4152 - accuracy: 0.8417 - val_loss: 0.3777 - val_accuracy: 0.8602\n",
      "Epoch 200/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4164 - accuracy: 0.8404 - val_loss: 0.3776 - val_accuracy: 0.8585\n",
      "Epoch 201/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4142 - accuracy: 0.8404 - val_loss: 0.3754 - val_accuracy: 0.8602\n",
      "Epoch 202/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4148 - accuracy: 0.8413 - val_loss: 0.3766 - val_accuracy: 0.8618\n",
      "Epoch 203/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4172 - accuracy: 0.8404 - val_loss: 0.3778 - val_accuracy: 0.8594\n",
      "Epoch 204/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4147 - accuracy: 0.8420 - val_loss: 0.3751 - val_accuracy: 0.8606\n",
      "Epoch 205/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4166 - accuracy: 0.8411 - val_loss: 0.3771 - val_accuracy: 0.8598\n",
      "Epoch 206/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4121 - accuracy: 0.8420 - val_loss: 0.3743 - val_accuracy: 0.8626\n",
      "Epoch 207/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4127 - accuracy: 0.8427 - val_loss: 0.3765 - val_accuracy: 0.8611\n",
      "Epoch 208/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4128 - accuracy: 0.8424 - val_loss: 0.3763 - val_accuracy: 0.8609\n",
      "Epoch 209/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4145 - accuracy: 0.8411 - val_loss: 0.3760 - val_accuracy: 0.8615\n",
      "Epoch 210/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4111 - accuracy: 0.8423 - val_loss: 0.3725 - val_accuracy: 0.8628\n",
      "Epoch 211/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4138 - accuracy: 0.8411 - val_loss: 0.3752 - val_accuracy: 0.8615\n",
      "Epoch 212/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4114 - accuracy: 0.8426 - val_loss: 0.3715 - val_accuracy: 0.8625\n",
      "Epoch 213/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4117 - accuracy: 0.8423 - val_loss: 0.3753 - val_accuracy: 0.8609\n",
      "Epoch 214/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4111 - accuracy: 0.8424 - val_loss: 0.3752 - val_accuracy: 0.8624\n",
      "Epoch 215/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4133 - accuracy: 0.8416 - val_loss: 0.3745 - val_accuracy: 0.8616\n",
      "Epoch 216/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4105 - accuracy: 0.8426 - val_loss: 0.3761 - val_accuracy: 0.8608\n",
      "Epoch 217/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4112 - accuracy: 0.8424 - val_loss: 0.3734 - val_accuracy: 0.8628\n",
      "Epoch 218/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4129 - accuracy: 0.8417 - val_loss: 0.3762 - val_accuracy: 0.8618\n",
      "Epoch 219/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4114 - accuracy: 0.8432 - val_loss: 0.3751 - val_accuracy: 0.8611\n",
      "Epoch 220/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4136 - accuracy: 0.8412 - val_loss: 0.3759 - val_accuracy: 0.8624\n",
      "Epoch 221/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4106 - accuracy: 0.8418 - val_loss: 0.3767 - val_accuracy: 0.8618\n",
      "Epoch 222/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4094 - accuracy: 0.8433 - val_loss: 0.3748 - val_accuracy: 0.8624\n",
      "Epoch 223/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4103 - accuracy: 0.8432 - val_loss: 0.3748 - val_accuracy: 0.8624\n",
      "Epoch 224/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4088 - accuracy: 0.8435 - val_loss: 0.3748 - val_accuracy: 0.8615\n",
      "Epoch 225/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4123 - accuracy: 0.8411 - val_loss: 0.3770 - val_accuracy: 0.8624\n",
      "Epoch 226/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4103 - accuracy: 0.8420 - val_loss: 0.3722 - val_accuracy: 0.8623\n",
      "Epoch 227/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4110 - accuracy: 0.8420 - val_loss: 0.3730 - val_accuracy: 0.8632\n",
      "Epoch 228/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4110 - accuracy: 0.8430 - val_loss: 0.3725 - val_accuracy: 0.8631\n",
      "Epoch 229/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4081 - accuracy: 0.8437 - val_loss: 0.3719 - val_accuracy: 0.8626\n",
      "Epoch 230/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4084 - accuracy: 0.8439 - val_loss: 0.3694 - val_accuracy: 0.8643\n",
      "Epoch 231/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4087 - accuracy: 0.8442 - val_loss: 0.3739 - val_accuracy: 0.8625\n",
      "Epoch 232/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4078 - accuracy: 0.8444 - val_loss: 0.3711 - val_accuracy: 0.8627\n",
      "Epoch 233/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4082 - accuracy: 0.8445 - val_loss: 0.3735 - val_accuracy: 0.8629\n",
      "Epoch 234/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4054 - accuracy: 0.8447 - val_loss: 0.3747 - val_accuracy: 0.8628\n",
      "Epoch 235/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4069 - accuracy: 0.8441 - val_loss: 0.3712 - val_accuracy: 0.8637\n",
      "Epoch 236/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4063 - accuracy: 0.8454 - val_loss: 0.3713 - val_accuracy: 0.8643\n",
      "Epoch 237/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4071 - accuracy: 0.8443 - val_loss: 0.3688 - val_accuracy: 0.8646\n",
      "Epoch 238/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4088 - accuracy: 0.8436 - val_loss: 0.3717 - val_accuracy: 0.8631\n",
      "Epoch 239/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4078 - accuracy: 0.8447 - val_loss: 0.3696 - val_accuracy: 0.8645\n",
      "Epoch 240/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4063 - accuracy: 0.8452 - val_loss: 0.3757 - val_accuracy: 0.8633\n",
      "Epoch 241/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4085 - accuracy: 0.8446 - val_loss: 0.3695 - val_accuracy: 0.8642\n",
      "Epoch 242/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4058 - accuracy: 0.8454 - val_loss: 0.3728 - val_accuracy: 0.8625\n",
      "Epoch 243/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4063 - accuracy: 0.8453 - val_loss: 0.3732 - val_accuracy: 0.8632\n",
      "Epoch 244/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4053 - accuracy: 0.8450 - val_loss: 0.3718 - val_accuracy: 0.8630\n",
      "Epoch 245/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4067 - accuracy: 0.8446 - val_loss: 0.3722 - val_accuracy: 0.8643\n",
      "Epoch 246/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4044 - accuracy: 0.8451 - val_loss: 0.3719 - val_accuracy: 0.8636\n",
      "Epoch 247/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4057 - accuracy: 0.8455 - val_loss: 0.3735 - val_accuracy: 0.8629\n",
      "Epoch 248/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4054 - accuracy: 0.8446 - val_loss: 0.3688 - val_accuracy: 0.8641\n",
      "Epoch 249/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4052 - accuracy: 0.8453 - val_loss: 0.3714 - val_accuracy: 0.8636\n",
      "Epoch 250/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4028 - accuracy: 0.8454 - val_loss: 0.3675 - val_accuracy: 0.8638\n",
      "Epoch 251/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4039 - accuracy: 0.8458 - val_loss: 0.3663 - val_accuracy: 0.8656\n",
      "Epoch 252/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4018 - accuracy: 0.8477 - val_loss: 0.3685 - val_accuracy: 0.8639\n",
      "Epoch 253/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4049 - accuracy: 0.8461 - val_loss: 0.3687 - val_accuracy: 0.8649\n",
      "Epoch 254/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4046 - accuracy: 0.8454 - val_loss: 0.3700 - val_accuracy: 0.8651\n",
      "Epoch 255/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4048 - accuracy: 0.8460 - val_loss: 0.3666 - val_accuracy: 0.8642\n",
      "Epoch 256/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4042 - accuracy: 0.8454 - val_loss: 0.3685 - val_accuracy: 0.8654\n",
      "Epoch 257/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4034 - accuracy: 0.8469 - val_loss: 0.3677 - val_accuracy: 0.8641\n",
      "Epoch 258/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4019 - accuracy: 0.8462 - val_loss: 0.3699 - val_accuracy: 0.8659\n",
      "Epoch 259/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4029 - accuracy: 0.8467 - val_loss: 0.3674 - val_accuracy: 0.8656\n",
      "Epoch 260/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4047 - accuracy: 0.8447 - val_loss: 0.3713 - val_accuracy: 0.8646\n",
      "Epoch 261/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4008 - accuracy: 0.8471 - val_loss: 0.3684 - val_accuracy: 0.8637\n",
      "Epoch 262/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3995 - accuracy: 0.8472 - val_loss: 0.3676 - val_accuracy: 0.8647\n",
      "Epoch 263/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4027 - accuracy: 0.8474 - val_loss: 0.3686 - val_accuracy: 0.8648\n",
      "Epoch 264/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4005 - accuracy: 0.8477 - val_loss: 0.3688 - val_accuracy: 0.8640\n",
      "Epoch 265/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.4015 - accuracy: 0.8475 - val_loss: 0.3688 - val_accuracy: 0.8644\n",
      "Epoch 266/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4014 - accuracy: 0.8470 - val_loss: 0.3692 - val_accuracy: 0.8649\n",
      "Epoch 267/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4006 - accuracy: 0.8472 - val_loss: 0.3679 - val_accuracy: 0.8656\n",
      "Epoch 268/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4007 - accuracy: 0.8477 - val_loss: 0.3686 - val_accuracy: 0.8648\n",
      "Epoch 269/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4004 - accuracy: 0.8471 - val_loss: 0.3664 - val_accuracy: 0.8656\n",
      "Epoch 270/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4000 - accuracy: 0.8475 - val_loss: 0.3653 - val_accuracy: 0.8664\n",
      "Epoch 271/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4001 - accuracy: 0.8490 - val_loss: 0.3696 - val_accuracy: 0.8642\n",
      "Epoch 272/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4028 - accuracy: 0.8456 - val_loss: 0.3688 - val_accuracy: 0.8656\n",
      "Epoch 273/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.4002 - accuracy: 0.8467 - val_loss: 0.3689 - val_accuracy: 0.8659\n",
      "Epoch 274/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3998 - accuracy: 0.8480 - val_loss: 0.3650 - val_accuracy: 0.8669\n",
      "Epoch 275/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3990 - accuracy: 0.8483 - val_loss: 0.3666 - val_accuracy: 0.8671\n",
      "Epoch 276/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3983 - accuracy: 0.8488 - val_loss: 0.3658 - val_accuracy: 0.8662\n",
      "Epoch 277/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3987 - accuracy: 0.8488 - val_loss: 0.3702 - val_accuracy: 0.8648\n",
      "Epoch 278/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3998 - accuracy: 0.8478 - val_loss: 0.3679 - val_accuracy: 0.8643\n",
      "Epoch 279/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3979 - accuracy: 0.8474 - val_loss: 0.3656 - val_accuracy: 0.8669\n",
      "Epoch 280/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3977 - accuracy: 0.8486 - val_loss: 0.3685 - val_accuracy: 0.8649\n",
      "Epoch 281/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.4019 - accuracy: 0.8466 - val_loss: 0.3693 - val_accuracy: 0.8633\n",
      "Epoch 282/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3989 - accuracy: 0.8481 - val_loss: 0.3659 - val_accuracy: 0.8652\n",
      "Epoch 283/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3973 - accuracy: 0.8492 - val_loss: 0.3657 - val_accuracy: 0.8666\n",
      "Epoch 284/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3984 - accuracy: 0.8489 - val_loss: 0.3668 - val_accuracy: 0.8639\n",
      "Epoch 285/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3948 - accuracy: 0.8507 - val_loss: 0.3667 - val_accuracy: 0.8668\n",
      "Epoch 286/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3992 - accuracy: 0.8479 - val_loss: 0.3657 - val_accuracy: 0.8659\n",
      "Epoch 287/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3992 - accuracy: 0.8474 - val_loss: 0.3640 - val_accuracy: 0.8658\n",
      "Epoch 288/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3958 - accuracy: 0.8496 - val_loss: 0.3625 - val_accuracy: 0.8654\n",
      "Epoch 289/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3962 - accuracy: 0.8490 - val_loss: 0.3679 - val_accuracy: 0.8652\n",
      "Epoch 290/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3983 - accuracy: 0.8473 - val_loss: 0.3623 - val_accuracy: 0.8662\n",
      "Epoch 291/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3968 - accuracy: 0.8488 - val_loss: 0.3665 - val_accuracy: 0.8659\n",
      "Epoch 292/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3959 - accuracy: 0.8496 - val_loss: 0.3658 - val_accuracy: 0.8659\n",
      "Epoch 293/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3960 - accuracy: 0.8492 - val_loss: 0.3660 - val_accuracy: 0.8649\n",
      "Epoch 294/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3948 - accuracy: 0.8501 - val_loss: 0.3654 - val_accuracy: 0.8669\n",
      "Epoch 295/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3964 - accuracy: 0.8492 - val_loss: 0.3662 - val_accuracy: 0.8659\n",
      "Epoch 296/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3970 - accuracy: 0.8487 - val_loss: 0.3686 - val_accuracy: 0.8649\n",
      "Epoch 297/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3956 - accuracy: 0.8495 - val_loss: 0.3650 - val_accuracy: 0.8671\n",
      "Epoch 298/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3961 - accuracy: 0.8493 - val_loss: 0.3645 - val_accuracy: 0.8654\n",
      "Epoch 299/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3966 - accuracy: 0.8492 - val_loss: 0.3649 - val_accuracy: 0.8667\n",
      "Epoch 300/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3961 - accuracy: 0.8499 - val_loss: 0.3622 - val_accuracy: 0.8666\n",
      "Epoch 301/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3976 - accuracy: 0.8480 - val_loss: 0.3651 - val_accuracy: 0.8661\n",
      "Epoch 302/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3963 - accuracy: 0.8495 - val_loss: 0.3625 - val_accuracy: 0.8682\n",
      "Epoch 303/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3932 - accuracy: 0.8510 - val_loss: 0.3647 - val_accuracy: 0.8675\n",
      "Epoch 304/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3948 - accuracy: 0.8503 - val_loss: 0.3644 - val_accuracy: 0.8661\n",
      "Epoch 305/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3940 - accuracy: 0.8495 - val_loss: 0.3634 - val_accuracy: 0.8673\n",
      "Epoch 306/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3928 - accuracy: 0.8507 - val_loss: 0.3645 - val_accuracy: 0.8664\n",
      "Epoch 307/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3954 - accuracy: 0.8498 - val_loss: 0.3642 - val_accuracy: 0.8676\n",
      "Epoch 308/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3932 - accuracy: 0.8504 - val_loss: 0.3609 - val_accuracy: 0.8663\n",
      "Epoch 309/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3951 - accuracy: 0.8491 - val_loss: 0.3628 - val_accuracy: 0.8671\n",
      "Epoch 310/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3947 - accuracy: 0.8491 - val_loss: 0.3629 - val_accuracy: 0.8674\n",
      "Epoch 311/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3939 - accuracy: 0.8505 - val_loss: 0.3625 - val_accuracy: 0.8678\n",
      "Epoch 312/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3945 - accuracy: 0.8497 - val_loss: 0.3623 - val_accuracy: 0.8663\n",
      "Epoch 313/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3923 - accuracy: 0.8514 - val_loss: 0.3641 - val_accuracy: 0.8664\n",
      "Epoch 314/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3922 - accuracy: 0.8521 - val_loss: 0.3620 - val_accuracy: 0.8672\n",
      "Epoch 315/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3974 - accuracy: 0.8492 - val_loss: 0.3656 - val_accuracy: 0.8646\n",
      "Epoch 316/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3954 - accuracy: 0.8497 - val_loss: 0.3624 - val_accuracy: 0.8661\n",
      "Epoch 317/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3945 - accuracy: 0.8498 - val_loss: 0.3650 - val_accuracy: 0.8676\n",
      "Epoch 318/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3923 - accuracy: 0.8510 - val_loss: 0.3656 - val_accuracy: 0.8663\n",
      "Epoch 319/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3902 - accuracy: 0.8528 - val_loss: 0.3631 - val_accuracy: 0.8674\n",
      "Epoch 320/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3907 - accuracy: 0.8503 - val_loss: 0.3645 - val_accuracy: 0.8664\n",
      "Epoch 321/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3944 - accuracy: 0.8504 - val_loss: 0.3606 - val_accuracy: 0.8675\n",
      "Epoch 322/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3956 - accuracy: 0.8499 - val_loss: 0.3603 - val_accuracy: 0.8679\n",
      "Epoch 323/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3911 - accuracy: 0.8519 - val_loss: 0.3642 - val_accuracy: 0.8672\n",
      "Epoch 324/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3933 - accuracy: 0.8507 - val_loss: 0.3631 - val_accuracy: 0.8661\n",
      "Epoch 325/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3926 - accuracy: 0.8508 - val_loss: 0.3640 - val_accuracy: 0.8661\n",
      "Epoch 326/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3892 - accuracy: 0.8525 - val_loss: 0.3603 - val_accuracy: 0.8674\n",
      "Epoch 327/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3918 - accuracy: 0.8510 - val_loss: 0.3617 - val_accuracy: 0.8683\n",
      "Epoch 328/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3921 - accuracy: 0.8515 - val_loss: 0.3656 - val_accuracy: 0.8674\n",
      "Epoch 329/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3921 - accuracy: 0.8516 - val_loss: 0.3640 - val_accuracy: 0.8675\n",
      "Epoch 330/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3925 - accuracy: 0.8514 - val_loss: 0.3622 - val_accuracy: 0.8671\n",
      "Epoch 331/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3917 - accuracy: 0.8524 - val_loss: 0.3619 - val_accuracy: 0.8676\n",
      "Epoch 332/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3908 - accuracy: 0.8523 - val_loss: 0.3626 - val_accuracy: 0.8680\n",
      "Epoch 333/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3922 - accuracy: 0.8513 - val_loss: 0.3614 - val_accuracy: 0.8683\n",
      "Epoch 334/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3899 - accuracy: 0.8518 - val_loss: 0.3610 - val_accuracy: 0.8677\n",
      "Epoch 335/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3901 - accuracy: 0.8521 - val_loss: 0.3629 - val_accuracy: 0.8678\n",
      "Epoch 336/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3918 - accuracy: 0.8516 - val_loss: 0.3592 - val_accuracy: 0.8700\n",
      "Epoch 337/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3895 - accuracy: 0.8522 - val_loss: 0.3618 - val_accuracy: 0.8681\n",
      "Epoch 338/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3918 - accuracy: 0.8509 - val_loss: 0.3635 - val_accuracy: 0.8681\n",
      "Epoch 339/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3903 - accuracy: 0.8523 - val_loss: 0.3608 - val_accuracy: 0.8691\n",
      "Epoch 340/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3904 - accuracy: 0.8525 - val_loss: 0.3619 - val_accuracy: 0.8671\n",
      "Epoch 341/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3901 - accuracy: 0.8529 - val_loss: 0.3614 - val_accuracy: 0.8687\n",
      "Epoch 342/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3886 - accuracy: 0.8523 - val_loss: 0.3604 - val_accuracy: 0.8683\n",
      "Epoch 343/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3880 - accuracy: 0.8524 - val_loss: 0.3612 - val_accuracy: 0.8689\n",
      "Epoch 344/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3906 - accuracy: 0.8525 - val_loss: 0.3598 - val_accuracy: 0.8686\n",
      "Epoch 345/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3870 - accuracy: 0.8530 - val_loss: 0.3627 - val_accuracy: 0.8682\n",
      "Epoch 346/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3881 - accuracy: 0.8528 - val_loss: 0.3624 - val_accuracy: 0.8684\n",
      "Epoch 347/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3889 - accuracy: 0.8522 - val_loss: 0.3629 - val_accuracy: 0.8686\n",
      "Epoch 348/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3907 - accuracy: 0.8508 - val_loss: 0.3640 - val_accuracy: 0.8659\n",
      "Epoch 349/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3883 - accuracy: 0.8531 - val_loss: 0.3639 - val_accuracy: 0.8672\n",
      "Epoch 350/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3908 - accuracy: 0.8508 - val_loss: 0.3620 - val_accuracy: 0.8691\n",
      "Epoch 351/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3880 - accuracy: 0.8525 - val_loss: 0.3594 - val_accuracy: 0.8694\n",
      "Epoch 352/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3873 - accuracy: 0.8533 - val_loss: 0.3617 - val_accuracy: 0.8685\n",
      "Epoch 353/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3877 - accuracy: 0.8526 - val_loss: 0.3651 - val_accuracy: 0.8680\n",
      "Epoch 354/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3872 - accuracy: 0.8536 - val_loss: 0.3633 - val_accuracy: 0.8677\n",
      "Epoch 355/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3869 - accuracy: 0.8543 - val_loss: 0.3595 - val_accuracy: 0.8694\n",
      "Epoch 356/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3875 - accuracy: 0.8537 - val_loss: 0.3642 - val_accuracy: 0.8672\n",
      "Epoch 357/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3870 - accuracy: 0.8532 - val_loss: 0.3629 - val_accuracy: 0.8669\n",
      "Epoch 358/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3907 - accuracy: 0.8511 - val_loss: 0.3612 - val_accuracy: 0.8678\n",
      "Epoch 359/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3858 - accuracy: 0.8527 - val_loss: 0.3618 - val_accuracy: 0.8684\n",
      "Epoch 360/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3869 - accuracy: 0.8528 - val_loss: 0.3619 - val_accuracy: 0.8674\n",
      "Epoch 361/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3884 - accuracy: 0.8524 - val_loss: 0.3607 - val_accuracy: 0.8691\n",
      "Epoch 362/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3873 - accuracy: 0.8532 - val_loss: 0.3604 - val_accuracy: 0.8689\n",
      "Epoch 363/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3866 - accuracy: 0.8534 - val_loss: 0.3621 - val_accuracy: 0.8674\n",
      "Epoch 364/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3888 - accuracy: 0.8524 - val_loss: 0.3628 - val_accuracy: 0.8680\n",
      "Epoch 365/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3867 - accuracy: 0.8525 - val_loss: 0.3599 - val_accuracy: 0.8687\n",
      "Epoch 366/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3844 - accuracy: 0.8547 - val_loss: 0.3627 - val_accuracy: 0.8670\n",
      "Epoch 367/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3888 - accuracy: 0.8528 - val_loss: 0.3622 - val_accuracy: 0.8674\n",
      "Epoch 368/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3868 - accuracy: 0.8530 - val_loss: 0.3613 - val_accuracy: 0.8689\n",
      "Epoch 369/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3883 - accuracy: 0.8526 - val_loss: 0.3596 - val_accuracy: 0.8691\n",
      "Epoch 370/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3868 - accuracy: 0.8530 - val_loss: 0.3623 - val_accuracy: 0.8681\n",
      "Epoch 371/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3878 - accuracy: 0.8528 - val_loss: 0.3616 - val_accuracy: 0.8674\n",
      "Epoch 372/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3840 - accuracy: 0.8550 - val_loss: 0.3613 - val_accuracy: 0.8695\n",
      "Epoch 373/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3868 - accuracy: 0.8537 - val_loss: 0.3622 - val_accuracy: 0.8680\n",
      "Epoch 374/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3841 - accuracy: 0.8536 - val_loss: 0.3605 - val_accuracy: 0.8681\n",
      "Epoch 375/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3882 - accuracy: 0.8528 - val_loss: 0.3594 - val_accuracy: 0.8689\n",
      "Epoch 376/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3857 - accuracy: 0.8545 - val_loss: 0.3614 - val_accuracy: 0.8684\n",
      "Epoch 377/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3844 - accuracy: 0.8537 - val_loss: 0.3606 - val_accuracy: 0.8699\n",
      "Epoch 378/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3882 - accuracy: 0.8533 - val_loss: 0.3616 - val_accuracy: 0.8694\n",
      "Epoch 379/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3843 - accuracy: 0.8552 - val_loss: 0.3622 - val_accuracy: 0.8678\n",
      "Epoch 380/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3836 - accuracy: 0.8546 - val_loss: 0.3590 - val_accuracy: 0.8677\n",
      "Epoch 381/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3870 - accuracy: 0.8527 - val_loss: 0.3587 - val_accuracy: 0.8690\n",
      "Epoch 382/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3845 - accuracy: 0.8532 - val_loss: 0.3596 - val_accuracy: 0.8685\n",
      "Epoch 383/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3858 - accuracy: 0.8538 - val_loss: 0.3596 - val_accuracy: 0.8676\n",
      "Epoch 384/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3842 - accuracy: 0.8540 - val_loss: 0.3596 - val_accuracy: 0.8689\n",
      "Epoch 385/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3846 - accuracy: 0.8542 - val_loss: 0.3606 - val_accuracy: 0.8667\n",
      "Epoch 386/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3877 - accuracy: 0.8524 - val_loss: 0.3582 - val_accuracy: 0.8691\n",
      "Epoch 387/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3840 - accuracy: 0.8540 - val_loss: 0.3606 - val_accuracy: 0.8681\n",
      "Epoch 388/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3845 - accuracy: 0.8540 - val_loss: 0.3597 - val_accuracy: 0.8693\n",
      "Epoch 389/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8558 - val_loss: 0.3612 - val_accuracy: 0.8689\n",
      "Epoch 390/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3824 - accuracy: 0.8556 - val_loss: 0.3574 - val_accuracy: 0.8687\n",
      "Epoch 391/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3860 - accuracy: 0.8552 - val_loss: 0.3597 - val_accuracy: 0.8687\n",
      "Epoch 392/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3845 - accuracy: 0.8537 - val_loss: 0.3611 - val_accuracy: 0.8674\n",
      "Epoch 393/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3825 - accuracy: 0.8538 - val_loss: 0.3618 - val_accuracy: 0.8690\n",
      "Epoch 394/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3840 - accuracy: 0.8541 - val_loss: 0.3591 - val_accuracy: 0.8693\n",
      "Epoch 395/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3818 - accuracy: 0.8551 - val_loss: 0.3603 - val_accuracy: 0.8689\n",
      "Epoch 396/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3831 - accuracy: 0.8565 - val_loss: 0.3607 - val_accuracy: 0.8701\n",
      "Epoch 397/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3818 - accuracy: 0.8558 - val_loss: 0.3602 - val_accuracy: 0.8697\n",
      "Epoch 398/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3807 - accuracy: 0.8569 - val_loss: 0.3577 - val_accuracy: 0.8706\n",
      "Epoch 399/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3819 - accuracy: 0.8554 - val_loss: 0.3610 - val_accuracy: 0.8699\n",
      "Epoch 400/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3824 - accuracy: 0.8544 - val_loss: 0.3569 - val_accuracy: 0.8703\n",
      "Epoch 401/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3848 - accuracy: 0.8552 - val_loss: 0.3605 - val_accuracy: 0.8677\n",
      "Epoch 402/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3853 - accuracy: 0.8527 - val_loss: 0.3585 - val_accuracy: 0.8696\n",
      "Epoch 403/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3828 - accuracy: 0.8544 - val_loss: 0.3600 - val_accuracy: 0.8695\n",
      "Epoch 404/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8558 - val_loss: 0.3592 - val_accuracy: 0.8691\n",
      "Epoch 405/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3831 - accuracy: 0.8547 - val_loss: 0.3574 - val_accuracy: 0.8698\n",
      "Epoch 406/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3843 - accuracy: 0.8545 - val_loss: 0.3580 - val_accuracy: 0.8704\n",
      "Epoch 407/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3843 - accuracy: 0.8544 - val_loss: 0.3589 - val_accuracy: 0.8688\n",
      "Epoch 408/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8562 - val_loss: 0.3602 - val_accuracy: 0.8704\n",
      "Epoch 409/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3813 - accuracy: 0.8558 - val_loss: 0.3588 - val_accuracy: 0.8703\n",
      "Epoch 410/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3838 - accuracy: 0.8552 - val_loss: 0.3571 - val_accuracy: 0.8698\n",
      "Epoch 411/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3827 - accuracy: 0.8552 - val_loss: 0.3552 - val_accuracy: 0.8704\n",
      "Epoch 412/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3822 - accuracy: 0.8550 - val_loss: 0.3574 - val_accuracy: 0.8706\n",
      "Epoch 413/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3834 - accuracy: 0.8546 - val_loss: 0.3579 - val_accuracy: 0.8698\n",
      "Epoch 414/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3824 - accuracy: 0.8557 - val_loss: 0.3575 - val_accuracy: 0.8700\n",
      "Epoch 415/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3814 - accuracy: 0.8563 - val_loss: 0.3600 - val_accuracy: 0.8699\n",
      "Epoch 416/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3820 - accuracy: 0.8546 - val_loss: 0.3576 - val_accuracy: 0.8704\n",
      "Epoch 417/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8570 - val_loss: 0.3573 - val_accuracy: 0.8695\n",
      "Epoch 418/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3783 - accuracy: 0.8568 - val_loss: 0.3593 - val_accuracy: 0.8699\n",
      "Epoch 419/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3807 - accuracy: 0.8562 - val_loss: 0.3550 - val_accuracy: 0.8711\n",
      "Epoch 420/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3828 - accuracy: 0.8555 - val_loss: 0.3579 - val_accuracy: 0.8701\n",
      "Epoch 421/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3837 - accuracy: 0.8545 - val_loss: 0.3578 - val_accuracy: 0.8694\n",
      "Epoch 422/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3813 - accuracy: 0.8557 - val_loss: 0.3572 - val_accuracy: 0.8700\n",
      "Epoch 423/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3801 - accuracy: 0.8557 - val_loss: 0.3598 - val_accuracy: 0.8686\n",
      "Epoch 424/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3808 - accuracy: 0.8561 - val_loss: 0.3577 - val_accuracy: 0.8698\n",
      "Epoch 425/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3798 - accuracy: 0.8555 - val_loss: 0.3586 - val_accuracy: 0.8702\n",
      "Epoch 426/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3802 - accuracy: 0.8565 - val_loss: 0.3574 - val_accuracy: 0.8700\n",
      "Epoch 427/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3799 - accuracy: 0.8569 - val_loss: 0.3556 - val_accuracy: 0.8704\n",
      "Epoch 428/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3793 - accuracy: 0.8564 - val_loss: 0.3610 - val_accuracy: 0.8675\n",
      "Epoch 429/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3813 - accuracy: 0.8564 - val_loss: 0.3586 - val_accuracy: 0.8701\n",
      "Epoch 430/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3796 - accuracy: 0.8554 - val_loss: 0.3562 - val_accuracy: 0.8701\n",
      "Epoch 431/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3807 - accuracy: 0.8563 - val_loss: 0.3569 - val_accuracy: 0.8690\n",
      "Epoch 432/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3794 - accuracy: 0.8558 - val_loss: 0.3574 - val_accuracy: 0.8695\n",
      "Epoch 433/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3797 - accuracy: 0.8550 - val_loss: 0.3581 - val_accuracy: 0.8701\n",
      "Epoch 434/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3766 - accuracy: 0.8573 - val_loss: 0.3556 - val_accuracy: 0.8718\n",
      "Epoch 435/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3803 - accuracy: 0.8555 - val_loss: 0.3581 - val_accuracy: 0.8695\n",
      "Epoch 436/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3784 - accuracy: 0.8580 - val_loss: 0.3567 - val_accuracy: 0.8710\n",
      "Epoch 437/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3778 - accuracy: 0.8568 - val_loss: 0.3566 - val_accuracy: 0.8700\n",
      "Epoch 438/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3790 - accuracy: 0.8576 - val_loss: 0.3581 - val_accuracy: 0.8708\n",
      "Epoch 439/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8559 - val_loss: 0.3579 - val_accuracy: 0.8693\n",
      "Epoch 440/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3791 - accuracy: 0.8564 - val_loss: 0.3601 - val_accuracy: 0.8690\n",
      "Epoch 441/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.3558 - val_accuracy: 0.8693\n",
      "Epoch 442/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3825 - accuracy: 0.8545 - val_loss: 0.3549 - val_accuracy: 0.8709\n",
      "Epoch 443/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3779 - accuracy: 0.8562 - val_loss: 0.3561 - val_accuracy: 0.8710\n",
      "Epoch 444/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3780 - accuracy: 0.8561 - val_loss: 0.3580 - val_accuracy: 0.8709\n",
      "Epoch 445/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3801 - accuracy: 0.8567 - val_loss: 0.3562 - val_accuracy: 0.8705\n",
      "Epoch 446/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3787 - accuracy: 0.8567 - val_loss: 0.3550 - val_accuracy: 0.8707\n",
      "Epoch 447/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3760 - accuracy: 0.8580 - val_loss: 0.3576 - val_accuracy: 0.8706\n",
      "Epoch 448/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3790 - accuracy: 0.8557 - val_loss: 0.3555 - val_accuracy: 0.8722\n",
      "Epoch 449/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3784 - accuracy: 0.8576 - val_loss: 0.3553 - val_accuracy: 0.8720\n",
      "Epoch 450/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3791 - accuracy: 0.8557 - val_loss: 0.3607 - val_accuracy: 0.8690\n",
      "Epoch 451/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3795 - accuracy: 0.8572 - val_loss: 0.3563 - val_accuracy: 0.8707\n",
      "Epoch 452/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3782 - accuracy: 0.8573 - val_loss: 0.3551 - val_accuracy: 0.8711\n",
      "Epoch 453/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3767 - accuracy: 0.8579 - val_loss: 0.3571 - val_accuracy: 0.8698\n",
      "Epoch 454/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3782 - accuracy: 0.8572 - val_loss: 0.3568 - val_accuracy: 0.8714\n",
      "Epoch 455/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3761 - accuracy: 0.8579 - val_loss: 0.3566 - val_accuracy: 0.8708\n",
      "Epoch 456/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3802 - accuracy: 0.8568 - val_loss: 0.3546 - val_accuracy: 0.8717\n",
      "Epoch 457/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3785 - accuracy: 0.8569 - val_loss: 0.3542 - val_accuracy: 0.8711\n",
      "Epoch 458/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3752 - accuracy: 0.8581 - val_loss: 0.3549 - val_accuracy: 0.8701\n",
      "Epoch 459/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8568 - val_loss: 0.3571 - val_accuracy: 0.8703\n",
      "Epoch 460/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3777 - accuracy: 0.8564 - val_loss: 0.3555 - val_accuracy: 0.8709\n",
      "Epoch 461/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3773 - accuracy: 0.8580 - val_loss: 0.3583 - val_accuracy: 0.8699\n",
      "Epoch 462/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3777 - accuracy: 0.8582 - val_loss: 0.3545 - val_accuracy: 0.8711\n",
      "Epoch 463/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3780 - accuracy: 0.8567 - val_loss: 0.3577 - val_accuracy: 0.8702\n",
      "Epoch 464/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3767 - accuracy: 0.8573 - val_loss: 0.3573 - val_accuracy: 0.8698\n",
      "Epoch 465/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3756 - accuracy: 0.8584 - val_loss: 0.3557 - val_accuracy: 0.8712\n",
      "Epoch 466/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3776 - accuracy: 0.8570 - val_loss: 0.3542 - val_accuracy: 0.8716\n",
      "Epoch 467/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3774 - accuracy: 0.8581 - val_loss: 0.3553 - val_accuracy: 0.8725\n",
      "Epoch 468/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3780 - accuracy: 0.8577 - val_loss: 0.3578 - val_accuracy: 0.8698\n",
      "Epoch 469/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3755 - accuracy: 0.8564 - val_loss: 0.3576 - val_accuracy: 0.8701\n",
      "Epoch 470/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3766 - accuracy: 0.8573 - val_loss: 0.3534 - val_accuracy: 0.8730\n",
      "Epoch 471/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3775 - accuracy: 0.8578 - val_loss: 0.3538 - val_accuracy: 0.8728\n",
      "Epoch 472/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3745 - accuracy: 0.8581 - val_loss: 0.3528 - val_accuracy: 0.8722\n",
      "Epoch 473/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3756 - accuracy: 0.8584 - val_loss: 0.3571 - val_accuracy: 0.8714\n",
      "Epoch 474/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3747 - accuracy: 0.8578 - val_loss: 0.3580 - val_accuracy: 0.8709\n",
      "Epoch 475/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3734 - accuracy: 0.8577 - val_loss: 0.3563 - val_accuracy: 0.8710\n",
      "Epoch 476/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3755 - accuracy: 0.8584 - val_loss: 0.3533 - val_accuracy: 0.8719\n",
      "Epoch 477/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3779 - accuracy: 0.8568 - val_loss: 0.3555 - val_accuracy: 0.8710\n",
      "Epoch 478/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3770 - accuracy: 0.8572 - val_loss: 0.3539 - val_accuracy: 0.8732\n",
      "Epoch 479/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3747 - accuracy: 0.8587 - val_loss: 0.3527 - val_accuracy: 0.8726\n",
      "Epoch 480/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3746 - accuracy: 0.8586 - val_loss: 0.3544 - val_accuracy: 0.8716\n",
      "Epoch 481/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3765 - accuracy: 0.8566 - val_loss: 0.3515 - val_accuracy: 0.8727\n",
      "Epoch 482/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3764 - accuracy: 0.8579 - val_loss: 0.3541 - val_accuracy: 0.8726\n",
      "Epoch 483/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3773 - accuracy: 0.8567 - val_loss: 0.3544 - val_accuracy: 0.8711\n",
      "Epoch 484/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3740 - accuracy: 0.8581 - val_loss: 0.3547 - val_accuracy: 0.8728\n",
      "Epoch 485/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3751 - accuracy: 0.8588 - val_loss: 0.3548 - val_accuracy: 0.8719\n",
      "Epoch 486/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3744 - accuracy: 0.8580 - val_loss: 0.3551 - val_accuracy: 0.8724\n",
      "Epoch 487/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3762 - accuracy: 0.8587 - val_loss: 0.3576 - val_accuracy: 0.8702\n",
      "Epoch 488/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3752 - accuracy: 0.8586 - val_loss: 0.3550 - val_accuracy: 0.8722\n",
      "Epoch 489/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3732 - accuracy: 0.8585 - val_loss: 0.3541 - val_accuracy: 0.8721\n",
      "Epoch 490/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3740 - accuracy: 0.8581 - val_loss: 0.3536 - val_accuracy: 0.8716\n",
      "Epoch 491/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3748 - accuracy: 0.8589 - val_loss: 0.3573 - val_accuracy: 0.8712\n",
      "Epoch 492/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3740 - accuracy: 0.8585 - val_loss: 0.3540 - val_accuracy: 0.8719\n",
      "Epoch 493/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3729 - accuracy: 0.8604 - val_loss: 0.3574 - val_accuracy: 0.8709\n",
      "Epoch 494/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3751 - accuracy: 0.8588 - val_loss: 0.3539 - val_accuracy: 0.8711\n",
      "Epoch 495/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3741 - accuracy: 0.8598 - val_loss: 0.3541 - val_accuracy: 0.8716\n",
      "Epoch 496/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3771 - accuracy: 0.8571 - val_loss: 0.3524 - val_accuracy: 0.8717\n",
      "Epoch 497/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3745 - accuracy: 0.8595 - val_loss: 0.3540 - val_accuracy: 0.8716\n",
      "Epoch 498/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3729 - accuracy: 0.8596 - val_loss: 0.3525 - val_accuracy: 0.8723\n",
      "Epoch 499/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3738 - accuracy: 0.8589 - val_loss: 0.3576 - val_accuracy: 0.8705\n",
      "Epoch 500/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3753 - accuracy: 0.8579 - val_loss: 0.3538 - val_accuracy: 0.8707\n",
      "Epoch 501/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3736 - accuracy: 0.8584 - val_loss: 0.3526 - val_accuracy: 0.8724\n",
      "Epoch 502/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3712 - accuracy: 0.8601 - val_loss: 0.3560 - val_accuracy: 0.8712\n",
      "Epoch 503/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3720 - accuracy: 0.8601 - val_loss: 0.3554 - val_accuracy: 0.8706\n",
      "Epoch 504/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3724 - accuracy: 0.8604 - val_loss: 0.3528 - val_accuracy: 0.8727\n",
      "Epoch 505/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3731 - accuracy: 0.8600 - val_loss: 0.3580 - val_accuracy: 0.8707\n",
      "Epoch 506/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3746 - accuracy: 0.8588 - val_loss: 0.3562 - val_accuracy: 0.8716\n",
      "Epoch 507/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3715 - accuracy: 0.8596 - val_loss: 0.3552 - val_accuracy: 0.8713\n",
      "Epoch 508/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3740 - accuracy: 0.8588 - val_loss: 0.3562 - val_accuracy: 0.8722\n",
      "Epoch 509/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3720 - accuracy: 0.8603 - val_loss: 0.3534 - val_accuracy: 0.8720\n",
      "Epoch 510/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3739 - accuracy: 0.8587 - val_loss: 0.3527 - val_accuracy: 0.8714\n",
      "Epoch 511/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3751 - accuracy: 0.8586 - val_loss: 0.3557 - val_accuracy: 0.8716\n",
      "Epoch 512/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3748 - accuracy: 0.8585 - val_loss: 0.3536 - val_accuracy: 0.8719\n",
      "Epoch 513/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3731 - accuracy: 0.8596 - val_loss: 0.3526 - val_accuracy: 0.8721\n",
      "Epoch 514/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3738 - accuracy: 0.8600 - val_loss: 0.3530 - val_accuracy: 0.8715\n",
      "Epoch 515/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3759 - accuracy: 0.8587 - val_loss: 0.3514 - val_accuracy: 0.8720\n",
      "Epoch 516/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3697 - accuracy: 0.8609 - val_loss: 0.3528 - val_accuracy: 0.8715\n",
      "Epoch 517/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3732 - accuracy: 0.8584 - val_loss: 0.3542 - val_accuracy: 0.8721\n",
      "Epoch 518/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3751 - accuracy: 0.8581 - val_loss: 0.3530 - val_accuracy: 0.8727\n",
      "Epoch 519/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3714 - accuracy: 0.8596 - val_loss: 0.3548 - val_accuracy: 0.8719\n",
      "Epoch 520/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3702 - accuracy: 0.8602 - val_loss: 0.3557 - val_accuracy: 0.8725\n",
      "Epoch 521/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3717 - accuracy: 0.8601 - val_loss: 0.3559 - val_accuracy: 0.8705\n",
      "Epoch 522/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3729 - accuracy: 0.8604 - val_loss: 0.3534 - val_accuracy: 0.8721\n",
      "Epoch 523/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3713 - accuracy: 0.8598 - val_loss: 0.3540 - val_accuracy: 0.8716\n",
      "Epoch 524/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3756 - accuracy: 0.8582 - val_loss: 0.3526 - val_accuracy: 0.8716\n",
      "Epoch 525/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3712 - accuracy: 0.8590 - val_loss: 0.3533 - val_accuracy: 0.8724\n",
      "Epoch 526/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3739 - accuracy: 0.8580 - val_loss: 0.3545 - val_accuracy: 0.8722\n",
      "Epoch 527/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3722 - accuracy: 0.8585 - val_loss: 0.3515 - val_accuracy: 0.8717\n",
      "Epoch 528/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3711 - accuracy: 0.8604 - val_loss: 0.3556 - val_accuracy: 0.8704\n",
      "Epoch 529/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3728 - accuracy: 0.8592 - val_loss: 0.3565 - val_accuracy: 0.8709\n",
      "Epoch 530/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3717 - accuracy: 0.8605 - val_loss: 0.3521 - val_accuracy: 0.8715\n",
      "Epoch 531/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3701 - accuracy: 0.8606 - val_loss: 0.3518 - val_accuracy: 0.8722\n",
      "Epoch 532/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3722 - accuracy: 0.8598 - val_loss: 0.3534 - val_accuracy: 0.8713\n",
      "Epoch 533/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3715 - accuracy: 0.8602 - val_loss: 0.3549 - val_accuracy: 0.8710\n",
      "Epoch 534/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3703 - accuracy: 0.8613 - val_loss: 0.3548 - val_accuracy: 0.8709\n",
      "Epoch 535/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3702 - accuracy: 0.8603 - val_loss: 0.3514 - val_accuracy: 0.8724\n",
      "Epoch 536/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3713 - accuracy: 0.8607 - val_loss: 0.3532 - val_accuracy: 0.8724\n",
      "Epoch 537/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3715 - accuracy: 0.8597 - val_loss: 0.3514 - val_accuracy: 0.8724\n",
      "Epoch 538/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3717 - accuracy: 0.8587 - val_loss: 0.3539 - val_accuracy: 0.8703\n",
      "Epoch 539/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3717 - accuracy: 0.8595 - val_loss: 0.3498 - val_accuracy: 0.8730\n",
      "Epoch 540/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3719 - accuracy: 0.8596 - val_loss: 0.3515 - val_accuracy: 0.8715\n",
      "Epoch 541/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3714 - accuracy: 0.8590 - val_loss: 0.3536 - val_accuracy: 0.8727\n",
      "Epoch 542/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3721 - accuracy: 0.8586 - val_loss: 0.3519 - val_accuracy: 0.8723\n",
      "Epoch 543/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3713 - accuracy: 0.8600 - val_loss: 0.3546 - val_accuracy: 0.8709\n",
      "Epoch 544/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3701 - accuracy: 0.8598 - val_loss: 0.3531 - val_accuracy: 0.8728\n",
      "Epoch 545/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3701 - accuracy: 0.8607 - val_loss: 0.3527 - val_accuracy: 0.8732\n",
      "Epoch 546/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3707 - accuracy: 0.8602 - val_loss: 0.3529 - val_accuracy: 0.8721\n",
      "Epoch 547/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3705 - accuracy: 0.8608 - val_loss: 0.3529 - val_accuracy: 0.8712\n",
      "Epoch 548/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3706 - accuracy: 0.8594 - val_loss: 0.3501 - val_accuracy: 0.8729\n",
      "Epoch 549/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3704 - accuracy: 0.8609 - val_loss: 0.3506 - val_accuracy: 0.8726\n",
      "Epoch 550/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3719 - accuracy: 0.8606 - val_loss: 0.3483 - val_accuracy: 0.8731\n",
      "Epoch 551/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3668 - accuracy: 0.8610 - val_loss: 0.3519 - val_accuracy: 0.8721\n",
      "Epoch 552/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3686 - accuracy: 0.8608 - val_loss: 0.3537 - val_accuracy: 0.8716\n",
      "Epoch 553/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3722 - accuracy: 0.8594 - val_loss: 0.3507 - val_accuracy: 0.8718\n",
      "Epoch 554/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3697 - accuracy: 0.8602 - val_loss: 0.3511 - val_accuracy: 0.8727\n",
      "Epoch 555/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3717 - accuracy: 0.8599 - val_loss: 0.3532 - val_accuracy: 0.8719\n",
      "Epoch 556/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3670 - accuracy: 0.8613 - val_loss: 0.3550 - val_accuracy: 0.8712\n",
      "Epoch 557/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3724 - accuracy: 0.8589 - val_loss: 0.3507 - val_accuracy: 0.8736\n",
      "Epoch 558/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3695 - accuracy: 0.8600 - val_loss: 0.3520 - val_accuracy: 0.8732\n",
      "Epoch 559/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3686 - accuracy: 0.8612 - val_loss: 0.3513 - val_accuracy: 0.8724\n",
      "Epoch 560/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3708 - accuracy: 0.8606 - val_loss: 0.3522 - val_accuracy: 0.8731\n",
      "Epoch 561/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.8615 - val_loss: 0.3499 - val_accuracy: 0.8724\n",
      "Epoch 562/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3685 - accuracy: 0.8620 - val_loss: 0.3519 - val_accuracy: 0.8726\n",
      "Epoch 563/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3698 - accuracy: 0.8622 - val_loss: 0.3523 - val_accuracy: 0.8721\n",
      "Epoch 564/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3690 - accuracy: 0.8601 - val_loss: 0.3530 - val_accuracy: 0.8729\n",
      "Epoch 565/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3687 - accuracy: 0.8609 - val_loss: 0.3493 - val_accuracy: 0.8729\n",
      "Epoch 566/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3705 - accuracy: 0.8597 - val_loss: 0.3524 - val_accuracy: 0.8728\n",
      "Epoch 567/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3696 - accuracy: 0.8598 - val_loss: 0.3514 - val_accuracy: 0.8736\n",
      "Epoch 568/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3667 - accuracy: 0.8622 - val_loss: 0.3509 - val_accuracy: 0.8736\n",
      "Epoch 569/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3715 - accuracy: 0.8608 - val_loss: 0.3517 - val_accuracy: 0.8732\n",
      "Epoch 570/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3691 - accuracy: 0.8609 - val_loss: 0.3504 - val_accuracy: 0.8721\n",
      "Epoch 571/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3682 - accuracy: 0.8611 - val_loss: 0.3513 - val_accuracy: 0.8738\n",
      "Epoch 572/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3708 - accuracy: 0.8606 - val_loss: 0.3491 - val_accuracy: 0.8738\n",
      "Epoch 573/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3716 - accuracy: 0.8597 - val_loss: 0.3519 - val_accuracy: 0.8746\n",
      "Epoch 574/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3679 - accuracy: 0.8614 - val_loss: 0.3505 - val_accuracy: 0.8725\n",
      "Epoch 575/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3707 - accuracy: 0.8602 - val_loss: 0.3505 - val_accuracy: 0.8732\n",
      "Epoch 576/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3689 - accuracy: 0.8610 - val_loss: 0.3530 - val_accuracy: 0.8724\n",
      "Epoch 577/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3679 - accuracy: 0.8607 - val_loss: 0.3520 - val_accuracy: 0.8726\n",
      "Epoch 578/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3681 - accuracy: 0.8616 - val_loss: 0.3495 - val_accuracy: 0.8743\n",
      "Epoch 579/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3670 - accuracy: 0.8608 - val_loss: 0.3507 - val_accuracy: 0.8717\n",
      "Epoch 580/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8618 - val_loss: 0.3530 - val_accuracy: 0.8723\n",
      "Epoch 581/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3692 - accuracy: 0.8606 - val_loss: 0.3494 - val_accuracy: 0.8734\n",
      "Epoch 582/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3660 - accuracy: 0.8630 - val_loss: 0.3504 - val_accuracy: 0.8728\n",
      "Epoch 583/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3715 - accuracy: 0.8596 - val_loss: 0.3519 - val_accuracy: 0.8720\n",
      "Epoch 584/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8610 - val_loss: 0.3510 - val_accuracy: 0.8730\n",
      "Epoch 585/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3664 - accuracy: 0.8625 - val_loss: 0.3516 - val_accuracy: 0.8724\n",
      "Epoch 586/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3667 - accuracy: 0.8617 - val_loss: 0.3489 - val_accuracy: 0.8739\n",
      "Epoch 587/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3651 - accuracy: 0.8619 - val_loss: 0.3508 - val_accuracy: 0.8736\n",
      "Epoch 588/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3648 - accuracy: 0.8618 - val_loss: 0.3507 - val_accuracy: 0.8726\n",
      "Epoch 589/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3660 - accuracy: 0.8618 - val_loss: 0.3506 - val_accuracy: 0.8726\n",
      "Epoch 590/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3668 - accuracy: 0.8616 - val_loss: 0.3499 - val_accuracy: 0.8733\n",
      "Epoch 591/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3663 - accuracy: 0.8623 - val_loss: 0.3491 - val_accuracy: 0.8734\n",
      "Epoch 592/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3656 - accuracy: 0.8626 - val_loss: 0.3537 - val_accuracy: 0.8715\n",
      "Epoch 593/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3686 - accuracy: 0.8605 - val_loss: 0.3510 - val_accuracy: 0.8724\n",
      "Epoch 594/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3666 - accuracy: 0.8618 - val_loss: 0.3526 - val_accuracy: 0.8716\n",
      "Epoch 595/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3684 - accuracy: 0.8603 - val_loss: 0.3514 - val_accuracy: 0.8719\n",
      "Epoch 596/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3659 - accuracy: 0.8627 - val_loss: 0.3510 - val_accuracy: 0.8724\n",
      "Epoch 597/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3699 - accuracy: 0.8603 - val_loss: 0.3501 - val_accuracy: 0.8742\n",
      "Epoch 598/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3673 - accuracy: 0.8618 - val_loss: 0.3539 - val_accuracy: 0.8721\n",
      "Epoch 599/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3678 - accuracy: 0.8600 - val_loss: 0.3509 - val_accuracy: 0.8736\n",
      "Epoch 600/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3662 - accuracy: 0.8626 - val_loss: 0.3484 - val_accuracy: 0.8731\n",
      "Epoch 601/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3667 - accuracy: 0.8615 - val_loss: 0.3506 - val_accuracy: 0.8731\n",
      "Epoch 602/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3660 - accuracy: 0.8625 - val_loss: 0.3535 - val_accuracy: 0.8730\n",
      "Epoch 603/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3703 - accuracy: 0.8612 - val_loss: 0.3533 - val_accuracy: 0.8741\n",
      "Epoch 604/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3669 - accuracy: 0.8606 - val_loss: 0.3507 - val_accuracy: 0.8731\n",
      "Epoch 605/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3664 - accuracy: 0.8620 - val_loss: 0.3509 - val_accuracy: 0.8734\n",
      "Epoch 606/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3668 - accuracy: 0.8630 - val_loss: 0.3495 - val_accuracy: 0.8749\n",
      "Epoch 607/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3649 - accuracy: 0.8636 - val_loss: 0.3480 - val_accuracy: 0.8748\n",
      "Epoch 608/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3675 - accuracy: 0.8615 - val_loss: 0.3507 - val_accuracy: 0.8730\n",
      "Epoch 609/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3644 - accuracy: 0.8634 - val_loss: 0.3495 - val_accuracy: 0.8751\n",
      "Epoch 610/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3669 - accuracy: 0.8612 - val_loss: 0.3486 - val_accuracy: 0.8737\n",
      "Epoch 611/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3683 - accuracy: 0.8610 - val_loss: 0.3489 - val_accuracy: 0.8732\n",
      "Epoch 612/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3681 - accuracy: 0.8611 - val_loss: 0.3475 - val_accuracy: 0.8741\n",
      "Epoch 613/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8619 - val_loss: 0.3508 - val_accuracy: 0.8742\n",
      "Epoch 614/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3673 - accuracy: 0.8620 - val_loss: 0.3500 - val_accuracy: 0.8731\n",
      "Epoch 615/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3644 - accuracy: 0.8627 - val_loss: 0.3499 - val_accuracy: 0.8745\n",
      "Epoch 616/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3666 - accuracy: 0.8623 - val_loss: 0.3493 - val_accuracy: 0.8744\n",
      "Epoch 617/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8624 - val_loss: 0.3496 - val_accuracy: 0.8723\n",
      "Epoch 618/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3648 - accuracy: 0.8632 - val_loss: 0.3491 - val_accuracy: 0.8736\n",
      "Epoch 619/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3662 - accuracy: 0.8623 - val_loss: 0.3490 - val_accuracy: 0.8746\n",
      "Epoch 620/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3656 - accuracy: 0.8623 - val_loss: 0.3477 - val_accuracy: 0.8738\n",
      "Epoch 621/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3645 - accuracy: 0.8614 - val_loss: 0.3501 - val_accuracy: 0.8734\n",
      "Epoch 622/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3663 - accuracy: 0.8624 - val_loss: 0.3493 - val_accuracy: 0.8718\n",
      "Epoch 623/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3645 - accuracy: 0.8628 - val_loss: 0.3491 - val_accuracy: 0.8729\n",
      "Epoch 624/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3656 - accuracy: 0.8624 - val_loss: 0.3487 - val_accuracy: 0.8732\n",
      "Epoch 625/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3645 - accuracy: 0.8623 - val_loss: 0.3494 - val_accuracy: 0.8735\n",
      "Epoch 626/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3661 - accuracy: 0.8610 - val_loss: 0.3500 - val_accuracy: 0.8733\n",
      "Epoch 627/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3644 - accuracy: 0.8628 - val_loss: 0.3513 - val_accuracy: 0.8733\n",
      "Epoch 628/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3663 - accuracy: 0.8621 - val_loss: 0.3499 - val_accuracy: 0.8741\n",
      "Epoch 629/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3666 - accuracy: 0.8618 - val_loss: 0.3481 - val_accuracy: 0.8737\n",
      "Epoch 630/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3634 - accuracy: 0.8635 - val_loss: 0.3532 - val_accuracy: 0.8718\n",
      "Epoch 631/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3659 - accuracy: 0.8624 - val_loss: 0.3519 - val_accuracy: 0.8732\n",
      "Epoch 632/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3654 - accuracy: 0.8634 - val_loss: 0.3487 - val_accuracy: 0.8737\n",
      "Epoch 633/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3656 - accuracy: 0.8619 - val_loss: 0.3498 - val_accuracy: 0.8741\n",
      "Epoch 634/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3651 - accuracy: 0.8622 - val_loss: 0.3484 - val_accuracy: 0.8747\n",
      "Epoch 635/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3640 - accuracy: 0.8629 - val_loss: 0.3513 - val_accuracy: 0.8722\n",
      "Epoch 636/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3652 - accuracy: 0.8615 - val_loss: 0.3500 - val_accuracy: 0.8736\n",
      "Epoch 637/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3643 - accuracy: 0.8621 - val_loss: 0.3483 - val_accuracy: 0.8749\n",
      "Epoch 638/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3625 - accuracy: 0.8628 - val_loss: 0.3487 - val_accuracy: 0.8746\n",
      "Epoch 639/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3642 - accuracy: 0.8627 - val_loss: 0.3514 - val_accuracy: 0.8742\n",
      "Epoch 640/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3667 - accuracy: 0.8618 - val_loss: 0.3508 - val_accuracy: 0.8725\n",
      "Epoch 641/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3653 - accuracy: 0.8622 - val_loss: 0.3491 - val_accuracy: 0.8727\n",
      "Epoch 642/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3644 - accuracy: 0.8623 - val_loss: 0.3515 - val_accuracy: 0.8731\n",
      "Epoch 643/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3636 - accuracy: 0.8627 - val_loss: 0.3510 - val_accuracy: 0.8731\n",
      "Epoch 644/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3643 - accuracy: 0.8624 - val_loss: 0.3481 - val_accuracy: 0.8728\n",
      "Epoch 645/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3643 - accuracy: 0.8630 - val_loss: 0.3480 - val_accuracy: 0.8738\n",
      "Epoch 646/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3648 - accuracy: 0.8628 - val_loss: 0.3510 - val_accuracy: 0.8743\n",
      "Epoch 647/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3646 - accuracy: 0.8625 - val_loss: 0.3497 - val_accuracy: 0.8736\n",
      "Epoch 648/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3631 - accuracy: 0.8636 - val_loss: 0.3479 - val_accuracy: 0.8738\n",
      "Epoch 649/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3643 - accuracy: 0.8626 - val_loss: 0.3532 - val_accuracy: 0.8731\n",
      "Epoch 650/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3644 - accuracy: 0.8634 - val_loss: 0.3496 - val_accuracy: 0.8740\n",
      "Epoch 651/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3632 - accuracy: 0.8629 - val_loss: 0.3496 - val_accuracy: 0.8736\n",
      "Epoch 652/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3613 - accuracy: 0.8637 - val_loss: 0.3509 - val_accuracy: 0.8728\n",
      "Epoch 653/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3639 - accuracy: 0.8634 - val_loss: 0.3488 - val_accuracy: 0.8741\n",
      "Epoch 654/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3633 - accuracy: 0.8632 - val_loss: 0.3486 - val_accuracy: 0.8736\n",
      "Epoch 655/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3637 - accuracy: 0.8630 - val_loss: 0.3467 - val_accuracy: 0.8739\n",
      "Epoch 656/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3622 - accuracy: 0.8638 - val_loss: 0.3511 - val_accuracy: 0.8738\n",
      "Epoch 657/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3626 - accuracy: 0.8628 - val_loss: 0.3510 - val_accuracy: 0.8726\n",
      "Epoch 658/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3655 - accuracy: 0.8626 - val_loss: 0.3527 - val_accuracy: 0.8720\n",
      "Epoch 659/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3635 - accuracy: 0.8628 - val_loss: 0.3518 - val_accuracy: 0.8729\n",
      "Epoch 660/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3663 - accuracy: 0.8623 - val_loss: 0.3513 - val_accuracy: 0.8719\n",
      "Epoch 661/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3646 - accuracy: 0.8613 - val_loss: 0.3524 - val_accuracy: 0.8719\n",
      "Epoch 662/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3631 - accuracy: 0.8637 - val_loss: 0.3505 - val_accuracy: 0.8744\n",
      "Epoch 663/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3648 - accuracy: 0.8629 - val_loss: 0.3473 - val_accuracy: 0.8738\n",
      "Epoch 664/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3640 - accuracy: 0.8626 - val_loss: 0.3489 - val_accuracy: 0.8741\n",
      "Epoch 665/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3628 - accuracy: 0.8633 - val_loss: 0.3487 - val_accuracy: 0.8745\n",
      "Epoch 666/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3657 - accuracy: 0.8615 - val_loss: 0.3509 - val_accuracy: 0.8731\n",
      "Epoch 667/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3631 - accuracy: 0.8633 - val_loss: 0.3492 - val_accuracy: 0.8724\n",
      "Epoch 668/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3612 - accuracy: 0.8635 - val_loss: 0.3507 - val_accuracy: 0.8724\n",
      "Epoch 669/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3641 - accuracy: 0.8629 - val_loss: 0.3507 - val_accuracy: 0.8728\n",
      "Epoch 670/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3639 - accuracy: 0.8632 - val_loss: 0.3466 - val_accuracy: 0.8744\n",
      "Epoch 671/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3657 - accuracy: 0.8623 - val_loss: 0.3531 - val_accuracy: 0.8722\n",
      "Epoch 672/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3620 - accuracy: 0.8643 - val_loss: 0.3530 - val_accuracy: 0.8728\n",
      "Epoch 673/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3600 - accuracy: 0.8647 - val_loss: 0.3527 - val_accuracy: 0.8731\n",
      "Epoch 674/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3637 - accuracy: 0.8629 - val_loss: 0.3486 - val_accuracy: 0.8739\n",
      "Epoch 675/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3632 - accuracy: 0.8621 - val_loss: 0.3501 - val_accuracy: 0.8727\n",
      "Epoch 676/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3617 - accuracy: 0.8636 - val_loss: 0.3461 - val_accuracy: 0.8740\n",
      "Epoch 677/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3635 - accuracy: 0.8619 - val_loss: 0.3500 - val_accuracy: 0.8741\n",
      "Epoch 678/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3630 - accuracy: 0.8630 - val_loss: 0.3466 - val_accuracy: 0.8740\n",
      "Epoch 679/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3611 - accuracy: 0.8638 - val_loss: 0.3477 - val_accuracy: 0.8741\n",
      "Epoch 680/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3608 - accuracy: 0.8648 - val_loss: 0.3508 - val_accuracy: 0.8743\n",
      "Epoch 681/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3639 - accuracy: 0.8634 - val_loss: 0.3491 - val_accuracy: 0.8736\n",
      "Epoch 682/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3641 - accuracy: 0.8632 - val_loss: 0.3507 - val_accuracy: 0.8731\n",
      "Epoch 683/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3616 - accuracy: 0.8632 - val_loss: 0.3495 - val_accuracy: 0.8736\n",
      "Epoch 684/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3616 - accuracy: 0.8638 - val_loss: 0.3511 - val_accuracy: 0.8740\n",
      "Epoch 685/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3602 - accuracy: 0.8645 - val_loss: 0.3496 - val_accuracy: 0.8736\n",
      "Epoch 686/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3630 - accuracy: 0.8629 - val_loss: 0.3480 - val_accuracy: 0.8730\n",
      "Epoch 687/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3617 - accuracy: 0.8638 - val_loss: 0.3471 - val_accuracy: 0.8745\n",
      "Epoch 688/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3606 - accuracy: 0.8645 - val_loss: 0.3478 - val_accuracy: 0.8740\n",
      "Epoch 689/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3630 - accuracy: 0.8636 - val_loss: 0.3487 - val_accuracy: 0.8734\n",
      "Epoch 690/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3633 - accuracy: 0.8631 - val_loss: 0.3514 - val_accuracy: 0.8722\n",
      "Epoch 691/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3619 - accuracy: 0.8650 - val_loss: 0.3476 - val_accuracy: 0.8736\n",
      "Epoch 692/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3625 - accuracy: 0.8636 - val_loss: 0.3492 - val_accuracy: 0.8737\n",
      "Epoch 693/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3602 - accuracy: 0.8648 - val_loss: 0.3489 - val_accuracy: 0.8752\n",
      "Epoch 694/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3604 - accuracy: 0.8641 - val_loss: 0.3493 - val_accuracy: 0.8725\n",
      "Epoch 695/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3609 - accuracy: 0.8649 - val_loss: 0.3477 - val_accuracy: 0.8731\n",
      "Epoch 696/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3626 - accuracy: 0.8633 - val_loss: 0.3515 - val_accuracy: 0.8730\n",
      "Epoch 697/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3615 - accuracy: 0.8639 - val_loss: 0.3529 - val_accuracy: 0.8722\n",
      "Epoch 698/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3634 - accuracy: 0.8628 - val_loss: 0.3504 - val_accuracy: 0.8744\n",
      "Epoch 699/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3627 - accuracy: 0.8628 - val_loss: 0.3460 - val_accuracy: 0.8743\n",
      "Epoch 700/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3607 - accuracy: 0.8641 - val_loss: 0.3487 - val_accuracy: 0.8742\n",
      "Epoch 701/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3617 - accuracy: 0.8638 - val_loss: 0.3447 - val_accuracy: 0.8742\n",
      "Epoch 702/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3596 - accuracy: 0.8652 - val_loss: 0.3467 - val_accuracy: 0.8733\n",
      "Epoch 703/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3618 - accuracy: 0.8630 - val_loss: 0.3477 - val_accuracy: 0.8751\n",
      "Epoch 704/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3588 - accuracy: 0.8642 - val_loss: 0.3511 - val_accuracy: 0.8736\n",
      "Epoch 705/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3605 - accuracy: 0.8644 - val_loss: 0.3496 - val_accuracy: 0.8743\n",
      "Epoch 706/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3593 - accuracy: 0.8648 - val_loss: 0.3492 - val_accuracy: 0.8749\n",
      "Epoch 707/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3594 - accuracy: 0.8656 - val_loss: 0.3504 - val_accuracy: 0.8742\n",
      "Epoch 708/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3593 - accuracy: 0.8648 - val_loss: 0.3467 - val_accuracy: 0.8742\n",
      "Epoch 709/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3610 - accuracy: 0.8648 - val_loss: 0.3478 - val_accuracy: 0.8747\n",
      "Epoch 710/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3619 - accuracy: 0.8629 - val_loss: 0.3521 - val_accuracy: 0.8737\n",
      "Epoch 711/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3616 - accuracy: 0.8642 - val_loss: 0.3502 - val_accuracy: 0.8749\n",
      "Epoch 712/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3622 - accuracy: 0.8642 - val_loss: 0.3468 - val_accuracy: 0.8756\n",
      "Epoch 713/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3602 - accuracy: 0.8640 - val_loss: 0.3480 - val_accuracy: 0.8737\n",
      "Epoch 714/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3590 - accuracy: 0.8642 - val_loss: 0.3521 - val_accuracy: 0.8733\n",
      "Epoch 715/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3609 - accuracy: 0.8641 - val_loss: 0.3460 - val_accuracy: 0.8754\n",
      "Epoch 716/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3607 - accuracy: 0.8645 - val_loss: 0.3480 - val_accuracy: 0.8749\n",
      "Epoch 717/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3602 - accuracy: 0.8653 - val_loss: 0.3496 - val_accuracy: 0.8746\n",
      "Epoch 718/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3606 - accuracy: 0.8648 - val_loss: 0.3477 - val_accuracy: 0.8757\n",
      "Epoch 719/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3614 - accuracy: 0.8630 - val_loss: 0.3481 - val_accuracy: 0.8763\n",
      "Epoch 720/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3637 - accuracy: 0.8636 - val_loss: 0.3466 - val_accuracy: 0.8750\n",
      "Epoch 721/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3592 - accuracy: 0.8647 - val_loss: 0.3484 - val_accuracy: 0.8756\n",
      "Epoch 722/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3591 - accuracy: 0.8639 - val_loss: 0.3503 - val_accuracy: 0.8747\n",
      "Epoch 723/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3586 - accuracy: 0.8639 - val_loss: 0.3487 - val_accuracy: 0.8748\n",
      "Epoch 724/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3607 - accuracy: 0.8641 - val_loss: 0.3487 - val_accuracy: 0.8753\n",
      "Epoch 725/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3593 - accuracy: 0.8637 - val_loss: 0.3486 - val_accuracy: 0.8748\n",
      "Epoch 726/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3594 - accuracy: 0.8637 - val_loss: 0.3509 - val_accuracy: 0.8744\n",
      "Epoch 727/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3597 - accuracy: 0.8641 - val_loss: 0.3512 - val_accuracy: 0.8735\n",
      "Epoch 728/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3607 - accuracy: 0.8637 - val_loss: 0.3470 - val_accuracy: 0.8750\n",
      "Epoch 729/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3611 - accuracy: 0.8646 - val_loss: 0.3473 - val_accuracy: 0.8754\n",
      "Epoch 730/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3571 - accuracy: 0.8657 - val_loss: 0.3477 - val_accuracy: 0.8733\n",
      "Epoch 731/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3618 - accuracy: 0.8637 - val_loss: 0.3499 - val_accuracy: 0.8734\n",
      "Epoch 732/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3601 - accuracy: 0.8639 - val_loss: 0.3504 - val_accuracy: 0.8749\n",
      "Epoch 733/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3585 - accuracy: 0.8663 - val_loss: 0.3465 - val_accuracy: 0.8749\n",
      "Epoch 734/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3610 - accuracy: 0.8642 - val_loss: 0.3487 - val_accuracy: 0.8754\n",
      "Epoch 735/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3581 - accuracy: 0.8660 - val_loss: 0.3466 - val_accuracy: 0.8759\n",
      "Epoch 736/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3624 - accuracy: 0.8634 - val_loss: 0.3484 - val_accuracy: 0.8758\n",
      "Epoch 737/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3604 - accuracy: 0.8648 - val_loss: 0.3508 - val_accuracy: 0.8744\n",
      "Epoch 738/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3601 - accuracy: 0.8640 - val_loss: 0.3474 - val_accuracy: 0.8756\n",
      "Epoch 739/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3590 - accuracy: 0.8638 - val_loss: 0.3483 - val_accuracy: 0.8748\n",
      "Epoch 740/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3604 - accuracy: 0.8639 - val_loss: 0.3462 - val_accuracy: 0.8751\n",
      "Epoch 741/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3609 - accuracy: 0.8644 - val_loss: 0.3483 - val_accuracy: 0.8732\n",
      "Epoch 742/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3579 - accuracy: 0.8644 - val_loss: 0.3484 - val_accuracy: 0.8742\n",
      "Epoch 743/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3625 - accuracy: 0.8623 - val_loss: 0.3482 - val_accuracy: 0.8749\n",
      "Epoch 744/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3616 - accuracy: 0.8633 - val_loss: 0.3478 - val_accuracy: 0.8761\n",
      "Epoch 745/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3585 - accuracy: 0.8655 - val_loss: 0.3488 - val_accuracy: 0.8755\n",
      "Epoch 746/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3592 - accuracy: 0.8649 - val_loss: 0.3475 - val_accuracy: 0.8760\n",
      "Epoch 747/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3605 - accuracy: 0.8646 - val_loss: 0.3471 - val_accuracy: 0.8751\n",
      "Epoch 748/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3602 - accuracy: 0.8648 - val_loss: 0.3481 - val_accuracy: 0.8765\n",
      "Epoch 749/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3582 - accuracy: 0.8650 - val_loss: 0.3491 - val_accuracy: 0.8758\n",
      "Epoch 750/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3597 - accuracy: 0.8642 - val_loss: 0.3493 - val_accuracy: 0.8739\n",
      "Epoch 751/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3593 - accuracy: 0.8643 - val_loss: 0.3508 - val_accuracy: 0.8763\n",
      "Epoch 752/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3591 - accuracy: 0.8652 - val_loss: 0.3454 - val_accuracy: 0.8764\n",
      "Epoch 753/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3570 - accuracy: 0.8653 - val_loss: 0.3483 - val_accuracy: 0.8748\n",
      "Epoch 754/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3588 - accuracy: 0.8653 - val_loss: 0.3473 - val_accuracy: 0.8742\n",
      "Epoch 755/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3571 - accuracy: 0.8657 - val_loss: 0.3478 - val_accuracy: 0.8740\n",
      "Epoch 756/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3596 - accuracy: 0.8656 - val_loss: 0.3492 - val_accuracy: 0.8734\n",
      "Epoch 757/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3590 - accuracy: 0.8644 - val_loss: 0.3470 - val_accuracy: 0.8753\n",
      "Epoch 758/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3591 - accuracy: 0.8648 - val_loss: 0.3491 - val_accuracy: 0.8750\n",
      "Epoch 759/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3589 - accuracy: 0.8647 - val_loss: 0.3465 - val_accuracy: 0.8751\n",
      "Epoch 760/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3578 - accuracy: 0.8647 - val_loss: 0.3479 - val_accuracy: 0.8753\n",
      "Epoch 761/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3583 - accuracy: 0.8650 - val_loss: 0.3478 - val_accuracy: 0.8753\n",
      "Epoch 762/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3574 - accuracy: 0.8661 - val_loss: 0.3483 - val_accuracy: 0.8749\n",
      "Epoch 763/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3589 - accuracy: 0.8650 - val_loss: 0.3464 - val_accuracy: 0.8743\n",
      "Epoch 764/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3573 - accuracy: 0.8648 - val_loss: 0.3478 - val_accuracy: 0.8740\n",
      "Epoch 765/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3575 - accuracy: 0.8658 - val_loss: 0.3488 - val_accuracy: 0.8744\n",
      "Epoch 766/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3569 - accuracy: 0.8653 - val_loss: 0.3480 - val_accuracy: 0.8758\n",
      "Epoch 767/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3577 - accuracy: 0.8652 - val_loss: 0.3470 - val_accuracy: 0.8736\n",
      "Epoch 768/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3576 - accuracy: 0.8654 - val_loss: 0.3491 - val_accuracy: 0.8741\n",
      "Epoch 769/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3589 - accuracy: 0.8653 - val_loss: 0.3471 - val_accuracy: 0.8758\n",
      "Epoch 770/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3592 - accuracy: 0.8649 - val_loss: 0.3462 - val_accuracy: 0.8751\n",
      "Epoch 771/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3582 - accuracy: 0.8642 - val_loss: 0.3461 - val_accuracy: 0.8761\n",
      "Epoch 772/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3582 - accuracy: 0.8651 - val_loss: 0.3455 - val_accuracy: 0.8745\n",
      "Epoch 773/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3578 - accuracy: 0.8655 - val_loss: 0.3464 - val_accuracy: 0.8748\n",
      "Epoch 774/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3586 - accuracy: 0.8655 - val_loss: 0.3452 - val_accuracy: 0.8751\n",
      "Epoch 775/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3598 - accuracy: 0.8651 - val_loss: 0.3479 - val_accuracy: 0.8742\n",
      "Epoch 776/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3576 - accuracy: 0.8655 - val_loss: 0.3510 - val_accuracy: 0.8751\n",
      "Epoch 777/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3579 - accuracy: 0.8655 - val_loss: 0.3459 - val_accuracy: 0.8751\n",
      "Epoch 778/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3568 - accuracy: 0.8662 - val_loss: 0.3457 - val_accuracy: 0.8757\n",
      "Epoch 779/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3584 - accuracy: 0.8649 - val_loss: 0.3476 - val_accuracy: 0.8738\n",
      "Epoch 780/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3601 - accuracy: 0.8644 - val_loss: 0.3456 - val_accuracy: 0.8748\n",
      "Epoch 781/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3567 - accuracy: 0.8654 - val_loss: 0.3459 - val_accuracy: 0.8755\n",
      "Epoch 782/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3570 - accuracy: 0.8656 - val_loss: 0.3477 - val_accuracy: 0.8759\n",
      "Epoch 783/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3573 - accuracy: 0.8654 - val_loss: 0.3470 - val_accuracy: 0.8746\n",
      "Epoch 784/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3587 - accuracy: 0.8667 - val_loss: 0.3479 - val_accuracy: 0.8743\n",
      "Epoch 785/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3582 - accuracy: 0.8657 - val_loss: 0.3459 - val_accuracy: 0.8757\n",
      "Epoch 786/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3597 - accuracy: 0.8649 - val_loss: 0.3473 - val_accuracy: 0.8743\n",
      "Epoch 787/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3576 - accuracy: 0.8652 - val_loss: 0.3450 - val_accuracy: 0.8761\n",
      "Epoch 788/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3575 - accuracy: 0.8650 - val_loss: 0.3452 - val_accuracy: 0.8756\n",
      "Epoch 789/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3573 - accuracy: 0.8645 - val_loss: 0.3468 - val_accuracy: 0.8737\n",
      "Epoch 790/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3557 - accuracy: 0.8656 - val_loss: 0.3469 - val_accuracy: 0.8742\n",
      "Epoch 791/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3551 - accuracy: 0.8662 - val_loss: 0.3461 - val_accuracy: 0.8736\n",
      "Epoch 792/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3574 - accuracy: 0.8650 - val_loss: 0.3490 - val_accuracy: 0.8749\n",
      "Epoch 793/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3568 - accuracy: 0.8652 - val_loss: 0.3444 - val_accuracy: 0.8753\n",
      "Epoch 794/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3580 - accuracy: 0.8649 - val_loss: 0.3474 - val_accuracy: 0.8750\n",
      "Epoch 795/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3581 - accuracy: 0.8660 - val_loss: 0.3495 - val_accuracy: 0.8751\n",
      "Epoch 796/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3595 - accuracy: 0.8651 - val_loss: 0.3447 - val_accuracy: 0.8741\n",
      "Epoch 797/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3572 - accuracy: 0.8661 - val_loss: 0.3474 - val_accuracy: 0.8753\n",
      "Epoch 798/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3576 - accuracy: 0.8655 - val_loss: 0.3458 - val_accuracy: 0.8753\n",
      "Epoch 799/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3555 - accuracy: 0.8667 - val_loss: 0.3469 - val_accuracy: 0.8749\n",
      "Epoch 800/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3570 - accuracy: 0.8659 - val_loss: 0.3475 - val_accuracy: 0.8758\n",
      "Epoch 801/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3567 - accuracy: 0.8665 - val_loss: 0.3470 - val_accuracy: 0.8757\n",
      "Epoch 802/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3575 - accuracy: 0.8655 - val_loss: 0.3457 - val_accuracy: 0.8756\n",
      "Epoch 803/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3577 - accuracy: 0.8659 - val_loss: 0.3482 - val_accuracy: 0.8761\n",
      "Epoch 804/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3568 - accuracy: 0.8650 - val_loss: 0.3460 - val_accuracy: 0.8759\n",
      "Epoch 805/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3577 - accuracy: 0.8656 - val_loss: 0.3468 - val_accuracy: 0.8750\n",
      "Epoch 806/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3550 - accuracy: 0.8658 - val_loss: 0.3452 - val_accuracy: 0.8772\n",
      "Epoch 807/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3546 - accuracy: 0.8662 - val_loss: 0.3468 - val_accuracy: 0.8756\n",
      "Epoch 808/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3582 - accuracy: 0.8660 - val_loss: 0.3445 - val_accuracy: 0.8756\n",
      "Epoch 809/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3588 - accuracy: 0.8659 - val_loss: 0.3461 - val_accuracy: 0.8756\n",
      "Epoch 810/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3563 - accuracy: 0.8661 - val_loss: 0.3467 - val_accuracy: 0.8753\n",
      "Epoch 811/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3546 - accuracy: 0.8673 - val_loss: 0.3460 - val_accuracy: 0.8754\n",
      "Epoch 812/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3573 - accuracy: 0.8672 - val_loss: 0.3449 - val_accuracy: 0.8753\n",
      "Epoch 813/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3554 - accuracy: 0.8666 - val_loss: 0.3456 - val_accuracy: 0.8752\n",
      "Epoch 814/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3567 - accuracy: 0.8661 - val_loss: 0.3462 - val_accuracy: 0.8756\n",
      "Epoch 815/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3552 - accuracy: 0.8661 - val_loss: 0.3451 - val_accuracy: 0.8768\n",
      "Epoch 816/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3533 - accuracy: 0.8673 - val_loss: 0.3452 - val_accuracy: 0.8766\n",
      "Epoch 817/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3565 - accuracy: 0.8653 - val_loss: 0.3496 - val_accuracy: 0.8766\n",
      "Epoch 818/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3543 - accuracy: 0.8659 - val_loss: 0.3464 - val_accuracy: 0.8759\n",
      "Epoch 819/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3568 - accuracy: 0.8665 - val_loss: 0.3472 - val_accuracy: 0.8748\n",
      "Epoch 820/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3578 - accuracy: 0.8652 - val_loss: 0.3434 - val_accuracy: 0.8760\n",
      "Epoch 821/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3579 - accuracy: 0.8647 - val_loss: 0.3438 - val_accuracy: 0.8768\n",
      "Epoch 822/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3563 - accuracy: 0.8659 - val_loss: 0.3453 - val_accuracy: 0.8766\n",
      "Epoch 823/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3583 - accuracy: 0.8650 - val_loss: 0.3463 - val_accuracy: 0.8757\n",
      "Epoch 824/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3558 - accuracy: 0.8664 - val_loss: 0.3448 - val_accuracy: 0.8764\n",
      "Epoch 825/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3558 - accuracy: 0.8672 - val_loss: 0.3471 - val_accuracy: 0.8757\n",
      "Epoch 826/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3559 - accuracy: 0.8655 - val_loss: 0.3461 - val_accuracy: 0.8766\n",
      "Epoch 827/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3538 - accuracy: 0.8676 - val_loss: 0.3467 - val_accuracy: 0.8755\n",
      "Epoch 828/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3557 - accuracy: 0.8664 - val_loss: 0.3464 - val_accuracy: 0.8758\n",
      "Epoch 829/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3581 - accuracy: 0.8645 - val_loss: 0.3457 - val_accuracy: 0.8765\n",
      "Epoch 830/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3557 - accuracy: 0.8662 - val_loss: 0.3450 - val_accuracy: 0.8773\n",
      "Epoch 831/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3560 - accuracy: 0.8657 - val_loss: 0.3443 - val_accuracy: 0.8764\n",
      "Epoch 832/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3539 - accuracy: 0.8670 - val_loss: 0.3453 - val_accuracy: 0.8766\n",
      "Epoch 833/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3562 - accuracy: 0.8659 - val_loss: 0.3450 - val_accuracy: 0.8764\n",
      "Epoch 834/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3560 - accuracy: 0.8661 - val_loss: 0.3454 - val_accuracy: 0.8760\n",
      "Epoch 835/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3558 - accuracy: 0.8659 - val_loss: 0.3438 - val_accuracy: 0.8770\n",
      "Epoch 836/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3548 - accuracy: 0.8661 - val_loss: 0.3453 - val_accuracy: 0.8780\n",
      "Epoch 837/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3571 - accuracy: 0.8654 - val_loss: 0.3443 - val_accuracy: 0.8752\n",
      "Epoch 838/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3545 - accuracy: 0.8668 - val_loss: 0.3468 - val_accuracy: 0.8767\n",
      "Epoch 839/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3562 - accuracy: 0.8658 - val_loss: 0.3485 - val_accuracy: 0.8766\n",
      "Epoch 840/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3538 - accuracy: 0.8683 - val_loss: 0.3434 - val_accuracy: 0.8782\n",
      "Epoch 841/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3554 - accuracy: 0.8670 - val_loss: 0.3429 - val_accuracy: 0.8781\n",
      "Epoch 842/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3556 - accuracy: 0.8663 - val_loss: 0.3450 - val_accuracy: 0.8761\n",
      "Epoch 843/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3556 - accuracy: 0.8658 - val_loss: 0.3482 - val_accuracy: 0.8752\n",
      "Epoch 844/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3579 - accuracy: 0.8657 - val_loss: 0.3446 - val_accuracy: 0.8762\n",
      "Epoch 845/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3561 - accuracy: 0.8667 - val_loss: 0.3473 - val_accuracy: 0.8759\n",
      "Epoch 846/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3561 - accuracy: 0.8666 - val_loss: 0.3479 - val_accuracy: 0.8761\n",
      "Epoch 847/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3546 - accuracy: 0.8673 - val_loss: 0.3454 - val_accuracy: 0.8753\n",
      "Epoch 848/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3551 - accuracy: 0.8659 - val_loss: 0.3455 - val_accuracy: 0.8770\n",
      "Epoch 849/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3537 - accuracy: 0.8671 - val_loss: 0.3476 - val_accuracy: 0.8768\n",
      "Epoch 850/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3532 - accuracy: 0.8673 - val_loss: 0.3442 - val_accuracy: 0.8772\n",
      "Epoch 851/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3549 - accuracy: 0.8674 - val_loss: 0.3494 - val_accuracy: 0.8766\n",
      "Epoch 852/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3567 - accuracy: 0.8655 - val_loss: 0.3445 - val_accuracy: 0.8776\n",
      "Epoch 853/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3565 - accuracy: 0.8663 - val_loss: 0.3443 - val_accuracy: 0.8771\n",
      "Epoch 854/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3541 - accuracy: 0.8667 - val_loss: 0.3458 - val_accuracy: 0.8771\n",
      "Epoch 855/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3547 - accuracy: 0.8662 - val_loss: 0.3462 - val_accuracy: 0.8775\n",
      "Epoch 856/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3543 - accuracy: 0.8664 - val_loss: 0.3453 - val_accuracy: 0.8782\n",
      "Epoch 857/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3541 - accuracy: 0.8665 - val_loss: 0.3454 - val_accuracy: 0.8761\n",
      "Epoch 858/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3576 - accuracy: 0.8662 - val_loss: 0.3439 - val_accuracy: 0.8778\n",
      "Epoch 859/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3537 - accuracy: 0.8667 - val_loss: 0.3456 - val_accuracy: 0.8761\n",
      "Epoch 860/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3540 - accuracy: 0.8662 - val_loss: 0.3441 - val_accuracy: 0.8769\n",
      "Epoch 861/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3539 - accuracy: 0.8669 - val_loss: 0.3450 - val_accuracy: 0.8779\n",
      "Epoch 862/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3558 - accuracy: 0.8658 - val_loss: 0.3459 - val_accuracy: 0.8764\n",
      "Epoch 863/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3542 - accuracy: 0.8680 - val_loss: 0.3443 - val_accuracy: 0.8756\n",
      "Epoch 864/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3553 - accuracy: 0.8664 - val_loss: 0.3486 - val_accuracy: 0.8758\n",
      "Epoch 865/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3538 - accuracy: 0.8676 - val_loss: 0.3465 - val_accuracy: 0.8769\n",
      "Epoch 866/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3527 - accuracy: 0.8673 - val_loss: 0.3451 - val_accuracy: 0.8767\n",
      "Epoch 867/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3538 - accuracy: 0.8663 - val_loss: 0.3460 - val_accuracy: 0.8765\n",
      "Epoch 868/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3541 - accuracy: 0.8664 - val_loss: 0.3471 - val_accuracy: 0.8765\n",
      "Epoch 869/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3549 - accuracy: 0.8671 - val_loss: 0.3457 - val_accuracy: 0.8768\n",
      "Epoch 870/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3521 - accuracy: 0.8668 - val_loss: 0.3482 - val_accuracy: 0.8749\n",
      "Epoch 871/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3566 - accuracy: 0.8658 - val_loss: 0.3458 - val_accuracy: 0.8769\n",
      "Epoch 872/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3535 - accuracy: 0.8680 - val_loss: 0.3460 - val_accuracy: 0.8762\n",
      "Epoch 873/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3530 - accuracy: 0.8668 - val_loss: 0.3479 - val_accuracy: 0.8765\n",
      "Epoch 874/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3528 - accuracy: 0.8671 - val_loss: 0.3446 - val_accuracy: 0.8764\n",
      "Epoch 875/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3534 - accuracy: 0.8686 - val_loss: 0.3480 - val_accuracy: 0.8759\n",
      "Epoch 876/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3565 - accuracy: 0.8670 - val_loss: 0.3461 - val_accuracy: 0.8762\n",
      "Epoch 877/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3539 - accuracy: 0.8670 - val_loss: 0.3506 - val_accuracy: 0.8751\n",
      "Epoch 878/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3550 - accuracy: 0.8660 - val_loss: 0.3483 - val_accuracy: 0.8747\n",
      "Epoch 879/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3536 - accuracy: 0.8676 - val_loss: 0.3488 - val_accuracy: 0.8756\n",
      "Epoch 880/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3533 - accuracy: 0.8664 - val_loss: 0.3451 - val_accuracy: 0.8765\n",
      "Epoch 881/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3524 - accuracy: 0.8675 - val_loss: 0.3472 - val_accuracy: 0.8766\n",
      "Epoch 882/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3526 - accuracy: 0.8680 - val_loss: 0.3491 - val_accuracy: 0.8751\n",
      "Epoch 883/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3545 - accuracy: 0.8670 - val_loss: 0.3466 - val_accuracy: 0.8777\n",
      "Epoch 884/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3544 - accuracy: 0.8655 - val_loss: 0.3454 - val_accuracy: 0.8763\n",
      "Epoch 885/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3522 - accuracy: 0.8686 - val_loss: 0.3460 - val_accuracy: 0.8771\n",
      "Epoch 886/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3540 - accuracy: 0.8673 - val_loss: 0.3446 - val_accuracy: 0.8765\n",
      "Epoch 887/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3530 - accuracy: 0.8681 - val_loss: 0.3477 - val_accuracy: 0.8767\n",
      "Epoch 888/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3519 - accuracy: 0.8679 - val_loss: 0.3479 - val_accuracy: 0.8762\n",
      "Epoch 889/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3512 - accuracy: 0.8682 - val_loss: 0.3448 - val_accuracy: 0.8772\n",
      "Epoch 890/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3560 - accuracy: 0.8667 - val_loss: 0.3468 - val_accuracy: 0.8760\n",
      "Epoch 891/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3540 - accuracy: 0.8673 - val_loss: 0.3470 - val_accuracy: 0.8757\n",
      "Epoch 892/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3520 - accuracy: 0.8678 - val_loss: 0.3455 - val_accuracy: 0.8768\n",
      "Epoch 893/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3523 - accuracy: 0.8678 - val_loss: 0.3447 - val_accuracy: 0.8765\n",
      "Epoch 894/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3529 - accuracy: 0.8665 - val_loss: 0.3426 - val_accuracy: 0.8759\n",
      "Epoch 895/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3525 - accuracy: 0.8668 - val_loss: 0.3469 - val_accuracy: 0.8767\n",
      "Epoch 896/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3500 - accuracy: 0.8679 - val_loss: 0.3466 - val_accuracy: 0.8757\n",
      "Epoch 897/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3539 - accuracy: 0.8666 - val_loss: 0.3435 - val_accuracy: 0.8767\n",
      "Epoch 898/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3532 - accuracy: 0.8676 - val_loss: 0.3449 - val_accuracy: 0.8756\n",
      "Epoch 899/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3524 - accuracy: 0.8668 - val_loss: 0.3461 - val_accuracy: 0.8764\n",
      "Epoch 900/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3530 - accuracy: 0.8669 - val_loss: 0.3474 - val_accuracy: 0.8761\n",
      "Epoch 901/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3557 - accuracy: 0.8660 - val_loss: 0.3461 - val_accuracy: 0.8770\n",
      "Epoch 902/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3513 - accuracy: 0.8674 - val_loss: 0.3462 - val_accuracy: 0.8764\n",
      "Epoch 903/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3560 - accuracy: 0.8663 - val_loss: 0.3449 - val_accuracy: 0.8768\n",
      "Epoch 904/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3531 - accuracy: 0.8669 - val_loss: 0.3477 - val_accuracy: 0.8754\n",
      "Epoch 905/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3528 - accuracy: 0.8678 - val_loss: 0.3440 - val_accuracy: 0.8775\n",
      "Epoch 906/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3528 - accuracy: 0.8677 - val_loss: 0.3436 - val_accuracy: 0.8768\n",
      "Epoch 907/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3543 - accuracy: 0.8670 - val_loss: 0.3447 - val_accuracy: 0.8768\n",
      "Epoch 908/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3520 - accuracy: 0.8669 - val_loss: 0.3459 - val_accuracy: 0.8773\n",
      "Epoch 909/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3529 - accuracy: 0.8668 - val_loss: 0.3440 - val_accuracy: 0.8778\n",
      "Epoch 910/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8682 - val_loss: 0.3455 - val_accuracy: 0.8769\n",
      "Epoch 911/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3513 - accuracy: 0.8678 - val_loss: 0.3452 - val_accuracy: 0.8765\n",
      "Epoch 912/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3486 - accuracy: 0.8692 - val_loss: 0.3467 - val_accuracy: 0.8758\n",
      "Epoch 913/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3540 - accuracy: 0.8675 - val_loss: 0.3450 - val_accuracy: 0.8752\n",
      "Epoch 914/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3523 - accuracy: 0.8666 - val_loss: 0.3445 - val_accuracy: 0.8763\n",
      "Epoch 915/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3519 - accuracy: 0.8673 - val_loss: 0.3437 - val_accuracy: 0.8769\n",
      "Epoch 916/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3525 - accuracy: 0.8675 - val_loss: 0.3471 - val_accuracy: 0.8753\n",
      "Epoch 917/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8681 - val_loss: 0.3426 - val_accuracy: 0.8775\n",
      "Epoch 918/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8671 - val_loss: 0.3459 - val_accuracy: 0.8775\n",
      "Epoch 919/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8680 - val_loss: 0.3446 - val_accuracy: 0.8770\n",
      "Epoch 920/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3526 - accuracy: 0.8676 - val_loss: 0.3452 - val_accuracy: 0.8765\n",
      "Epoch 921/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3529 - accuracy: 0.8672 - val_loss: 0.3450 - val_accuracy: 0.8766\n",
      "Epoch 922/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3508 - accuracy: 0.8682 - val_loss: 0.3455 - val_accuracy: 0.8765\n",
      "Epoch 923/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3527 - accuracy: 0.8676 - val_loss: 0.3426 - val_accuracy: 0.8776\n",
      "Epoch 924/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3529 - accuracy: 0.8681 - val_loss: 0.3448 - val_accuracy: 0.8775\n",
      "Epoch 925/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3547 - accuracy: 0.8664 - val_loss: 0.3454 - val_accuracy: 0.8767\n",
      "Epoch 926/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3520 - accuracy: 0.8681 - val_loss: 0.3454 - val_accuracy: 0.8763\n",
      "Epoch 927/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3530 - accuracy: 0.8684 - val_loss: 0.3416 - val_accuracy: 0.8786\n",
      "Epoch 928/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3504 - accuracy: 0.8683 - val_loss: 0.3462 - val_accuracy: 0.8762\n",
      "Epoch 929/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3500 - accuracy: 0.8688 - val_loss: 0.3436 - val_accuracy: 0.8783\n",
      "Epoch 930/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3539 - accuracy: 0.8670 - val_loss: 0.3445 - val_accuracy: 0.8763\n",
      "Epoch 931/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8673 - val_loss: 0.3450 - val_accuracy: 0.8767\n",
      "Epoch 932/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3516 - accuracy: 0.8671 - val_loss: 0.3442 - val_accuracy: 0.8771\n",
      "Epoch 933/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8675 - val_loss: 0.3441 - val_accuracy: 0.8775\n",
      "Epoch 934/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3516 - accuracy: 0.8677 - val_loss: 0.3446 - val_accuracy: 0.8770\n",
      "Epoch 935/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3517 - accuracy: 0.8678 - val_loss: 0.3485 - val_accuracy: 0.8759\n",
      "Epoch 936/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3519 - accuracy: 0.8685 - val_loss: 0.3450 - val_accuracy: 0.8761\n",
      "Epoch 937/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3534 - accuracy: 0.8676 - val_loss: 0.3432 - val_accuracy: 0.8767\n",
      "Epoch 938/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3517 - accuracy: 0.8678 - val_loss: 0.3452 - val_accuracy: 0.8774\n",
      "Epoch 939/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3516 - accuracy: 0.8680 - val_loss: 0.3435 - val_accuracy: 0.8775\n",
      "Epoch 940/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3514 - accuracy: 0.8675 - val_loss: 0.3437 - val_accuracy: 0.8777\n",
      "Epoch 941/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3517 - accuracy: 0.8684 - val_loss: 0.3443 - val_accuracy: 0.8773\n",
      "Epoch 942/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3539 - accuracy: 0.8670 - val_loss: 0.3447 - val_accuracy: 0.8768\n",
      "Epoch 943/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3517 - accuracy: 0.8677 - val_loss: 0.3453 - val_accuracy: 0.8781\n",
      "Epoch 944/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3498 - accuracy: 0.8679 - val_loss: 0.3487 - val_accuracy: 0.8769\n",
      "Epoch 945/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8673 - val_loss: 0.3477 - val_accuracy: 0.8763\n",
      "Epoch 946/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3521 - accuracy: 0.8680 - val_loss: 0.3468 - val_accuracy: 0.8761\n",
      "Epoch 947/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3507 - accuracy: 0.8683 - val_loss: 0.3433 - val_accuracy: 0.8783\n",
      "Epoch 948/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8686 - val_loss: 0.3429 - val_accuracy: 0.8784\n",
      "Epoch 949/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3507 - accuracy: 0.8674 - val_loss: 0.3451 - val_accuracy: 0.8773\n",
      "Epoch 950/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3500 - accuracy: 0.8683 - val_loss: 0.3439 - val_accuracy: 0.8768\n",
      "Epoch 951/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3514 - accuracy: 0.8680 - val_loss: 0.3409 - val_accuracy: 0.8782\n",
      "Epoch 952/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3515 - accuracy: 0.8684 - val_loss: 0.3451 - val_accuracy: 0.8761\n",
      "Epoch 953/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3517 - accuracy: 0.8677 - val_loss: 0.3457 - val_accuracy: 0.8766\n",
      "Epoch 954/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3502 - accuracy: 0.8679 - val_loss: 0.3430 - val_accuracy: 0.8785\n",
      "Epoch 955/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3532 - accuracy: 0.8682 - val_loss: 0.3414 - val_accuracy: 0.8777\n",
      "Epoch 956/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3509 - accuracy: 0.8683 - val_loss: 0.3447 - val_accuracy: 0.8786\n",
      "Epoch 957/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3509 - accuracy: 0.8691 - val_loss: 0.3444 - val_accuracy: 0.8779\n",
      "Epoch 958/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3493 - accuracy: 0.8689 - val_loss: 0.3470 - val_accuracy: 0.8774\n",
      "Epoch 959/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8676 - val_loss: 0.3433 - val_accuracy: 0.8773\n",
      "Epoch 960/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3505 - accuracy: 0.8690 - val_loss: 0.3428 - val_accuracy: 0.8778\n",
      "Epoch 961/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3514 - accuracy: 0.8686 - val_loss: 0.3461 - val_accuracy: 0.8756\n",
      "Epoch 962/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3475 - accuracy: 0.8689 - val_loss: 0.3426 - val_accuracy: 0.8779\n",
      "Epoch 963/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3509 - accuracy: 0.8682 - val_loss: 0.3461 - val_accuracy: 0.8765\n",
      "Epoch 964/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3525 - accuracy: 0.8676 - val_loss: 0.3461 - val_accuracy: 0.8774\n",
      "Epoch 965/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3497 - accuracy: 0.8688 - val_loss: 0.3485 - val_accuracy: 0.8764\n",
      "Epoch 966/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3520 - accuracy: 0.8677 - val_loss: 0.3450 - val_accuracy: 0.8780\n",
      "Epoch 967/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3500 - accuracy: 0.8691 - val_loss: 0.3438 - val_accuracy: 0.8776\n",
      "Epoch 968/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3495 - accuracy: 0.8687 - val_loss: 0.3427 - val_accuracy: 0.8783\n",
      "Epoch 969/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3502 - accuracy: 0.8683 - val_loss: 0.3435 - val_accuracy: 0.8773\n",
      "Epoch 970/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8682 - val_loss: 0.3492 - val_accuracy: 0.8751\n",
      "Epoch 971/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3493 - accuracy: 0.8690 - val_loss: 0.3454 - val_accuracy: 0.8771\n",
      "Epoch 972/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3512 - accuracy: 0.8680 - val_loss: 0.3462 - val_accuracy: 0.8762\n",
      "Epoch 973/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3534 - accuracy: 0.8662 - val_loss: 0.3428 - val_accuracy: 0.8784\n",
      "Epoch 974/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3465 - accuracy: 0.8693 - val_loss: 0.3425 - val_accuracy: 0.8780\n",
      "Epoch 975/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3516 - accuracy: 0.8687 - val_loss: 0.3429 - val_accuracy: 0.8776\n",
      "Epoch 976/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3541 - accuracy: 0.8664 - val_loss: 0.3404 - val_accuracy: 0.8786\n",
      "Epoch 977/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3488 - accuracy: 0.8691 - val_loss: 0.3454 - val_accuracy: 0.8765\n",
      "Epoch 978/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3499 - accuracy: 0.8677 - val_loss: 0.3455 - val_accuracy: 0.8771\n",
      "Epoch 979/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3504 - accuracy: 0.8688 - val_loss: 0.3417 - val_accuracy: 0.8768\n",
      "Epoch 980/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3502 - accuracy: 0.8679 - val_loss: 0.3446 - val_accuracy: 0.8771\n",
      "Epoch 981/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3515 - accuracy: 0.8682 - val_loss: 0.3449 - val_accuracy: 0.8777\n",
      "Epoch 982/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8683 - val_loss: 0.3434 - val_accuracy: 0.8764\n",
      "Epoch 983/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3525 - accuracy: 0.8674 - val_loss: 0.3447 - val_accuracy: 0.8771\n",
      "Epoch 984/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8684 - val_loss: 0.3452 - val_accuracy: 0.8761\n",
      "Epoch 985/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8685 - val_loss: 0.3462 - val_accuracy: 0.8764\n",
      "Epoch 986/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8681 - val_loss: 0.3434 - val_accuracy: 0.8766\n",
      "Epoch 987/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8675 - val_loss: 0.3440 - val_accuracy: 0.8767\n",
      "Epoch 988/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3504 - accuracy: 0.8687 - val_loss: 0.3424 - val_accuracy: 0.8778\n",
      "Epoch 989/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3505 - accuracy: 0.8684 - val_loss: 0.3434 - val_accuracy: 0.8774\n",
      "Epoch 990/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3502 - accuracy: 0.8687 - val_loss: 0.3429 - val_accuracy: 0.8792\n",
      "Epoch 991/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3485 - accuracy: 0.8687 - val_loss: 0.3445 - val_accuracy: 0.8770\n",
      "Epoch 992/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3511 - accuracy: 0.8678 - val_loss: 0.3435 - val_accuracy: 0.8768\n",
      "Epoch 993/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8685 - val_loss: 0.3463 - val_accuracy: 0.8763\n",
      "Epoch 994/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8687 - val_loss: 0.3440 - val_accuracy: 0.8765\n",
      "Epoch 995/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3497 - accuracy: 0.8680 - val_loss: 0.3455 - val_accuracy: 0.8772\n",
      "Epoch 996/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3477 - accuracy: 0.8695 - val_loss: 0.3409 - val_accuracy: 0.8770\n",
      "Epoch 997/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3503 - accuracy: 0.8688 - val_loss: 0.3456 - val_accuracy: 0.8778\n",
      "Epoch 998/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3524 - accuracy: 0.8674 - val_loss: 0.3451 - val_accuracy: 0.8766\n",
      "Epoch 999/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8697 - val_loss: 0.3427 - val_accuracy: 0.8779\n",
      "Epoch 1000/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3509 - accuracy: 0.8685 - val_loss: 0.3458 - val_accuracy: 0.8768\n",
      "Epoch 1001/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3477 - accuracy: 0.8684 - val_loss: 0.3441 - val_accuracy: 0.8773\n",
      "Epoch 1002/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3521 - accuracy: 0.8684 - val_loss: 0.3424 - val_accuracy: 0.8763\n",
      "Epoch 1003/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3502 - accuracy: 0.8680 - val_loss: 0.3420 - val_accuracy: 0.8785\n",
      "Epoch 1004/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3496 - accuracy: 0.8691 - val_loss: 0.3447 - val_accuracy: 0.8769\n",
      "Epoch 1005/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3512 - accuracy: 0.8690 - val_loss: 0.3457 - val_accuracy: 0.8772\n",
      "Epoch 1006/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8694 - val_loss: 0.3418 - val_accuracy: 0.8776\n",
      "Epoch 1007/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3480 - accuracy: 0.8698 - val_loss: 0.3452 - val_accuracy: 0.8770\n",
      "Epoch 1008/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3474 - accuracy: 0.8695 - val_loss: 0.3453 - val_accuracy: 0.8774\n",
      "Epoch 1009/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3506 - accuracy: 0.8687 - val_loss: 0.3452 - val_accuracy: 0.8776\n",
      "Epoch 1010/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3483 - accuracy: 0.8696 - val_loss: 0.3438 - val_accuracy: 0.8781\n",
      "Epoch 1011/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3521 - accuracy: 0.8673 - val_loss: 0.3413 - val_accuracy: 0.8776\n",
      "Epoch 1012/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3439 - accuracy: 0.8711 - val_loss: 0.3478 - val_accuracy: 0.8768\n",
      "Epoch 1013/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3510 - accuracy: 0.8691 - val_loss: 0.3433 - val_accuracy: 0.8783\n",
      "Epoch 1014/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3505 - accuracy: 0.8693 - val_loss: 0.3437 - val_accuracy: 0.8769\n",
      "Epoch 1015/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3510 - accuracy: 0.8683 - val_loss: 0.3440 - val_accuracy: 0.8768\n",
      "Epoch 1016/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3477 - accuracy: 0.8692 - val_loss: 0.3432 - val_accuracy: 0.8781\n",
      "Epoch 1017/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3493 - accuracy: 0.8683 - val_loss: 0.3471 - val_accuracy: 0.8781\n",
      "Epoch 1018/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3482 - accuracy: 0.8691 - val_loss: 0.3441 - val_accuracy: 0.8770\n",
      "Epoch 1019/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8683 - val_loss: 0.3449 - val_accuracy: 0.8777\n",
      "Epoch 1020/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3481 - accuracy: 0.8698 - val_loss: 0.3436 - val_accuracy: 0.8785\n",
      "Epoch 1021/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8694 - val_loss: 0.3447 - val_accuracy: 0.8778\n",
      "Epoch 1022/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3492 - accuracy: 0.8697 - val_loss: 0.3441 - val_accuracy: 0.8776\n",
      "Epoch 1023/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3490 - accuracy: 0.8676 - val_loss: 0.3438 - val_accuracy: 0.8783\n",
      "Epoch 1024/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3484 - accuracy: 0.8688 - val_loss: 0.3445 - val_accuracy: 0.8788\n",
      "Epoch 1025/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3481 - accuracy: 0.8692 - val_loss: 0.3438 - val_accuracy: 0.8774\n",
      "Epoch 1026/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3485 - accuracy: 0.8693 - val_loss: 0.3425 - val_accuracy: 0.8773\n",
      "Epoch 1027/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3471 - accuracy: 0.8689 - val_loss: 0.3424 - val_accuracy: 0.8784\n",
      "Epoch 1028/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3508 - accuracy: 0.8679 - val_loss: 0.3431 - val_accuracy: 0.8776\n",
      "Epoch 1029/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3515 - accuracy: 0.8678 - val_loss: 0.3464 - val_accuracy: 0.8776\n",
      "Epoch 1030/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3489 - accuracy: 0.8691 - val_loss: 0.3425 - val_accuracy: 0.8796\n",
      "Epoch 1031/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3484 - accuracy: 0.8677 - val_loss: 0.3445 - val_accuracy: 0.8778\n",
      "Epoch 1032/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3493 - accuracy: 0.8690 - val_loss: 0.3406 - val_accuracy: 0.8774\n",
      "Epoch 1033/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3490 - accuracy: 0.8678 - val_loss: 0.3438 - val_accuracy: 0.8782\n",
      "Epoch 1034/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3481 - accuracy: 0.8691 - val_loss: 0.3425 - val_accuracy: 0.8770\n",
      "Epoch 1035/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3479 - accuracy: 0.8692 - val_loss: 0.3428 - val_accuracy: 0.8776\n",
      "Epoch 1036/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8694 - val_loss: 0.3448 - val_accuracy: 0.8771\n",
      "Epoch 1037/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8686 - val_loss: 0.3454 - val_accuracy: 0.8767\n",
      "Epoch 1038/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8692 - val_loss: 0.3446 - val_accuracy: 0.8765\n",
      "Epoch 1039/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3504 - accuracy: 0.8678 - val_loss: 0.3422 - val_accuracy: 0.8779\n",
      "Epoch 1040/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3469 - accuracy: 0.8691 - val_loss: 0.3458 - val_accuracy: 0.8780\n",
      "Epoch 1041/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8696 - val_loss: 0.3454 - val_accuracy: 0.8768\n",
      "Epoch 1042/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8690 - val_loss: 0.3435 - val_accuracy: 0.8787\n",
      "Epoch 1043/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3467 - accuracy: 0.8692 - val_loss: 0.3441 - val_accuracy: 0.8783\n",
      "Epoch 1044/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3466 - accuracy: 0.8696 - val_loss: 0.3410 - val_accuracy: 0.8777\n",
      "Epoch 1045/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3483 - accuracy: 0.8695 - val_loss: 0.3473 - val_accuracy: 0.8761\n",
      "Epoch 1046/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3462 - accuracy: 0.8695 - val_loss: 0.3452 - val_accuracy: 0.8775\n",
      "Epoch 1047/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3450 - accuracy: 0.8696 - val_loss: 0.3442 - val_accuracy: 0.8776\n",
      "Epoch 1048/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8698 - val_loss: 0.3444 - val_accuracy: 0.8781\n",
      "Epoch 1049/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3499 - accuracy: 0.8683 - val_loss: 0.3445 - val_accuracy: 0.8783\n",
      "Epoch 1050/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3480 - accuracy: 0.8698 - val_loss: 0.3439 - val_accuracy: 0.8787\n",
      "Epoch 1051/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3482 - accuracy: 0.8695 - val_loss: 0.3424 - val_accuracy: 0.8792\n",
      "Epoch 1052/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8698 - val_loss: 0.3439 - val_accuracy: 0.8783\n",
      "Epoch 1053/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3475 - accuracy: 0.8704 - val_loss: 0.3427 - val_accuracy: 0.8785\n",
      "Epoch 1054/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8695 - val_loss: 0.3434 - val_accuracy: 0.8778\n",
      "Epoch 1055/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3466 - accuracy: 0.8695 - val_loss: 0.3431 - val_accuracy: 0.8780\n",
      "Epoch 1056/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8692 - val_loss: 0.3454 - val_accuracy: 0.8795\n",
      "Epoch 1057/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8700 - val_loss: 0.3452 - val_accuracy: 0.8781\n",
      "Epoch 1058/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3487 - accuracy: 0.8692 - val_loss: 0.3436 - val_accuracy: 0.8786\n",
      "Epoch 1059/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3499 - accuracy: 0.8695 - val_loss: 0.3452 - val_accuracy: 0.8771\n",
      "Epoch 1060/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3490 - accuracy: 0.8688 - val_loss: 0.3446 - val_accuracy: 0.8760\n",
      "Epoch 1061/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3461 - accuracy: 0.8705 - val_loss: 0.3409 - val_accuracy: 0.8775\n",
      "Epoch 1062/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3488 - accuracy: 0.8694 - val_loss: 0.3438 - val_accuracy: 0.8781\n",
      "Epoch 1063/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3467 - accuracy: 0.8704 - val_loss: 0.3460 - val_accuracy: 0.8778\n",
      "Epoch 1064/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8709 - val_loss: 0.3430 - val_accuracy: 0.8784\n",
      "Epoch 1065/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3477 - accuracy: 0.8695 - val_loss: 0.3412 - val_accuracy: 0.8789\n",
      "Epoch 1066/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3489 - accuracy: 0.8685 - val_loss: 0.3455 - val_accuracy: 0.8770\n",
      "Epoch 1067/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3484 - accuracy: 0.8688 - val_loss: 0.3442 - val_accuracy: 0.8767\n",
      "Epoch 1068/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8687 - val_loss: 0.3446 - val_accuracy: 0.8761\n",
      "Epoch 1069/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3459 - accuracy: 0.8699 - val_loss: 0.3421 - val_accuracy: 0.8784\n",
      "Epoch 1070/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8703 - val_loss: 0.3454 - val_accuracy: 0.8781\n",
      "Epoch 1071/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3487 - accuracy: 0.8691 - val_loss: 0.3442 - val_accuracy: 0.8773\n",
      "Epoch 1072/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8710 - val_loss: 0.3445 - val_accuracy: 0.8785\n",
      "Epoch 1073/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3486 - accuracy: 0.8694 - val_loss: 0.3436 - val_accuracy: 0.8784\n",
      "Epoch 1074/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3467 - accuracy: 0.8706 - val_loss: 0.3450 - val_accuracy: 0.8779\n",
      "Epoch 1075/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8718 - val_loss: 0.3431 - val_accuracy: 0.8773\n",
      "Epoch 1076/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3439 - accuracy: 0.8712 - val_loss: 0.3440 - val_accuracy: 0.8775\n",
      "Epoch 1077/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3493 - accuracy: 0.8678 - val_loss: 0.3416 - val_accuracy: 0.8776\n",
      "Epoch 1078/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8702 - val_loss: 0.3419 - val_accuracy: 0.8772\n",
      "Epoch 1079/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3464 - accuracy: 0.8698 - val_loss: 0.3466 - val_accuracy: 0.8769\n",
      "Epoch 1080/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8692 - val_loss: 0.3445 - val_accuracy: 0.8781\n",
      "Epoch 1081/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3469 - accuracy: 0.8695 - val_loss: 0.3474 - val_accuracy: 0.8777\n",
      "Epoch 1082/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3482 - accuracy: 0.8695 - val_loss: 0.3419 - val_accuracy: 0.8768\n",
      "Epoch 1083/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8713 - val_loss: 0.3433 - val_accuracy: 0.8772\n",
      "Epoch 1084/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3489 - accuracy: 0.8693 - val_loss: 0.3425 - val_accuracy: 0.8783\n",
      "Epoch 1085/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3466 - accuracy: 0.8700 - val_loss: 0.3428 - val_accuracy: 0.8775\n",
      "Epoch 1086/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8689 - val_loss: 0.3415 - val_accuracy: 0.8790\n",
      "Epoch 1087/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3453 - accuracy: 0.8708 - val_loss: 0.3415 - val_accuracy: 0.8791\n",
      "Epoch 1088/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3491 - accuracy: 0.8683 - val_loss: 0.3414 - val_accuracy: 0.8782\n",
      "Epoch 1089/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3448 - accuracy: 0.8710 - val_loss: 0.3396 - val_accuracy: 0.8791\n",
      "Epoch 1090/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3453 - accuracy: 0.8702 - val_loss: 0.3439 - val_accuracy: 0.8779\n",
      "Epoch 1091/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3436 - accuracy: 0.8716 - val_loss: 0.3453 - val_accuracy: 0.8773\n",
      "Epoch 1092/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3479 - accuracy: 0.8694 - val_loss: 0.3450 - val_accuracy: 0.8784\n",
      "Epoch 1093/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3462 - accuracy: 0.8700 - val_loss: 0.3445 - val_accuracy: 0.8765\n",
      "Epoch 1094/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3453 - accuracy: 0.8693 - val_loss: 0.3421 - val_accuracy: 0.8786\n",
      "Epoch 1095/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3447 - accuracy: 0.8700 - val_loss: 0.3427 - val_accuracy: 0.8777\n",
      "Epoch 1096/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3454 - accuracy: 0.8714 - val_loss: 0.3420 - val_accuracy: 0.8782\n",
      "Epoch 1097/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8690 - val_loss: 0.3412 - val_accuracy: 0.8778\n",
      "Epoch 1098/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3467 - accuracy: 0.8697 - val_loss: 0.3413 - val_accuracy: 0.8781\n",
      "Epoch 1099/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8706 - val_loss: 0.3422 - val_accuracy: 0.8778\n",
      "Epoch 1100/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3477 - accuracy: 0.8695 - val_loss: 0.3418 - val_accuracy: 0.8771\n",
      "Epoch 1101/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8687 - val_loss: 0.3408 - val_accuracy: 0.8771\n",
      "Epoch 1102/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3452 - accuracy: 0.8701 - val_loss: 0.3430 - val_accuracy: 0.8771\n",
      "Epoch 1103/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3475 - accuracy: 0.8691 - val_loss: 0.3420 - val_accuracy: 0.8782\n",
      "Epoch 1104/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3456 - accuracy: 0.8695 - val_loss: 0.3421 - val_accuracy: 0.8789\n",
      "Epoch 1105/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3476 - accuracy: 0.8694 - val_loss: 0.3416 - val_accuracy: 0.8778\n",
      "Epoch 1106/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3451 - accuracy: 0.8701 - val_loss: 0.3415 - val_accuracy: 0.8791\n",
      "Epoch 1107/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8689 - val_loss: 0.3402 - val_accuracy: 0.8777\n",
      "Epoch 1108/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3485 - accuracy: 0.8690 - val_loss: 0.3421 - val_accuracy: 0.8788\n",
      "Epoch 1109/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3456 - accuracy: 0.8699 - val_loss: 0.3412 - val_accuracy: 0.8783\n",
      "Epoch 1110/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3455 - accuracy: 0.8694 - val_loss: 0.3418 - val_accuracy: 0.8777\n",
      "Epoch 1111/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8700 - val_loss: 0.3404 - val_accuracy: 0.8793\n",
      "Epoch 1112/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3479 - accuracy: 0.8692 - val_loss: 0.3420 - val_accuracy: 0.8778\n",
      "Epoch 1113/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3447 - accuracy: 0.8716 - val_loss: 0.3412 - val_accuracy: 0.8789\n",
      "Epoch 1114/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3480 - accuracy: 0.8692 - val_loss: 0.3415 - val_accuracy: 0.8785\n",
      "Epoch 1115/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3477 - accuracy: 0.8695 - val_loss: 0.3396 - val_accuracy: 0.8789\n",
      "Epoch 1116/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3479 - accuracy: 0.8702 - val_loss: 0.3430 - val_accuracy: 0.8778\n",
      "Epoch 1117/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3423 - accuracy: 0.8712 - val_loss: 0.3408 - val_accuracy: 0.8771\n",
      "Epoch 1118/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8708 - val_loss: 0.3401 - val_accuracy: 0.8776\n",
      "Epoch 1119/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3451 - accuracy: 0.8707 - val_loss: 0.3438 - val_accuracy: 0.8769\n",
      "Epoch 1120/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8699 - val_loss: 0.3413 - val_accuracy: 0.8776\n",
      "Epoch 1121/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3467 - accuracy: 0.8697 - val_loss: 0.3419 - val_accuracy: 0.8771\n",
      "Epoch 1122/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8702 - val_loss: 0.3443 - val_accuracy: 0.8769\n",
      "Epoch 1123/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8705 - val_loss: 0.3420 - val_accuracy: 0.8778\n",
      "Epoch 1124/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8699 - val_loss: 0.3460 - val_accuracy: 0.8774\n",
      "Epoch 1125/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3448 - accuracy: 0.8704 - val_loss: 0.3434 - val_accuracy: 0.8780\n",
      "Epoch 1126/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8694 - val_loss: 0.3423 - val_accuracy: 0.8774\n",
      "Epoch 1127/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3481 - accuracy: 0.8683 - val_loss: 0.3436 - val_accuracy: 0.8787\n",
      "Epoch 1128/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3461 - accuracy: 0.8697 - val_loss: 0.3403 - val_accuracy: 0.8786\n",
      "Epoch 1129/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3454 - accuracy: 0.8713 - val_loss: 0.3443 - val_accuracy: 0.8775\n",
      "Epoch 1130/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3442 - accuracy: 0.8714 - val_loss: 0.3421 - val_accuracy: 0.8787\n",
      "Epoch 1131/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8719 - val_loss: 0.3446 - val_accuracy: 0.8780\n",
      "Epoch 1132/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3428 - accuracy: 0.8715 - val_loss: 0.3407 - val_accuracy: 0.8778\n",
      "Epoch 1133/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8694 - val_loss: 0.3409 - val_accuracy: 0.8783\n",
      "Epoch 1134/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3462 - accuracy: 0.8703 - val_loss: 0.3416 - val_accuracy: 0.8793\n",
      "Epoch 1135/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3447 - accuracy: 0.8713 - val_loss: 0.3430 - val_accuracy: 0.8786\n",
      "Epoch 1136/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8698 - val_loss: 0.3418 - val_accuracy: 0.8784\n",
      "Epoch 1137/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3474 - accuracy: 0.8695 - val_loss: 0.3432 - val_accuracy: 0.8765\n",
      "Epoch 1138/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3464 - accuracy: 0.8703 - val_loss: 0.3427 - val_accuracy: 0.8793\n",
      "Epoch 1139/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3467 - accuracy: 0.8693 - val_loss: 0.3427 - val_accuracy: 0.8778\n",
      "Epoch 1140/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3468 - accuracy: 0.8699 - val_loss: 0.3412 - val_accuracy: 0.8788\n",
      "Epoch 1141/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3433 - accuracy: 0.8717 - val_loss: 0.3412 - val_accuracy: 0.8792\n",
      "Epoch 1142/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8696 - val_loss: 0.3421 - val_accuracy: 0.8785\n",
      "Epoch 1143/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3438 - accuracy: 0.8711 - val_loss: 0.3410 - val_accuracy: 0.8791\n",
      "Epoch 1144/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3478 - accuracy: 0.8697 - val_loss: 0.3438 - val_accuracy: 0.8777\n",
      "Epoch 1145/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3430 - accuracy: 0.8707 - val_loss: 0.3427 - val_accuracy: 0.8778\n",
      "Epoch 1146/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3425 - accuracy: 0.8714 - val_loss: 0.3416 - val_accuracy: 0.8787\n",
      "Epoch 1147/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3462 - accuracy: 0.8703 - val_loss: 0.3409 - val_accuracy: 0.8803\n",
      "Epoch 1148/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3432 - accuracy: 0.8710 - val_loss: 0.3423 - val_accuracy: 0.8790\n",
      "Epoch 1149/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3458 - accuracy: 0.8706 - val_loss: 0.3412 - val_accuracy: 0.8791\n",
      "Epoch 1150/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3456 - accuracy: 0.8700 - val_loss: 0.3422 - val_accuracy: 0.8798\n",
      "Epoch 1151/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3459 - accuracy: 0.8702 - val_loss: 0.3431 - val_accuracy: 0.8786\n",
      "Epoch 1152/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3484 - accuracy: 0.8690 - val_loss: 0.3431 - val_accuracy: 0.8787\n",
      "Epoch 1153/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8700 - val_loss: 0.3429 - val_accuracy: 0.8791\n",
      "Epoch 1154/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8702 - val_loss: 0.3427 - val_accuracy: 0.8798\n",
      "Epoch 1155/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8700 - val_loss: 0.3461 - val_accuracy: 0.8768\n",
      "Epoch 1156/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3475 - accuracy: 0.8693 - val_loss: 0.3410 - val_accuracy: 0.8791\n",
      "Epoch 1157/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8707 - val_loss: 0.3421 - val_accuracy: 0.8796\n",
      "Epoch 1158/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3443 - accuracy: 0.8703 - val_loss: 0.3419 - val_accuracy: 0.8788\n",
      "Epoch 1159/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3447 - accuracy: 0.8709 - val_loss: 0.3404 - val_accuracy: 0.8783\n",
      "Epoch 1160/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3466 - accuracy: 0.8699 - val_loss: 0.3422 - val_accuracy: 0.8783\n",
      "Epoch 1161/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8711 - val_loss: 0.3403 - val_accuracy: 0.8794\n",
      "Epoch 1162/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8702 - val_loss: 0.3412 - val_accuracy: 0.8788\n",
      "Epoch 1163/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3436 - accuracy: 0.8707 - val_loss: 0.3421 - val_accuracy: 0.8793\n",
      "Epoch 1164/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3456 - accuracy: 0.8700 - val_loss: 0.3424 - val_accuracy: 0.8769\n",
      "Epoch 1165/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3456 - accuracy: 0.8712 - val_loss: 0.3421 - val_accuracy: 0.8787\n",
      "Epoch 1166/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3449 - accuracy: 0.8704 - val_loss: 0.3434 - val_accuracy: 0.8776\n",
      "Epoch 1167/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3471 - accuracy: 0.8701 - val_loss: 0.3425 - val_accuracy: 0.8781\n",
      "Epoch 1168/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3434 - accuracy: 0.8705 - val_loss: 0.3418 - val_accuracy: 0.8789\n",
      "Epoch 1169/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8689 - val_loss: 0.3454 - val_accuracy: 0.8781\n",
      "Epoch 1170/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3451 - accuracy: 0.8712 - val_loss: 0.3421 - val_accuracy: 0.8788\n",
      "Epoch 1171/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3455 - accuracy: 0.8704 - val_loss: 0.3396 - val_accuracy: 0.8777\n",
      "Epoch 1172/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3467 - accuracy: 0.8702 - val_loss: 0.3439 - val_accuracy: 0.8771\n",
      "Epoch 1173/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3448 - accuracy: 0.8704 - val_loss: 0.3429 - val_accuracy: 0.8788\n",
      "Epoch 1174/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3419 - accuracy: 0.8719 - val_loss: 0.3425 - val_accuracy: 0.8795\n",
      "Epoch 1175/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8700 - val_loss: 0.3431 - val_accuracy: 0.8792\n",
      "Epoch 1176/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3443 - accuracy: 0.8699 - val_loss: 0.3409 - val_accuracy: 0.8789\n",
      "Epoch 1177/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8716 - val_loss: 0.3410 - val_accuracy: 0.8794\n",
      "Epoch 1178/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3413 - accuracy: 0.8713 - val_loss: 0.3422 - val_accuracy: 0.8786\n",
      "Epoch 1179/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3454 - accuracy: 0.8702 - val_loss: 0.3403 - val_accuracy: 0.8783\n",
      "Epoch 1180/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8703 - val_loss: 0.3437 - val_accuracy: 0.8783\n",
      "Epoch 1181/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3439 - accuracy: 0.8713 - val_loss: 0.3408 - val_accuracy: 0.8781\n",
      "Epoch 1182/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3458 - accuracy: 0.8717 - val_loss: 0.3421 - val_accuracy: 0.8779\n",
      "Epoch 1183/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8707 - val_loss: 0.3412 - val_accuracy: 0.8783\n",
      "Epoch 1184/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8713 - val_loss: 0.3439 - val_accuracy: 0.8772\n",
      "Epoch 1185/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3439 - accuracy: 0.8700 - val_loss: 0.3406 - val_accuracy: 0.8788\n",
      "Epoch 1186/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3457 - accuracy: 0.8704 - val_loss: 0.3461 - val_accuracy: 0.8770\n",
      "Epoch 1187/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3470 - accuracy: 0.8698 - val_loss: 0.3460 - val_accuracy: 0.8770\n",
      "Epoch 1188/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3420 - accuracy: 0.8716 - val_loss: 0.3471 - val_accuracy: 0.8779\n",
      "Epoch 1189/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3424 - accuracy: 0.8718 - val_loss: 0.3445 - val_accuracy: 0.8761\n",
      "Epoch 1190/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3452 - accuracy: 0.8704 - val_loss: 0.3455 - val_accuracy: 0.8762\n",
      "Epoch 1191/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3415 - accuracy: 0.8710 - val_loss: 0.3416 - val_accuracy: 0.8786\n",
      "Epoch 1192/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3459 - accuracy: 0.8710 - val_loss: 0.3430 - val_accuracy: 0.8781\n",
      "Epoch 1193/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3428 - accuracy: 0.8702 - val_loss: 0.3442 - val_accuracy: 0.8763\n",
      "Epoch 1194/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8708 - val_loss: 0.3414 - val_accuracy: 0.8770\n",
      "Epoch 1195/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3402 - accuracy: 0.8718 - val_loss: 0.3442 - val_accuracy: 0.8769\n",
      "Epoch 1196/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3446 - accuracy: 0.8710 - val_loss: 0.3433 - val_accuracy: 0.8775\n",
      "Epoch 1197/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3448 - accuracy: 0.8705 - val_loss: 0.3463 - val_accuracy: 0.8770\n",
      "Epoch 1198/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3474 - accuracy: 0.8696 - val_loss: 0.3441 - val_accuracy: 0.8771\n",
      "Epoch 1199/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3453 - accuracy: 0.8699 - val_loss: 0.3436 - val_accuracy: 0.8783\n",
      "Epoch 1200/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8689 - val_loss: 0.3413 - val_accuracy: 0.8782\n",
      "Epoch 1201/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3453 - accuracy: 0.8714 - val_loss: 0.3391 - val_accuracy: 0.8784\n",
      "Epoch 1202/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3443 - accuracy: 0.8707 - val_loss: 0.3415 - val_accuracy: 0.8782\n",
      "Epoch 1203/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3451 - accuracy: 0.8704 - val_loss: 0.3412 - val_accuracy: 0.8771\n",
      "Epoch 1204/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3460 - accuracy: 0.8708 - val_loss: 0.3434 - val_accuracy: 0.8769\n",
      "Epoch 1205/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3455 - accuracy: 0.8704 - val_loss: 0.3442 - val_accuracy: 0.8780\n",
      "Epoch 1206/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3402 - accuracy: 0.8725 - val_loss: 0.3451 - val_accuracy: 0.8776\n",
      "Epoch 1207/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8705 - val_loss: 0.3408 - val_accuracy: 0.8783\n",
      "Epoch 1208/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3418 - accuracy: 0.8713 - val_loss: 0.3443 - val_accuracy: 0.8771\n",
      "Epoch 1209/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3444 - accuracy: 0.8706 - val_loss: 0.3440 - val_accuracy: 0.8763\n",
      "Epoch 1210/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3447 - accuracy: 0.8700 - val_loss: 0.3431 - val_accuracy: 0.8768\n",
      "Epoch 1211/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3449 - accuracy: 0.8697 - val_loss: 0.3435 - val_accuracy: 0.8777\n",
      "Epoch 1212/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3437 - accuracy: 0.8711 - val_loss: 0.3419 - val_accuracy: 0.8780\n",
      "Epoch 1213/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3440 - accuracy: 0.8708 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
      "Epoch 1214/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3456 - accuracy: 0.8699 - val_loss: 0.3398 - val_accuracy: 0.8781\n",
      "Epoch 1215/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8707 - val_loss: 0.3408 - val_accuracy: 0.8777\n",
      "Epoch 1216/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3458 - accuracy: 0.8701 - val_loss: 0.3401 - val_accuracy: 0.8783\n",
      "Epoch 1217/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3419 - accuracy: 0.8718 - val_loss: 0.3398 - val_accuracy: 0.8783\n",
      "Epoch 1218/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3412 - accuracy: 0.8724 - val_loss: 0.3421 - val_accuracy: 0.8773\n",
      "Epoch 1219/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3438 - accuracy: 0.8715 - val_loss: 0.3428 - val_accuracy: 0.8771\n",
      "Epoch 1220/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3452 - accuracy: 0.8698 - val_loss: 0.3403 - val_accuracy: 0.8781\n",
      "Epoch 1221/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3457 - accuracy: 0.8699 - val_loss: 0.3405 - val_accuracy: 0.8772\n",
      "Epoch 1222/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3445 - accuracy: 0.8715 - val_loss: 0.3428 - val_accuracy: 0.8790\n",
      "Epoch 1223/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3437 - accuracy: 0.8709 - val_loss: 0.3421 - val_accuracy: 0.8776\n",
      "Epoch 1224/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3430 - accuracy: 0.8711 - val_loss: 0.3418 - val_accuracy: 0.8775\n",
      "Epoch 1225/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3410 - accuracy: 0.8716 - val_loss: 0.3441 - val_accuracy: 0.8781\n",
      "Epoch 1226/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3420 - accuracy: 0.8713 - val_loss: 0.3427 - val_accuracy: 0.8781\n",
      "Epoch 1227/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3435 - accuracy: 0.8717 - val_loss: 0.3449 - val_accuracy: 0.8786\n",
      "Epoch 1228/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3437 - accuracy: 0.8711 - val_loss: 0.3419 - val_accuracy: 0.8786\n",
      "Epoch 1229/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3458 - accuracy: 0.8695 - val_loss: 0.3418 - val_accuracy: 0.8787\n",
      "Epoch 1230/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8704 - val_loss: 0.3425 - val_accuracy: 0.8780\n",
      "Epoch 1231/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3403 - accuracy: 0.8732 - val_loss: 0.3448 - val_accuracy: 0.8779\n",
      "Epoch 1232/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3435 - accuracy: 0.8708 - val_loss: 0.3424 - val_accuracy: 0.8770\n",
      "Epoch 1233/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3410 - accuracy: 0.8715 - val_loss: 0.3452 - val_accuracy: 0.8781\n",
      "Epoch 1234/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3438 - accuracy: 0.8709 - val_loss: 0.3435 - val_accuracy: 0.8772\n",
      "Epoch 1235/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3455 - accuracy: 0.8712 - val_loss: 0.3421 - val_accuracy: 0.8785\n",
      "Epoch 1236/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3438 - accuracy: 0.8710 - val_loss: 0.3427 - val_accuracy: 0.8785\n",
      "Epoch 1237/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3399 - accuracy: 0.8722 - val_loss: 0.3429 - val_accuracy: 0.8795\n",
      "Epoch 1238/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3433 - accuracy: 0.8707 - val_loss: 0.3402 - val_accuracy: 0.8788\n",
      "Epoch 1239/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3424 - accuracy: 0.8704 - val_loss: 0.3391 - val_accuracy: 0.8790\n",
      "Epoch 1240/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3419 - accuracy: 0.8727 - val_loss: 0.3430 - val_accuracy: 0.8790\n",
      "Epoch 1241/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3423 - accuracy: 0.8716 - val_loss: 0.3405 - val_accuracy: 0.8786\n",
      "Epoch 1242/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3441 - accuracy: 0.8714 - val_loss: 0.3410 - val_accuracy: 0.8781\n",
      "Epoch 1243/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3427 - accuracy: 0.8710 - val_loss: 0.3416 - val_accuracy: 0.8783\n",
      "Epoch 1244/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3445 - accuracy: 0.8709 - val_loss: 0.3387 - val_accuracy: 0.8792\n",
      "Epoch 1245/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3425 - accuracy: 0.8707 - val_loss: 0.3439 - val_accuracy: 0.8781\n",
      "Epoch 1246/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3414 - accuracy: 0.8716 - val_loss: 0.3442 - val_accuracy: 0.8778\n",
      "Epoch 1247/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3447 - accuracy: 0.8716 - val_loss: 0.3422 - val_accuracy: 0.8779\n",
      "Epoch 1248/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3439 - accuracy: 0.8708 - val_loss: 0.3428 - val_accuracy: 0.8779\n",
      "Epoch 1249/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8709 - val_loss: 0.3394 - val_accuracy: 0.8797\n",
      "Epoch 1250/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3438 - accuracy: 0.8713 - val_loss: 0.3412 - val_accuracy: 0.8782\n",
      "Epoch 1251/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3405 - accuracy: 0.8726 - val_loss: 0.3407 - val_accuracy: 0.8797\n",
      "Epoch 1252/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3437 - accuracy: 0.8713 - val_loss: 0.3408 - val_accuracy: 0.8786\n",
      "Epoch 1253/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3397 - accuracy: 0.8721 - val_loss: 0.3411 - val_accuracy: 0.8784\n",
      "Epoch 1254/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3425 - accuracy: 0.8712 - val_loss: 0.3409 - val_accuracy: 0.8783\n",
      "Epoch 1255/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3441 - accuracy: 0.8704 - val_loss: 0.3418 - val_accuracy: 0.8786\n",
      "Epoch 1256/2000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3418 - accuracy: 0.8723 - val_loss: 0.3410 - val_accuracy: 0.8780\n",
      "Epoch 1257/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3453 - accuracy: 0.8701 - val_loss: 0.3435 - val_accuracy: 0.8781\n",
      "Epoch 1258/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3406 - accuracy: 0.8723 - val_loss: 0.3444 - val_accuracy: 0.8775\n",
      "Epoch 1259/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8716 - val_loss: 0.3401 - val_accuracy: 0.8774\n",
      "Epoch 1260/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3429 - accuracy: 0.8723 - val_loss: 0.3376 - val_accuracy: 0.8794\n",
      "Epoch 1261/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3409 - accuracy: 0.8716 - val_loss: 0.3379 - val_accuracy: 0.8791\n",
      "Epoch 1262/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3425 - accuracy: 0.8711 - val_loss: 0.3429 - val_accuracy: 0.8786\n",
      "Epoch 1263/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3415 - accuracy: 0.8717 - val_loss: 0.3415 - val_accuracy: 0.8794\n",
      "Epoch 1264/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3397 - accuracy: 0.8726 - val_loss: 0.3435 - val_accuracy: 0.8793\n",
      "Epoch 1265/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3430 - accuracy: 0.8713 - val_loss: 0.3398 - val_accuracy: 0.8785\n",
      "Epoch 1266/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3435 - accuracy: 0.8705 - val_loss: 0.3402 - val_accuracy: 0.8791\n",
      "Epoch 1267/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.8708 - val_loss: 0.3421 - val_accuracy: 0.8779\n",
      "Epoch 1268/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3410 - accuracy: 0.8733 - val_loss: 0.3402 - val_accuracy: 0.8777\n",
      "Epoch 1269/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3402 - accuracy: 0.8720 - val_loss: 0.3393 - val_accuracy: 0.8776\n",
      "Epoch 1270/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3423 - accuracy: 0.8722 - val_loss: 0.3413 - val_accuracy: 0.8774\n",
      "Epoch 1271/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3439 - accuracy: 0.8713 - val_loss: 0.3423 - val_accuracy: 0.8780\n",
      "Epoch 1272/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3405 - accuracy: 0.8732 - val_loss: 0.3431 - val_accuracy: 0.8777\n",
      "Epoch 1273/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3403 - accuracy: 0.8719 - val_loss: 0.3434 - val_accuracy: 0.8768\n",
      "Epoch 1274/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3421 - accuracy: 0.8715 - val_loss: 0.3430 - val_accuracy: 0.8773\n",
      "Epoch 1275/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3440 - accuracy: 0.8717 - val_loss: 0.3422 - val_accuracy: 0.8787\n",
      "Epoch 1276/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3398 - accuracy: 0.8720 - val_loss: 0.3422 - val_accuracy: 0.8778\n",
      "Epoch 1277/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3404 - accuracy: 0.8716 - val_loss: 0.3397 - val_accuracy: 0.8785\n",
      "Epoch 1278/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3398 - accuracy: 0.8726 - val_loss: 0.3397 - val_accuracy: 0.8783\n",
      "Epoch 1279/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3400 - accuracy: 0.8720 - val_loss: 0.3399 - val_accuracy: 0.8803\n",
      "Epoch 1280/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3394 - accuracy: 0.8724 - val_loss: 0.3403 - val_accuracy: 0.8791\n",
      "Epoch 1281/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.8721 - val_loss: 0.3381 - val_accuracy: 0.8791\n",
      "Epoch 1282/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3417 - accuracy: 0.8719 - val_loss: 0.3415 - val_accuracy: 0.8787\n",
      "Epoch 1283/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3426 - accuracy: 0.8703 - val_loss: 0.3386 - val_accuracy: 0.8800\n",
      "Epoch 1284/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3421 - accuracy: 0.8718 - val_loss: 0.3420 - val_accuracy: 0.8787\n",
      "Epoch 1285/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3427 - accuracy: 0.8711 - val_loss: 0.3442 - val_accuracy: 0.8787\n",
      "Epoch 1286/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3396 - accuracy: 0.8736 - val_loss: 0.3388 - val_accuracy: 0.8804\n",
      "Epoch 1287/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3406 - accuracy: 0.8717 - val_loss: 0.3403 - val_accuracy: 0.8792\n",
      "Epoch 1288/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3406 - accuracy: 0.8713 - val_loss: 0.3431 - val_accuracy: 0.8780\n",
      "Epoch 1289/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3434 - accuracy: 0.8716 - val_loss: 0.3406 - val_accuracy: 0.8792\n",
      "Epoch 1290/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.8718 - val_loss: 0.3366 - val_accuracy: 0.8794\n",
      "Epoch 1291/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3416 - accuracy: 0.8719 - val_loss: 0.3409 - val_accuracy: 0.8784\n",
      "Epoch 1292/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3433 - accuracy: 0.8716 - val_loss: 0.3404 - val_accuracy: 0.8795\n",
      "Epoch 1293/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3427 - accuracy: 0.8717 - val_loss: 0.3382 - val_accuracy: 0.8797\n",
      "Epoch 1294/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3407 - accuracy: 0.8716 - val_loss: 0.3398 - val_accuracy: 0.8795\n",
      "Epoch 1295/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3420 - accuracy: 0.8727 - val_loss: 0.3391 - val_accuracy: 0.8788\n",
      "Epoch 1296/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3410 - accuracy: 0.8728 - val_loss: 0.3395 - val_accuracy: 0.8796\n",
      "Epoch 1297/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3419 - accuracy: 0.8719 - val_loss: 0.3409 - val_accuracy: 0.8785\n",
      "Epoch 1298/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3403 - accuracy: 0.8721 - val_loss: 0.3434 - val_accuracy: 0.8784\n",
      "Epoch 1299/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3426 - accuracy: 0.8705 - val_loss: 0.3432 - val_accuracy: 0.8783\n",
      "Epoch 1300/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3395 - accuracy: 0.8724 - val_loss: 0.3450 - val_accuracy: 0.8784\n",
      "Epoch 1301/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3426 - accuracy: 0.8719 - val_loss: 0.3402 - val_accuracy: 0.8786\n",
      "Epoch 1302/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3411 - accuracy: 0.8721 - val_loss: 0.3446 - val_accuracy: 0.8788\n",
      "Epoch 1303/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3415 - accuracy: 0.8715 - val_loss: 0.3408 - val_accuracy: 0.8780\n",
      "Epoch 1304/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3382 - accuracy: 0.8722 - val_loss: 0.3447 - val_accuracy: 0.8776\n",
      "Epoch 1305/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3443 - accuracy: 0.8708 - val_loss: 0.3402 - val_accuracy: 0.8782\n",
      "Epoch 1306/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3413 - accuracy: 0.8716 - val_loss: 0.3417 - val_accuracy: 0.8786\n",
      "Epoch 1307/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3388 - accuracy: 0.8722 - val_loss: 0.3416 - val_accuracy: 0.8784\n",
      "Epoch 1308/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3405 - accuracy: 0.8717 - val_loss: 0.3408 - val_accuracy: 0.8789\n",
      "Epoch 1309/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3413 - accuracy: 0.8715 - val_loss: 0.3394 - val_accuracy: 0.8784\n",
      "Epoch 1310/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3408 - accuracy: 0.8722 - val_loss: 0.3403 - val_accuracy: 0.8787\n",
      "Epoch 1311/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3437 - accuracy: 0.8707 - val_loss: 0.3423 - val_accuracy: 0.8785\n",
      "Epoch 1312/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3441 - accuracy: 0.8706 - val_loss: 0.3426 - val_accuracy: 0.8775\n",
      "Epoch 1313/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3447 - accuracy: 0.8707 - val_loss: 0.3413 - val_accuracy: 0.8777\n",
      "Epoch 1314/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3408 - accuracy: 0.8724 - val_loss: 0.3447 - val_accuracy: 0.8783\n",
      "Epoch 1315/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3403 - accuracy: 0.8720 - val_loss: 0.3450 - val_accuracy: 0.8778\n",
      "Epoch 1316/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3392 - accuracy: 0.8732 - val_loss: 0.3421 - val_accuracy: 0.8785\n",
      "Epoch 1317/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3409 - accuracy: 0.8728 - val_loss: 0.3421 - val_accuracy: 0.8790\n",
      "Epoch 1318/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3392 - accuracy: 0.8730 - val_loss: 0.3403 - val_accuracy: 0.8792\n",
      "Epoch 1319/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.8710 - val_loss: 0.3425 - val_accuracy: 0.8791\n",
      "Epoch 1320/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3425 - accuracy: 0.8714 - val_loss: 0.3418 - val_accuracy: 0.8781\n",
      "Epoch 1321/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3394 - accuracy: 0.8723 - val_loss: 0.3429 - val_accuracy: 0.8787\n",
      "Epoch 1322/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3422 - accuracy: 0.8714 - val_loss: 0.3407 - val_accuracy: 0.8786\n",
      "Epoch 1323/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3400 - accuracy: 0.8725 - val_loss: 0.3392 - val_accuracy: 0.8785\n",
      "Epoch 1324/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3409 - accuracy: 0.8728 - val_loss: 0.3424 - val_accuracy: 0.8789\n",
      "Epoch 1325/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3390 - accuracy: 0.8739 - val_loss: 0.3429 - val_accuracy: 0.8798\n",
      "Epoch 1326/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3408 - accuracy: 0.8716 - val_loss: 0.3412 - val_accuracy: 0.8806\n",
      "Epoch 1327/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3422 - accuracy: 0.8716 - val_loss: 0.3410 - val_accuracy: 0.8798\n",
      "Epoch 1328/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3419 - accuracy: 0.8710 - val_loss: 0.3409 - val_accuracy: 0.8795\n",
      "Epoch 1329/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3415 - accuracy: 0.8734 - val_loss: 0.3402 - val_accuracy: 0.8798\n",
      "Epoch 1330/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3396 - accuracy: 0.8728 - val_loss: 0.3419 - val_accuracy: 0.8783\n",
      "Epoch 1331/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3399 - accuracy: 0.8726 - val_loss: 0.3395 - val_accuracy: 0.8794\n",
      "Epoch 1332/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3408 - accuracy: 0.8717 - val_loss: 0.3392 - val_accuracy: 0.8787\n",
      "Epoch 1333/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3375 - accuracy: 0.8739 - val_loss: 0.3416 - val_accuracy: 0.8783\n",
      "Epoch 1334/2000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3383 - accuracy: 0.8729 - val_loss: 0.3440 - val_accuracy: 0.8791\n",
      "Epoch 1335/2000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3388 - accuracy: 0.8723 - val_loss: 0.3403 - val_accuracy: 0.8793\n",
      "Epoch 1336/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3397 - accuracy: 0.8709 - val_loss: 0.3385 - val_accuracy: 0.8807\n",
      "Epoch 1337/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3391 - accuracy: 0.8712 - val_loss: 0.3419 - val_accuracy: 0.8792\n",
      "Epoch 1338/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3406 - accuracy: 0.8724 - val_loss: 0.3414 - val_accuracy: 0.8790\n",
      "Epoch 1339/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3420 - accuracy: 0.8718 - val_loss: 0.3401 - val_accuracy: 0.8784\n",
      "Epoch 1340/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3411 - accuracy: 0.8716 - val_loss: 0.3402 - val_accuracy: 0.8791\n",
      "Epoch 1341/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3421 - accuracy: 0.8710 - val_loss: 0.3429 - val_accuracy: 0.8786\n",
      "Epoch 1342/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3425 - accuracy: 0.8708 - val_loss: 0.3431 - val_accuracy: 0.8791\n",
      "Epoch 1343/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3416 - accuracy: 0.8725 - val_loss: 0.3411 - val_accuracy: 0.8791\n",
      "Epoch 1344/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3407 - accuracy: 0.8718 - val_loss: 0.3402 - val_accuracy: 0.8786\n",
      "Epoch 1345/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3409 - accuracy: 0.8725 - val_loss: 0.3417 - val_accuracy: 0.8788\n",
      "Epoch 1346/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3393 - accuracy: 0.8731 - val_loss: 0.3425 - val_accuracy: 0.8780\n",
      "Epoch 1347/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3418 - accuracy: 0.8715 - val_loss: 0.3433 - val_accuracy: 0.8786\n",
      "Epoch 1348/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3393 - accuracy: 0.8724 - val_loss: 0.3401 - val_accuracy: 0.8790\n",
      "Epoch 1349/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3406 - accuracy: 0.8722 - val_loss: 0.3401 - val_accuracy: 0.8797\n",
      "Epoch 1350/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3407 - accuracy: 0.8721 - val_loss: 0.3426 - val_accuracy: 0.8785\n",
      "Epoch 1351/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3434 - accuracy: 0.8712 - val_loss: 0.3398 - val_accuracy: 0.8795\n",
      "Epoch 1352/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3394 - accuracy: 0.8720 - val_loss: 0.3411 - val_accuracy: 0.8794\n",
      "Epoch 1353/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3409 - accuracy: 0.8717 - val_loss: 0.3412 - val_accuracy: 0.8792\n",
      "Epoch 1354/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3387 - accuracy: 0.8730 - val_loss: 0.3414 - val_accuracy: 0.8798\n",
      "Epoch 1355/2000\n",
      "188/188 [==============================] - 2s 12ms/step - loss: 0.3412 - accuracy: 0.8724 - val_loss: 0.3404 - val_accuracy: 0.8789\n",
      "Epoch 1356/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3399 - accuracy: 0.8722 - val_loss: 0.3380 - val_accuracy: 0.8800\n",
      "Epoch 1357/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3392 - accuracy: 0.8726 - val_loss: 0.3396 - val_accuracy: 0.8803\n",
      "Epoch 1358/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3429 - accuracy: 0.8718 - val_loss: 0.3414 - val_accuracy: 0.8790\n",
      "Epoch 1359/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3396 - accuracy: 0.8722 - val_loss: 0.3396 - val_accuracy: 0.8791\n",
      "Epoch 1360/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3401 - accuracy: 0.8737 - val_loss: 0.3448 - val_accuracy: 0.8789\n",
      "Epoch 1361/2000\n",
      "188/188 [==============================] - 2s 11ms/step - loss: 0.3400 - accuracy: 0.8728 - val_loss: 0.3380 - val_accuracy: 0.8803\n",
      "Epoch 1362/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3416 - accuracy: 0.8714 - val_loss: 0.3427 - val_accuracy: 0.8771\n",
      "Epoch 1363/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3380 - accuracy: 0.8731 - val_loss: 0.3424 - val_accuracy: 0.8791\n",
      "Epoch 1364/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3400 - accuracy: 0.8720 - val_loss: 0.3412 - val_accuracy: 0.8780\n",
      "Epoch 1365/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3419 - accuracy: 0.8716 - val_loss: 0.3369 - val_accuracy: 0.8797\n",
      "Epoch 1366/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3382 - accuracy: 0.8749 - val_loss: 0.3404 - val_accuracy: 0.8792\n",
      "Epoch 1367/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3404 - accuracy: 0.8721 - val_loss: 0.3397 - val_accuracy: 0.8792\n",
      "Epoch 1368/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3382 - accuracy: 0.8725 - val_loss: 0.3423 - val_accuracy: 0.8788\n",
      "Epoch 1369/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3400 - accuracy: 0.8724 - val_loss: 0.3418 - val_accuracy: 0.8796\n",
      "Epoch 1370/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3391 - accuracy: 0.8733 - val_loss: 0.3399 - val_accuracy: 0.8784\n",
      "Epoch 1371/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3395 - accuracy: 0.8717 - val_loss: 0.3411 - val_accuracy: 0.8783\n",
      "Epoch 1372/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3403 - accuracy: 0.8730 - val_loss: 0.3407 - val_accuracy: 0.8801\n",
      "Epoch 1373/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3424 - accuracy: 0.8725 - val_loss: 0.3430 - val_accuracy: 0.8781\n",
      "Epoch 1374/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3389 - accuracy: 0.8730 - val_loss: 0.3433 - val_accuracy: 0.8773\n",
      "Epoch 1375/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.8732 - val_loss: 0.3425 - val_accuracy: 0.8784\n",
      "Epoch 1376/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3398 - accuracy: 0.8722 - val_loss: 0.3438 - val_accuracy: 0.8793\n",
      "Epoch 1377/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8736 - val_loss: 0.3376 - val_accuracy: 0.8793\n",
      "Epoch 1378/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3382 - accuracy: 0.8727 - val_loss: 0.3421 - val_accuracy: 0.8797\n",
      "Epoch 1379/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3395 - accuracy: 0.8723 - val_loss: 0.3404 - val_accuracy: 0.8795\n",
      "Epoch 1380/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3390 - accuracy: 0.8733 - val_loss: 0.3431 - val_accuracy: 0.8779\n",
      "Epoch 1381/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3384 - accuracy: 0.8735 - val_loss: 0.3384 - val_accuracy: 0.8785\n",
      "Epoch 1382/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3394 - accuracy: 0.8723 - val_loss: 0.3407 - val_accuracy: 0.8773\n",
      "Epoch 1383/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3391 - accuracy: 0.8734 - val_loss: 0.3422 - val_accuracy: 0.8792\n",
      "Epoch 1384/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3411 - accuracy: 0.8717 - val_loss: 0.3444 - val_accuracy: 0.8778\n",
      "Epoch 1385/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8723 - val_loss: 0.3407 - val_accuracy: 0.8798\n",
      "Epoch 1386/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3381 - accuracy: 0.8733 - val_loss: 0.3395 - val_accuracy: 0.8788\n",
      "Epoch 1387/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.8740 - val_loss: 0.3398 - val_accuracy: 0.8791\n",
      "Epoch 1388/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3410 - accuracy: 0.8722 - val_loss: 0.3403 - val_accuracy: 0.8788\n",
      "Epoch 1389/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3407 - accuracy: 0.8722 - val_loss: 0.3403 - val_accuracy: 0.8795\n",
      "Epoch 1390/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3426 - accuracy: 0.8702 - val_loss: 0.3408 - val_accuracy: 0.8798\n",
      "Epoch 1391/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8731 - val_loss: 0.3392 - val_accuracy: 0.8787\n",
      "Epoch 1392/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3414 - accuracy: 0.8719 - val_loss: 0.3408 - val_accuracy: 0.8787\n",
      "Epoch 1393/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3410 - accuracy: 0.8718 - val_loss: 0.3393 - val_accuracy: 0.8787\n",
      "Epoch 1394/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3409 - accuracy: 0.8721 - val_loss: 0.3400 - val_accuracy: 0.8787\n",
      "Epoch 1395/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3392 - accuracy: 0.8717 - val_loss: 0.3394 - val_accuracy: 0.8797\n",
      "Epoch 1396/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3404 - accuracy: 0.8720 - val_loss: 0.3419 - val_accuracy: 0.8791\n",
      "Epoch 1397/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8739 - val_loss: 0.3414 - val_accuracy: 0.8781\n",
      "Epoch 1398/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3371 - accuracy: 0.8742 - val_loss: 0.3381 - val_accuracy: 0.8796\n",
      "Epoch 1399/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.8732 - val_loss: 0.3419 - val_accuracy: 0.8785\n",
      "Epoch 1400/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3376 - accuracy: 0.8733 - val_loss: 0.3427 - val_accuracy: 0.8790\n",
      "Epoch 1401/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3389 - accuracy: 0.8730 - val_loss: 0.3431 - val_accuracy: 0.8782\n",
      "Epoch 1402/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8734 - val_loss: 0.3393 - val_accuracy: 0.8803\n",
      "Epoch 1403/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3401 - accuracy: 0.8731 - val_loss: 0.3431 - val_accuracy: 0.8798\n",
      "Epoch 1404/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3388 - accuracy: 0.8732 - val_loss: 0.3397 - val_accuracy: 0.8783\n",
      "Epoch 1405/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3390 - accuracy: 0.8730 - val_loss: 0.3414 - val_accuracy: 0.8788\n",
      "Epoch 1406/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8734 - val_loss: 0.3380 - val_accuracy: 0.8800\n",
      "Epoch 1407/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3348 - accuracy: 0.8750 - val_loss: 0.3386 - val_accuracy: 0.8793\n",
      "Epoch 1408/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3385 - accuracy: 0.8726 - val_loss: 0.3412 - val_accuracy: 0.8792\n",
      "Epoch 1409/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8736 - val_loss: 0.3414 - val_accuracy: 0.8782\n",
      "Epoch 1410/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3416 - accuracy: 0.8726 - val_loss: 0.3393 - val_accuracy: 0.8796\n",
      "Epoch 1411/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8731 - val_loss: 0.3398 - val_accuracy: 0.8796\n",
      "Epoch 1412/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8736 - val_loss: 0.3417 - val_accuracy: 0.8793\n",
      "Epoch 1413/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3410 - accuracy: 0.8718 - val_loss: 0.3401 - val_accuracy: 0.8797\n",
      "Epoch 1414/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3375 - accuracy: 0.8738 - val_loss: 0.3412 - val_accuracy: 0.8771\n",
      "Epoch 1415/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3379 - accuracy: 0.8732 - val_loss: 0.3414 - val_accuracy: 0.8798\n",
      "Epoch 1416/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3370 - accuracy: 0.8742 - val_loss: 0.3426 - val_accuracy: 0.8779\n",
      "Epoch 1417/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3406 - accuracy: 0.8721 - val_loss: 0.3424 - val_accuracy: 0.8783\n",
      "Epoch 1418/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3401 - accuracy: 0.8729 - val_loss: 0.3384 - val_accuracy: 0.8803\n",
      "Epoch 1419/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3416 - accuracy: 0.8712 - val_loss: 0.3411 - val_accuracy: 0.8796\n",
      "Epoch 1420/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3380 - accuracy: 0.8731 - val_loss: 0.3398 - val_accuracy: 0.8794\n",
      "Epoch 1421/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3388 - accuracy: 0.8727 - val_loss: 0.3452 - val_accuracy: 0.8777\n",
      "Epoch 1422/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3385 - accuracy: 0.8729 - val_loss: 0.3396 - val_accuracy: 0.8793\n",
      "Epoch 1423/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3337 - accuracy: 0.8743 - val_loss: 0.3436 - val_accuracy: 0.8791\n",
      "Epoch 1424/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3397 - accuracy: 0.8719 - val_loss: 0.3419 - val_accuracy: 0.8792\n",
      "Epoch 1425/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3394 - accuracy: 0.8720 - val_loss: 0.3394 - val_accuracy: 0.8789\n",
      "Epoch 1426/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3389 - accuracy: 0.8724 - val_loss: 0.3408 - val_accuracy: 0.8791\n",
      "Epoch 1427/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3393 - accuracy: 0.8728 - val_loss: 0.3426 - val_accuracy: 0.8785\n",
      "Epoch 1428/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3404 - accuracy: 0.8725 - val_loss: 0.3391 - val_accuracy: 0.8788\n",
      "Epoch 1429/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3393 - accuracy: 0.8724 - val_loss: 0.3404 - val_accuracy: 0.8793\n",
      "Epoch 1430/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3379 - accuracy: 0.8734 - val_loss: 0.3404 - val_accuracy: 0.8789\n",
      "Epoch 1431/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3392 - accuracy: 0.8730 - val_loss: 0.3410 - val_accuracy: 0.8781\n",
      "Epoch 1432/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8724 - val_loss: 0.3413 - val_accuracy: 0.8776\n",
      "Epoch 1433/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8723 - val_loss: 0.3381 - val_accuracy: 0.8784\n",
      "Epoch 1434/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.8728 - val_loss: 0.3406 - val_accuracy: 0.8802\n",
      "Epoch 1435/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3392 - accuracy: 0.8731 - val_loss: 0.3440 - val_accuracy: 0.8791\n",
      "Epoch 1436/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3380 - accuracy: 0.8730 - val_loss: 0.3396 - val_accuracy: 0.8794\n",
      "Epoch 1437/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3405 - accuracy: 0.8724 - val_loss: 0.3407 - val_accuracy: 0.8781\n",
      "Epoch 1438/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.8726 - val_loss: 0.3423 - val_accuracy: 0.8796\n",
      "Epoch 1439/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8728 - val_loss: 0.3391 - val_accuracy: 0.8795\n",
      "Epoch 1440/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3359 - accuracy: 0.8736 - val_loss: 0.3427 - val_accuracy: 0.8782\n",
      "Epoch 1441/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3381 - accuracy: 0.8725 - val_loss: 0.3403 - val_accuracy: 0.8800\n",
      "Epoch 1442/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3389 - accuracy: 0.8718 - val_loss: 0.3398 - val_accuracy: 0.8801\n",
      "Epoch 1443/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3353 - accuracy: 0.8736 - val_loss: 0.3402 - val_accuracy: 0.8793\n",
      "Epoch 1444/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3391 - accuracy: 0.8732 - val_loss: 0.3421 - val_accuracy: 0.8791\n",
      "Epoch 1445/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3409 - accuracy: 0.8715 - val_loss: 0.3415 - val_accuracy: 0.8805\n",
      "Epoch 1446/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3369 - accuracy: 0.8737 - val_loss: 0.3394 - val_accuracy: 0.8803\n",
      "Epoch 1447/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8725 - val_loss: 0.3395 - val_accuracy: 0.8786\n",
      "Epoch 1448/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3376 - accuracy: 0.8730 - val_loss: 0.3424 - val_accuracy: 0.8788\n",
      "Epoch 1449/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3398 - accuracy: 0.8725 - val_loss: 0.3383 - val_accuracy: 0.8785\n",
      "Epoch 1450/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.8733 - val_loss: 0.3408 - val_accuracy: 0.8793\n",
      "Epoch 1451/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3395 - accuracy: 0.8739 - val_loss: 0.3373 - val_accuracy: 0.8803\n",
      "Epoch 1452/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8726 - val_loss: 0.3413 - val_accuracy: 0.8790\n",
      "Epoch 1453/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3375 - accuracy: 0.8734 - val_loss: 0.3416 - val_accuracy: 0.8795\n",
      "Epoch 1454/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3381 - accuracy: 0.8735 - val_loss: 0.3397 - val_accuracy: 0.8789\n",
      "Epoch 1455/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3385 - accuracy: 0.8724 - val_loss: 0.3401 - val_accuracy: 0.8793\n",
      "Epoch 1456/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3383 - accuracy: 0.8721 - val_loss: 0.3391 - val_accuracy: 0.8796\n",
      "Epoch 1457/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3389 - accuracy: 0.8724 - val_loss: 0.3417 - val_accuracy: 0.8801\n",
      "Epoch 1458/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3383 - accuracy: 0.8733 - val_loss: 0.3386 - val_accuracy: 0.8790\n",
      "Epoch 1459/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3409 - accuracy: 0.8726 - val_loss: 0.3410 - val_accuracy: 0.8793\n",
      "Epoch 1460/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3376 - accuracy: 0.8734 - val_loss: 0.3388 - val_accuracy: 0.8796\n",
      "Epoch 1461/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3387 - accuracy: 0.8729 - val_loss: 0.3382 - val_accuracy: 0.8796\n",
      "Epoch 1462/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3386 - accuracy: 0.8724 - val_loss: 0.3402 - val_accuracy: 0.8804\n",
      "Epoch 1463/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.8724 - val_loss: 0.3407 - val_accuracy: 0.8795\n",
      "Epoch 1464/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3339 - accuracy: 0.8746 - val_loss: 0.3385 - val_accuracy: 0.8806\n",
      "Epoch 1465/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3373 - accuracy: 0.8738 - val_loss: 0.3403 - val_accuracy: 0.8796\n",
      "Epoch 1466/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3394 - accuracy: 0.8724 - val_loss: 0.3370 - val_accuracy: 0.8798\n",
      "Epoch 1467/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3376 - accuracy: 0.8741 - val_loss: 0.3352 - val_accuracy: 0.8796\n",
      "Epoch 1468/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3372 - accuracy: 0.8746 - val_loss: 0.3397 - val_accuracy: 0.8796\n",
      "Epoch 1469/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3389 - accuracy: 0.8728 - val_loss: 0.3410 - val_accuracy: 0.8793\n",
      "Epoch 1470/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3392 - accuracy: 0.8726 - val_loss: 0.3398 - val_accuracy: 0.8799\n",
      "Epoch 1471/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3391 - accuracy: 0.8725 - val_loss: 0.3371 - val_accuracy: 0.8806\n",
      "Epoch 1472/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.8727 - val_loss: 0.3422 - val_accuracy: 0.8791\n",
      "Epoch 1473/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3399 - accuracy: 0.8715 - val_loss: 0.3387 - val_accuracy: 0.8801\n",
      "Epoch 1474/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3407 - accuracy: 0.8719 - val_loss: 0.3395 - val_accuracy: 0.8799\n",
      "Epoch 1475/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3357 - accuracy: 0.8749 - val_loss: 0.3396 - val_accuracy: 0.8799\n",
      "Epoch 1476/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3364 - accuracy: 0.8737 - val_loss: 0.3393 - val_accuracy: 0.8794\n",
      "Epoch 1477/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3399 - accuracy: 0.8735 - val_loss: 0.3383 - val_accuracy: 0.8801\n",
      "Epoch 1478/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3386 - accuracy: 0.8731 - val_loss: 0.3411 - val_accuracy: 0.8793\n",
      "Epoch 1479/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3356 - accuracy: 0.8741 - val_loss: 0.3397 - val_accuracy: 0.8797\n",
      "Epoch 1480/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3359 - accuracy: 0.8745 - val_loss: 0.3396 - val_accuracy: 0.8798\n",
      "Epoch 1481/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3387 - accuracy: 0.8727 - val_loss: 0.3399 - val_accuracy: 0.8794\n",
      "Epoch 1482/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3369 - accuracy: 0.8732 - val_loss: 0.3401 - val_accuracy: 0.8809\n",
      "Epoch 1483/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3379 - accuracy: 0.8724 - val_loss: 0.3375 - val_accuracy: 0.8805\n",
      "Epoch 1484/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3382 - accuracy: 0.8725 - val_loss: 0.3405 - val_accuracy: 0.8795\n",
      "Epoch 1485/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3386 - accuracy: 0.8727 - val_loss: 0.3391 - val_accuracy: 0.8801\n",
      "Epoch 1486/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3381 - accuracy: 0.8732 - val_loss: 0.3373 - val_accuracy: 0.8806\n",
      "Epoch 1487/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3400 - accuracy: 0.8726 - val_loss: 0.3377 - val_accuracy: 0.8802\n",
      "Epoch 1488/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3387 - accuracy: 0.8734 - val_loss: 0.3373 - val_accuracy: 0.8807\n",
      "Epoch 1489/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3366 - accuracy: 0.8735 - val_loss: 0.3388 - val_accuracy: 0.8787\n",
      "Epoch 1490/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.8741 - val_loss: 0.3368 - val_accuracy: 0.8806\n",
      "Epoch 1491/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3376 - accuracy: 0.8730 - val_loss: 0.3382 - val_accuracy: 0.8803\n",
      "Epoch 1492/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3362 - accuracy: 0.8739 - val_loss: 0.3382 - val_accuracy: 0.8817\n",
      "Epoch 1493/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.8728 - val_loss: 0.3368 - val_accuracy: 0.8807\n",
      "Epoch 1494/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3358 - accuracy: 0.8737 - val_loss: 0.3364 - val_accuracy: 0.8802\n",
      "Epoch 1495/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3356 - accuracy: 0.8745 - val_loss: 0.3395 - val_accuracy: 0.8782\n",
      "Epoch 1496/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3377 - accuracy: 0.8731 - val_loss: 0.3399 - val_accuracy: 0.8783\n",
      "Epoch 1497/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3359 - accuracy: 0.8740 - val_loss: 0.3400 - val_accuracy: 0.8801\n",
      "Epoch 1498/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3391 - accuracy: 0.8736 - val_loss: 0.3411 - val_accuracy: 0.8791\n",
      "Epoch 1499/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3378 - accuracy: 0.8742 - val_loss: 0.3418 - val_accuracy: 0.8793\n",
      "Epoch 1500/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3367 - accuracy: 0.8737 - val_loss: 0.3413 - val_accuracy: 0.8778\n",
      "Epoch 1501/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3384 - accuracy: 0.8733 - val_loss: 0.3403 - val_accuracy: 0.8775\n",
      "Epoch 1502/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3375 - accuracy: 0.8736 - val_loss: 0.3408 - val_accuracy: 0.8791\n",
      "Epoch 1503/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3384 - accuracy: 0.8725 - val_loss: 0.3430 - val_accuracy: 0.8786\n",
      "Epoch 1504/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3373 - accuracy: 0.8736 - val_loss: 0.3420 - val_accuracy: 0.8778\n",
      "Epoch 1505/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3374 - accuracy: 0.8735 - val_loss: 0.3391 - val_accuracy: 0.8782\n",
      "Epoch 1506/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3380 - accuracy: 0.8725 - val_loss: 0.3389 - val_accuracy: 0.8787\n",
      "Epoch 1507/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3358 - accuracy: 0.8737 - val_loss: 0.3390 - val_accuracy: 0.8781\n",
      "Epoch 1508/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3378 - accuracy: 0.8731 - val_loss: 0.3424 - val_accuracy: 0.8782\n",
      "Epoch 1509/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3367 - accuracy: 0.8741 - val_loss: 0.3403 - val_accuracy: 0.8773\n",
      "Epoch 1510/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3335 - accuracy: 0.8750 - val_loss: 0.3395 - val_accuracy: 0.8786\n",
      "Epoch 1511/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8739 - val_loss: 0.3410 - val_accuracy: 0.8792\n",
      "Epoch 1512/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3392 - accuracy: 0.8727 - val_loss: 0.3428 - val_accuracy: 0.8772\n",
      "Epoch 1513/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8732 - val_loss: 0.3408 - val_accuracy: 0.8795\n",
      "Epoch 1514/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3388 - accuracy: 0.8721 - val_loss: 0.3400 - val_accuracy: 0.8789\n",
      "Epoch 1515/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3333 - accuracy: 0.8749 - val_loss: 0.3416 - val_accuracy: 0.8804\n",
      "Epoch 1516/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3363 - accuracy: 0.8741 - val_loss: 0.3399 - val_accuracy: 0.8776\n",
      "Epoch 1517/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8738 - val_loss: 0.3367 - val_accuracy: 0.8791\n",
      "Epoch 1518/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3370 - accuracy: 0.8736 - val_loss: 0.3387 - val_accuracy: 0.8790\n",
      "Epoch 1519/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3362 - accuracy: 0.8746 - val_loss: 0.3421 - val_accuracy: 0.8784\n",
      "Epoch 1520/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8739 - val_loss: 0.3367 - val_accuracy: 0.8797\n",
      "Epoch 1521/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3359 - accuracy: 0.8741 - val_loss: 0.3426 - val_accuracy: 0.8793\n",
      "Epoch 1522/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3371 - accuracy: 0.8734 - val_loss: 0.3388 - val_accuracy: 0.8800\n",
      "Epoch 1523/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3377 - accuracy: 0.8743 - val_loss: 0.3406 - val_accuracy: 0.8788\n",
      "Epoch 1524/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3373 - accuracy: 0.8742 - val_loss: 0.3394 - val_accuracy: 0.8787\n",
      "Epoch 1525/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3396 - accuracy: 0.8732 - val_loss: 0.3398 - val_accuracy: 0.8791\n",
      "Epoch 1526/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3383 - accuracy: 0.8733 - val_loss: 0.3407 - val_accuracy: 0.8798\n",
      "Epoch 1527/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3371 - accuracy: 0.8738 - val_loss: 0.3380 - val_accuracy: 0.8809\n",
      "Epoch 1528/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3362 - accuracy: 0.8742 - val_loss: 0.3399 - val_accuracy: 0.8788\n",
      "Epoch 1529/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3374 - accuracy: 0.8740 - val_loss: 0.3374 - val_accuracy: 0.8799\n",
      "Epoch 1530/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3361 - accuracy: 0.8739 - val_loss: 0.3404 - val_accuracy: 0.8794\n",
      "Epoch 1531/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3385 - accuracy: 0.8734 - val_loss: 0.3416 - val_accuracy: 0.8779\n",
      "Epoch 1532/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3364 - accuracy: 0.8733 - val_loss: 0.3381 - val_accuracy: 0.8792\n",
      "Epoch 1533/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3360 - accuracy: 0.8740 - val_loss: 0.3403 - val_accuracy: 0.8806\n",
      "Epoch 1534/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3366 - accuracy: 0.8728 - val_loss: 0.3392 - val_accuracy: 0.8790\n",
      "Epoch 1535/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3354 - accuracy: 0.8744 - val_loss: 0.3428 - val_accuracy: 0.8790\n",
      "Epoch 1536/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3372 - accuracy: 0.8724 - val_loss: 0.3388 - val_accuracy: 0.8806\n",
      "Epoch 1537/2000\n",
      "188/188 [==============================] - 1s 7ms/step - loss: 0.3369 - accuracy: 0.8741 - val_loss: 0.3403 - val_accuracy: 0.8796\n",
      "Epoch 1538/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3375 - accuracy: 0.8739 - val_loss: 0.3400 - val_accuracy: 0.8794\n",
      "Epoch 1539/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3380 - accuracy: 0.8733 - val_loss: 0.3414 - val_accuracy: 0.8801\n",
      "Epoch 1540/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3371 - accuracy: 0.8728 - val_loss: 0.3392 - val_accuracy: 0.8801\n",
      "Epoch 1541/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3352 - accuracy: 0.8760 - val_loss: 0.3394 - val_accuracy: 0.8801\n",
      "Epoch 1542/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3368 - accuracy: 0.8730 - val_loss: 0.3416 - val_accuracy: 0.8801\n",
      "Epoch 1543/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3383 - accuracy: 0.8728 - val_loss: 0.3418 - val_accuracy: 0.8791\n",
      "Epoch 1544/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3385 - accuracy: 0.8732 - val_loss: 0.3400 - val_accuracy: 0.8793\n",
      "Epoch 1545/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3382 - accuracy: 0.8732 - val_loss: 0.3398 - val_accuracy: 0.8794\n",
      "Epoch 1546/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3361 - accuracy: 0.8738 - val_loss: 0.3429 - val_accuracy: 0.8792\n",
      "Epoch 1547/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3385 - accuracy: 0.8730 - val_loss: 0.3383 - val_accuracy: 0.8805\n",
      "Epoch 1548/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3370 - accuracy: 0.8735 - val_loss: 0.3417 - val_accuracy: 0.8791\n",
      "Epoch 1549/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3350 - accuracy: 0.8746 - val_loss: 0.3400 - val_accuracy: 0.8797\n",
      "Epoch 1550/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3357 - accuracy: 0.8743 - val_loss: 0.3399 - val_accuracy: 0.8792\n",
      "Epoch 1551/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3372 - accuracy: 0.8733 - val_loss: 0.3393 - val_accuracy: 0.8802\n",
      "Epoch 1552/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3348 - accuracy: 0.8743 - val_loss: 0.3389 - val_accuracy: 0.8790\n",
      "Epoch 1553/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3370 - accuracy: 0.8732 - val_loss: 0.3401 - val_accuracy: 0.8789\n",
      "Epoch 1554/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3369 - accuracy: 0.8738 - val_loss: 0.3396 - val_accuracy: 0.8792\n",
      "Epoch 1555/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3347 - accuracy: 0.8741 - val_loss: 0.3408 - val_accuracy: 0.8783\n",
      "Epoch 1556/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3359 - accuracy: 0.8748 - val_loss: 0.3418 - val_accuracy: 0.8788\n",
      "Epoch 1557/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3357 - accuracy: 0.8739 - val_loss: 0.3430 - val_accuracy: 0.8782\n",
      "Epoch 1558/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.8735 - val_loss: 0.3425 - val_accuracy: 0.8789\n",
      "Epoch 1559/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3363 - accuracy: 0.8743 - val_loss: 0.3437 - val_accuracy: 0.8798\n",
      "Epoch 1560/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3355 - accuracy: 0.8747 - val_loss: 0.3380 - val_accuracy: 0.8809\n",
      "Epoch 1561/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3359 - accuracy: 0.8742 - val_loss: 0.3411 - val_accuracy: 0.8801\n",
      "Epoch 1562/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3363 - accuracy: 0.8746 - val_loss: 0.3397 - val_accuracy: 0.8806\n",
      "Epoch 1563/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3377 - accuracy: 0.8750 - val_loss: 0.3387 - val_accuracy: 0.8813\n",
      "Epoch 1564/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3362 - accuracy: 0.8740 - val_loss: 0.3386 - val_accuracy: 0.8784\n",
      "Epoch 1565/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3372 - accuracy: 0.8748 - val_loss: 0.3398 - val_accuracy: 0.8805\n",
      "Epoch 1566/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.8746 - val_loss: 0.3394 - val_accuracy: 0.8808\n",
      "Epoch 1567/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3360 - accuracy: 0.8746 - val_loss: 0.3395 - val_accuracy: 0.8813\n",
      "Epoch 1568/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3377 - accuracy: 0.8741 - val_loss: 0.3412 - val_accuracy: 0.8796\n",
      "Epoch 1569/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3352 - accuracy: 0.8735 - val_loss: 0.3396 - val_accuracy: 0.8798\n",
      "Epoch 1570/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3357 - accuracy: 0.8737 - val_loss: 0.3408 - val_accuracy: 0.8795\n",
      "Epoch 1571/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3336 - accuracy: 0.8752 - val_loss: 0.3407 - val_accuracy: 0.8800\n",
      "Epoch 1572/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3358 - accuracy: 0.8744 - val_loss: 0.3412 - val_accuracy: 0.8795\n",
      "Epoch 1573/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3345 - accuracy: 0.8747 - val_loss: 0.3416 - val_accuracy: 0.8788\n",
      "Epoch 1574/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3374 - accuracy: 0.8726 - val_loss: 0.3397 - val_accuracy: 0.8790\n",
      "Epoch 1575/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3364 - accuracy: 0.8750 - val_loss: 0.3416 - val_accuracy: 0.8795\n",
      "Epoch 1576/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3337 - accuracy: 0.8740 - val_loss: 0.3410 - val_accuracy: 0.8782\n",
      "Epoch 1577/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3337 - accuracy: 0.8750 - val_loss: 0.3404 - val_accuracy: 0.8793\n",
      "Epoch 1578/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3343 - accuracy: 0.8742 - val_loss: 0.3406 - val_accuracy: 0.8788\n",
      "Epoch 1579/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3329 - accuracy: 0.8759 - val_loss: 0.3416 - val_accuracy: 0.8794\n",
      "Epoch 1580/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3334 - accuracy: 0.8738 - val_loss: 0.3384 - val_accuracy: 0.8799\n",
      "Epoch 1581/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3346 - accuracy: 0.8753 - val_loss: 0.3420 - val_accuracy: 0.8785\n",
      "Epoch 1582/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3342 - accuracy: 0.8746 - val_loss: 0.3389 - val_accuracy: 0.8790\n",
      "Epoch 1583/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3338 - accuracy: 0.8737 - val_loss: 0.3383 - val_accuracy: 0.8795\n",
      "Epoch 1584/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3362 - accuracy: 0.8738 - val_loss: 0.3405 - val_accuracy: 0.8792\n",
      "Epoch 1585/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3347 - accuracy: 0.8755 - val_loss: 0.3363 - val_accuracy: 0.8797\n",
      "Epoch 1586/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3346 - accuracy: 0.8740 - val_loss: 0.3391 - val_accuracy: 0.8801\n",
      "Epoch 1587/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3328 - accuracy: 0.8758 - val_loss: 0.3390 - val_accuracy: 0.8808\n",
      "Epoch 1588/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3331 - accuracy: 0.8753 - val_loss: 0.3403 - val_accuracy: 0.8795\n",
      "Epoch 1589/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3360 - accuracy: 0.8741 - val_loss: 0.3440 - val_accuracy: 0.8795\n",
      "Epoch 1590/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3344 - accuracy: 0.8743 - val_loss: 0.3377 - val_accuracy: 0.8809\n",
      "Epoch 1591/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3361 - accuracy: 0.8731 - val_loss: 0.3402 - val_accuracy: 0.8793\n",
      "Epoch 1592/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3373 - accuracy: 0.8733 - val_loss: 0.3391 - val_accuracy: 0.8806\n",
      "Epoch 1593/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3356 - accuracy: 0.8744 - val_loss: 0.3403 - val_accuracy: 0.8809\n",
      "Epoch 1594/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3362 - accuracy: 0.8732 - val_loss: 0.3420 - val_accuracy: 0.8798\n",
      "Epoch 1595/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3341 - accuracy: 0.8746 - val_loss: 0.3403 - val_accuracy: 0.8790\n",
      "Epoch 1596/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3349 - accuracy: 0.8747 - val_loss: 0.3402 - val_accuracy: 0.8806\n",
      "Epoch 1597/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3346 - accuracy: 0.8740 - val_loss: 0.3395 - val_accuracy: 0.8794\n",
      "Epoch 1598/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3319 - accuracy: 0.8758 - val_loss: 0.3411 - val_accuracy: 0.8793\n",
      "Epoch 1599/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3339 - accuracy: 0.8747 - val_loss: 0.3423 - val_accuracy: 0.8794\n",
      "Epoch 1600/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3353 - accuracy: 0.8744 - val_loss: 0.3399 - val_accuracy: 0.8794\n",
      "Epoch 1601/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3322 - accuracy: 0.8745 - val_loss: 0.3412 - val_accuracy: 0.8794\n",
      "Epoch 1602/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3377 - accuracy: 0.8744 - val_loss: 0.3442 - val_accuracy: 0.8784\n",
      "Epoch 1603/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3351 - accuracy: 0.8741 - val_loss: 0.3361 - val_accuracy: 0.8808\n",
      "Epoch 1604/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3353 - accuracy: 0.8748 - val_loss: 0.3408 - val_accuracy: 0.8789\n",
      "Epoch 1605/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3369 - accuracy: 0.8743 - val_loss: 0.3405 - val_accuracy: 0.8801\n",
      "Epoch 1606/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3363 - accuracy: 0.8733 - val_loss: 0.3404 - val_accuracy: 0.8803\n",
      "Epoch 1607/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3339 - accuracy: 0.8751 - val_loss: 0.3410 - val_accuracy: 0.8797\n",
      "Epoch 1608/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3309 - accuracy: 0.8758 - val_loss: 0.3422 - val_accuracy: 0.8787\n",
      "Epoch 1609/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3357 - accuracy: 0.8743 - val_loss: 0.3439 - val_accuracy: 0.8794\n",
      "Epoch 1610/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.8738 - val_loss: 0.3374 - val_accuracy: 0.8808\n",
      "Epoch 1611/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3356 - accuracy: 0.8746 - val_loss: 0.3377 - val_accuracy: 0.8806\n",
      "Epoch 1612/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3358 - accuracy: 0.8739 - val_loss: 0.3403 - val_accuracy: 0.8792\n",
      "Epoch 1613/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3334 - accuracy: 0.8750 - val_loss: 0.3377 - val_accuracy: 0.8799\n",
      "Epoch 1614/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3364 - accuracy: 0.8734 - val_loss: 0.3403 - val_accuracy: 0.8795\n",
      "Epoch 1615/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3356 - accuracy: 0.8747 - val_loss: 0.3376 - val_accuracy: 0.8789\n",
      "Epoch 1616/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3367 - accuracy: 0.8731 - val_loss: 0.3416 - val_accuracy: 0.8789\n",
      "Epoch 1617/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3365 - accuracy: 0.8740 - val_loss: 0.3419 - val_accuracy: 0.8778\n",
      "Epoch 1618/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3322 - accuracy: 0.8750 - val_loss: 0.3405 - val_accuracy: 0.8803\n",
      "Epoch 1619/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3353 - accuracy: 0.8751 - val_loss: 0.3401 - val_accuracy: 0.8797\n",
      "Epoch 1620/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3362 - accuracy: 0.8733 - val_loss: 0.3419 - val_accuracy: 0.8794\n",
      "Epoch 1621/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3365 - accuracy: 0.8740 - val_loss: 0.3372 - val_accuracy: 0.8811\n",
      "Epoch 1622/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3351 - accuracy: 0.8727 - val_loss: 0.3401 - val_accuracy: 0.8790\n",
      "Epoch 1623/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3331 - accuracy: 0.8741 - val_loss: 0.3391 - val_accuracy: 0.8803\n",
      "Epoch 1624/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3344 - accuracy: 0.8748 - val_loss: 0.3418 - val_accuracy: 0.8799\n",
      "Epoch 1625/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3352 - accuracy: 0.8746 - val_loss: 0.3425 - val_accuracy: 0.8797\n",
      "Epoch 1626/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3361 - accuracy: 0.8743 - val_loss: 0.3367 - val_accuracy: 0.8808\n",
      "Epoch 1627/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3361 - accuracy: 0.8743 - val_loss: 0.3388 - val_accuracy: 0.8791\n",
      "Epoch 1628/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3336 - accuracy: 0.8743 - val_loss: 0.3375 - val_accuracy: 0.8793\n",
      "Epoch 1629/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3334 - accuracy: 0.8743 - val_loss: 0.3374 - val_accuracy: 0.8808\n",
      "Epoch 1630/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3341 - accuracy: 0.8745 - val_loss: 0.3425 - val_accuracy: 0.8782\n",
      "Epoch 1631/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3347 - accuracy: 0.8747 - val_loss: 0.3400 - val_accuracy: 0.8781\n",
      "Epoch 1632/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3354 - accuracy: 0.8738 - val_loss: 0.3405 - val_accuracy: 0.8794\n",
      "Epoch 1633/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3355 - accuracy: 0.8742 - val_loss: 0.3410 - val_accuracy: 0.8798\n",
      "Epoch 1634/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3348 - accuracy: 0.8754 - val_loss: 0.3394 - val_accuracy: 0.8798\n",
      "Epoch 1635/2000\n",
      "188/188 [==============================] - 1s 8ms/step - loss: 0.3326 - accuracy: 0.8744 - val_loss: 0.3415 - val_accuracy: 0.8796\n",
      "Epoch 1636/2000\n",
      "188/188 [==============================] - 2s 10ms/step - loss: 0.3327 - accuracy: 0.8748 - val_loss: 0.3400 - val_accuracy: 0.8789\n",
      "Epoch 1637/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3371 - accuracy: 0.8744 - val_loss: 0.3357 - val_accuracy: 0.8805\n",
      "Epoch 1638/2000\n",
      "188/188 [==============================] - 2s 9ms/step - loss: 0.3339 - accuracy: 0.8746 - val_loss: 0.3387 - val_accuracy: 0.8789\n",
      "Epoch 1639/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3330 - accuracy: 0.8758 - val_loss: 0.3362 - val_accuracy: 0.8802\n",
      "Epoch 1640/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3340 - accuracy: 0.8749 - val_loss: 0.3382 - val_accuracy: 0.8796\n",
      "Epoch 1641/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3337 - accuracy: 0.8746 - val_loss: 0.3417 - val_accuracy: 0.8788\n",
      "Epoch 1642/2000\n",
      "188/188 [==============================] - 2s 8ms/step - loss: 0.3364 - accuracy: 0.8740 - val_loss: 0.3427 - val_accuracy: 0.8791\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x= X_train, y= y_train, validation_data= (X_test, y_test), validation_split= 0.1, batch_size= 512, epochs=2000, verbose=1, \n",
    "          callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 2s 3ms/step - loss: 0.3382 - accuracy: 0.8817\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3381553888320923, 0.8816792368888855]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABR8AAAIjCAYAAACK3myEAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAADw9klEQVR4nOzdd3gUVdvH8e/uZtMbISGhBEIv0qs0RWmKYhfFQrHwWFCU1wIqIBawInZ8HgG7otgFEUSaVEGl995JgJCebLL7/jHJJksSCEs2m4Tf57py7cyZMzP3nmRhcucUk8PhcCAiIiIiIiIiIiJSyszeDkBEREREREREREQqJyUfRURERERERERExCOUfBQRERERERERERGPUPJRREREREREREREPELJRxEREREREREREfEIJR9FRERERERERETEI5R8FBEREREREREREY9Q8lFEREREREREREQ8QslHERERERERERER8QglH0VESmDPnj2YTCY++uijcz534cKFmEwmFi5ceMZ6H330ESaTiT179rgVo4iIiIiUH2Xx/CgiUhEo+SgiIiIiIiIiIiIeoeSjiIiIiIiIiIiIeISSjyIiIiIiIiLicampqd4OQUS8QMlHEakQnn32WUwmE9u2beOOO+4gLCyMqKgoxowZg8PhYP/+/Vx77bWEhoYSExPD66+/Xugax44d4+677yY6Ohp/f39atWrFxx9/XKheYmIiQ4YMISwsjPDwcAYPHkxiYmKRcW3ZsoWbbrqJiIgI/P39ad++PT/99FOpvvf33nuPiy66CD8/P2rUqMGDDz5YKJ7t27dz4403EhMTg7+/P7Vq1eLWW2/l1KlTzjrz5s2jW7duhIeHExwcTOPGjXnqqadKNVYRERGR8uJCeH7cu3cvDzzwAI0bNyYgIICqVaty8803FzmHeGJiIo8++ihxcXH4+flRq1YtBg0aREJCgrNORkYGzz77LI0aNcLf35/q1atzww03sHPnTqD4uSiLmt9yyJAhBAcHs3PnTvr160dISAi33347AEuWLOHmm2+mdu3a+Pn5ERsby6OPPkp6enqR7TVgwACioqIICAigcePGPP300wAsWLAAk8nE999/X+i8L774ApPJxPLly8+1WUWklPl4OwARkXNxyy230LRpU1566SVmzZrFCy+8QEREBB988AGXX345L7/8Mp9//jmPPfYYHTp04JJLLgEgPT2dHj16sGPHDoYPH07dunX55ptvGDJkCImJiYwYMQIAh8PBtddey59//sl9991H06ZN+f777xk8eHChWDZu3EjXrl2pWbMmo0aNIigoiK+//prrrruOb7/9luuvv/683++zzz7L+PHj6dWrF/fffz9bt27l/fff56+//mLp0qVYrVaysrLo27cvmZmZPPTQQ8TExHDw4EF++eUXEhMTCQsLY+PGjVx99dW0bNmS5557Dj8/P3bs2MHSpUvPO0YRERGR8qwyPz/+9ddfLFu2jFtvvZVatWqxZ88e3n//fXr06MGmTZsIDAwEICUlhe7du7N582buuusu2rZtS0JCAj/99BMHDhwgMjKSnJwcrr76aubPn8+tt97KiBEjSE5OZt68eWzYsIH69eufc9tnZ2fTt29funXrxmuvveaM55tvviEtLY3777+fqlWrsmrVKt5++20OHDjAN9984zx/3bp1dO/eHavVyrBhw4iLi2Pnzp38/PPPvPjii/To0YPY2Fg+//zzQm33+eefU79+fTp37nzOcYtIKXOIiFQA48aNcwCOYcOGOcuys7MdtWrVcphMJsdLL73kLD958qQjICDAMXjwYGfZ5MmTHYDjs88+c5ZlZWU5Onfu7AgODnYkJSU5HA6H44cffnAAjldeecXlPt27d3cAjunTpzvLe/bs6WjRooUjIyPDWWa32x1dunRxNGzY0Fm2YMECB+BYsGDBGd/j9OnTHYBj9+7dDofD4Th27JjD19fX0adPH0dOTo6z3jvvvOMAHNOmTXM4HA7HP//84wAc33zzTbHXfuONNxyAIz4+/owxiIiIiFQWF8LzY1paWqGy5cuXOwDHJ5984iwbO3asA3B89913herb7XaHw+FwTJs2zQE4Jk2aVGyd4uLavXt3ofc6ePBgB+AYNWpUieKeOHGiw2QyOfbu3essu+SSSxwhISEuZQXjcTgcjtGjRzv8/PwciYmJzrJjx445fHx8HOPGjSt0HxEpexp2LSIVyj333OPctlgstG/fHofDwd133+0sDw8Pp3HjxuzatctZNnv2bGJiYhg4cKCzzGq18vDDD5OSksKiRYuc9Xx8fLj//vtd7vPQQw+5xHHixAn++OMPBgwYQHJyMgkJCSQkJHD8+HH69u3L9u3bOXjw4Hm9199//52srCweeeQRzOb8f67vvfdeQkNDmTVrFgBhYWEA/Pbbb6SlpRV5rfDwcAB+/PFH7Hb7ecUlIiIiUpFU5ufHgIAA57bNZuP48eM0aNCA8PBw/v77b+exb7/9llatWhXZs9JkMjnrREZGFoq7YB13FGyXouJOTU0lISGBLl264HA4+OeffwCIj49n8eLF3HXXXdSuXbvYeAYNGkRmZiYzZ850ls2YMYPs7GzuuOMOt+MWkdKj5KOIVCinP3iEhYXh7+9PZGRkofKTJ0869/fu3UvDhg1dkngATZs2dR7Pe61evTrBwcEu9Ro3buyyv2PHDhwOB2PGjCEqKsrla9y4cYAxR9D5yIvp9Hv7+vpSr1495/G6desycuRIPvzwQyIjI+nbty/vvvuuy3yPt9xyC127duWee+4hOjqaW2+9la+//lqJSBEREan0KvPzY3p6OmPHjiU2NhY/Pz8iIyOJiooiMTHR5Vlw586dNG/e/IzX2rlzJ40bN8bHp/RmZ/Px8aFWrVqFyvft28eQIUOIiIggODiYqKgoLr30UgBn3HmJ4LPF3aRJEzp06MDnn3/uLPv888+5+OKLadCgQWm9FRE5D5rzUUQqFIvFUqIyMObf8ZS8pN1jjz1G3759i6xTlg87r7/+OkOGDOHHH39k7ty5PPzww0ycOJEVK1ZQq1YtAgICWLx4MQsWLGDWrFnMmTOHGTNmcPnllzN37txi21BERESkoqvMz48PPfQQ06dP55FHHqFz586EhYVhMpm49dZbPfJH5uJ6QObk5BRZ7ufnVyh5m5OTQ+/evTlx4gRPPvkkTZo0ISgoiIMHDzJkyBC34h40aBAjRozgwIEDZGZmsmLFCt55551zvo6IeIaSjyJyQahTpw7r1q3Dbre7PABt2bLFeTzvdf78+aSkpLj89Xrr1q0u16tXrx5gDL3p1auXx2LOu3fe/QCysrLYvXt3ofu2aNGCFi1a8Mwzz7Bs2TK6du3KlClTeOGFFwAwm8307NmTnj17MmnSJCZMmMDTTz/NggULPPYeRERERCqqivD8OHPmTAYPHuyyUndGRkahlbbr16/Phg0bznit+vXrs3LlSmw2G1artcg6VapUASh0/bxeoCWxfv16tm3bxscff8ygQYOc5fPmzXOpl9deZ4sb4NZbb2XkyJF8+eWXpKenY7VaueWWW0ock4h4loZdi8gFoV+/fhw5coQZM2Y4y7Kzs3n77bcJDg52DvPo168f2dnZvP/++856OTk5vP322y7Xq1atGj169OCDDz7g8OHDhe4XHx9/3jH36tULX19f3nrrLZe/wk+dOpVTp05x1VVXAZCUlER2drbLuS1atMBsNpOZmQkYcwydrnXr1gDOOiIiIiKSryI8P1oslkK9Nd9+++1CPRFvvPFG1q5dy/fff1/oGnnn33jjjSQkJBTZYzCvTp06dbBYLCxevNjl+HvvvXdOMRe8Zt72m2++6VIvKiqKSy65hGnTprFv374i48kTGRnJlVdeyWeffcbnn3/OFVdcUWhYvYh4j3o+isgFYdiwYXzwwQcMGTKENWvWEBcXx8yZM1m6dCmTJ08mJCQEgP79+9O1a1dGjRrFnj17aNasGd99953LnDl53n33Xbp160aLFi249957qVevHkePHmX58uUcOHCAtWvXnlfMUVFRjB49mvHjx3PFFVdwzTXXsHXrVt577z06dOjgnED7jz/+YPjw4dx88800atSI7OxsPv30UywWCzfeeCMAzz33HIsXL+aqq66iTp06HDt2jPfee49atWrRrVu384pTREREpDKqCM+PV199NZ9++ilhYWE0a9aM5cuX8/vvv1O1alWXeo8//jgzZ87k5ptv5q677qJdu3acOHGCn376iSlTptCqVSsGDRrEJ598wsiRI1m1ahXdu3cnNTWV33//nQceeIBrr72WsLAwbr75Zt5++21MJhP169fnl19+Oae5Kps0aUL9+vV57LHHOHjwIKGhoXz77bcu823meeutt+jWrRtt27Zl2LBh1K1blz179jBr1iz+/fdfl7qDBg3ipptuAuD5558/p3YUEc9S8lFELggBAQEsXLiQUaNG8fHHH5OUlETjxo2ZPn06Q4YMcdYzm8389NNPPPLII3z22WeYTCauueYaXn/9ddq0aeNyzWbNmrF69WrGjx/PRx99xPHjx6lWrRpt2rRh7NixpRL3s88+S1RUFO+88w6PPvooERERDBs2jAkTJjiHw7Rq1Yq+ffvy888/c/DgQQIDA2nVqhW//vorF198MQDXXHMNe/bsYdq0aSQkJBAZGcmll17K+PHjnatli4iIiEi+ivD8+Oabb2KxWPj888/JyMiga9eu/P7774XmlAwODmbJkiWMGzeO77//no8//phq1arRs2dP54IwFouF2bNn8+KLL/LFF1/w7bffUrVqVWeyNM/bb7+NzWZjypQp+Pn5MWDAAF599dWzLgyTx2q18vPPPzvnKPf39+f6669n+PDhtGrVyqVuq1atWLFiBWPGjOH9998nIyODOnXqMGDAgELX7d+/P1WqVMFut3PNNdeca1OKiAeZHJ6cUVdERERERERExMOys7OpUaMG/fv3Z+rUqd4OR0QK0JyPIiIiIiIiIlKh/fDDD8THx7ssYiMi5YN6PoqIiIiIiIhIhbRy5UrWrVvH888/T2RkJH///be3QxKR06jno4iIiIiIiIhUSO+//z73338/1apV45NPPvF2OCJSBPV8FBEREREREREREY9Qz0cRERERERERERHxCCUfRURERERERERExCN8vB1AWbPb7Rw6dIiQkBBMJpO3wxERERE5Zw6Hg+TkZGrUqIHZrL8lV0R6JhUREZGK7FyeRy+45OOhQ4eIjY31dhgiIiIi523//v3UqlXL22GIG/RMKiIiIpVBSZ5HL7jkY0hICGA0TmhoqMfuY7PZmDt3Ln369MFqtXrsPpWN2s09ajf3qN3co3Zzj9rNPWq3oiUlJREbG+t8rpGKpyyeSfX5cY/azT1qN/eo3dyntnOP2s09arfCzuV59IJLPuYNawkNDfV48jEwMJDQ0FD9YJ4DtZt71G7uUbu5R+3mHrWbe9RuZ6bhuhVXWTyT6vPjHrWbe9Ru7lG7uU9t5x61m3vUbsUryfOoJgkSERERERERERERj1DyUURERERERERERDxCyUcRERERERERERHxiAtuzkcRERHxPIfDQXZ2Njk5Oed1HZvNho+PDxkZGed9rYrEYrHg4+OjOR0vcDk5OdhsNrfPv1A/P6DPkIiISHmi5KOIiIiUqqysLA4fPkxaWtp5X8vhcBATE8P+/fsvuCRCYGAg1atXx9fX19uhiBekpKRw4MABHA6H29e4kD8/oM+QiIhIeaHko4iIiJQau93O7t27sVgs1KhRA19f3/NKetjtdlJSUggODsZsvjBmi3E4HGRlZREfH8/u3btp2LDhBfPexZCTk8OBAwcIDAwkKirK7c/Qhfj5AX2GREREyhslH0VERKTUZGVlYbfbiY2NJTAw8LyvZ7fbycrKwt/f/4JKHgQEBGC1Wtm7d6/z/cuFw2az4XA4iIqKIiAgwO3rXKifH9BnSEREpDy5sJ5CREREpExcaIkOT1AbyoU4VLo06TMkIiJSPuh/ZBEREREREREREfEIJR9FRERERERERETEI7yefHz33XeJi4vD39+fTp06sWrVqmLr2mw2nnvuOerXr4+/vz+tWrVizpw5ZRitiIiIyNnFxcUxefJkb4chUmHpMyQiIlJ5eDX5OGPGDEaOHMm4ceP4+++/adWqFX379uXYsWNF1n/mmWf44IMPePvtt9m0aRP33Xcf119/Pf/8808ZRy4iIiKVTY8ePXjkkUdK5Vp//fUXw4YNK5VriVQU+gyJiIhIUbyafJw0aRL33nsvQ4cOpVmzZkyZMoXAwECmTZtWZP1PP/2Up556in79+lGvXj3uv/9++vXrx+uvv17GkYuIiMiFxuFwkJ2dXaK6UVFRpbLat0hlos+QiIjIhcnHWzfOyspizZo1jB492llmNpvp1asXy5cvL/KczMxM/P39XcoCAgL4888/i71PZmYmmZmZzv2kpCTAGMJts9nO5y2cUd61PXmPykjt5h61m3vUbu5Ru7nnQmk3m82Gw+HAbrdjt9sBI+GQbstx63oOh4P0rBwsmTa3Vv4NsFpKdN7QoUNZtGgRixYt4s033wRg6tSp3H333fzyyy+MHTuW9evXM2fOHGJjY/m///s/Vq5cSWpqKk2bNuXFF1+kV69ezuvVq1ePESNGMGLECAAsFgsffPABs2fPZu7cudSsWZNXX32Va665ptiY7HY7DocDm82GxWJxOVbZf47ElbufIbvdTnpWDj5Z2W6v/FzSz9CQIUMKfYamT5/O0KFDmT17Ns888wzr169n7ty5xMbGMnLkSFasWOH8DE2cONHlMxQXF8cjjzzi7ElpMpn43//+x6xZs/jtt9+oWbMmr7/++hk/QyIiIlI+eC35mJCQQE5ODtHR0S7l0dHRbNmypchz+vbty6RJk7jkkkuoX78+8+fP57vvviMnp/iHsYkTJzJ+/PhC5XPnzi2Tv6bOmzfP4/eojNRu7lG7uUft5h61m3sqe7v5+PgQExNDSkoKWVlZAKRn5dB50gqvxLN85MUE+FrOWu+5555j8+bNNGvWzPmH0bznkSeffJLnn3+euLg4wsPDOXDgAJdddhmjRo3Cz8+Pr776imuvvZZVq1YRGxsLGEmfjIwM5x89AcaPH8/48eMZO3Ys//3vf7nzzjtZt24dVapUKTKmrKws0tPTWbx4caHeYmlpaW61h1RM6bYcmo39zSv33vRcXwJ9z/4rw5tvvsm2bdto3rw5zz33HAAbN24EYNSoUbz22mvUq1ePKlWqsH//fvr168eLL76In58fn3zyCf3792fr1q3Url272HuMHz+eV155hVdffZW3336b22+/nb179xIREVE6b1ZEREQ8wmvJR3e8+eab3HvvvTRp0gSTyUT9+vUZOnRoscO0AUaPHs3IkSOd+0lJScTGxtKnTx9CQ0M9FqvNZmPevHn07t0bq9XqsftUNmo396jd3KN2c4/azT0XSrtlZGSwf/9+goODnaMVfLJKNszSE0JCQ0qUOAkNDSUwMJCwsDAaNmwIwMGDBwF4/vnnufbaa51169SpQ9euXZ37bdq04ddff2XhwoU8+OCDgDGaw9/f3+VZY+jQodx1110AvPrqq3zwwQds3ryZK664osiYMjIyCAgI4JJLLik08qNgUlOkPAgLC8PX15fAwEBiYmKA/AT+c889R+/evZ11IyIiaNWqlXP/+eef5/vvv+enn35i+PDhxd5jyJAhDBw4EIAJEybw1ltvsWrVqmI/QyIiIlI+eC35GBkZicVi4ejRoy7lR48edT6wnC4qKooffviBjIwMjh8/To0aNRg1ahT16tUr9j5+fn74+fkVKrdarR775S8lM5sF206w/oSJfh68T2Xmye9PZaZ2c4/azT1qN/dU9nbLycnBZDJhNpudwzyD/Kxseq6vW9ez2+0kJyUTEhri1rDRkg4ZzZMXO+B87dixo8u9U1JSePbZZ5k1axaHDx8mOzub9PR09u/f71Kv4LUAWrVq5dwPCQkhNDSUhISEYt+X2WzGZDIV+TNTmX+GpLAAq8Wtz9D5fn7y7n2+2rdv77Jf3Gdo3759Z7xOy5YtndtBQUGEhoYWu1CliIjIeTuyHoJjIDjK25FUeF5LPvr6+tKuXTvmz5/PddddBxgPSPPnzz/jXzwB/P39qVmzJjabjW+//ZYBAwaUQcQldywpg4e+WkuAxcyT3g5GRETEy0wmU4l6HxbFbreT7Wsh0NfH7eTJ+QoKCnLZf+yxx5g3bx6vvfYaDRo0ICAggJtuusk5zLw4pycMTSaTc15MkTNx9zNUHj4/oM+QiIhUQPFbYUo3CKkO/1f01IBuW/waHN0ItTtDx3vBjXnNATi5FzISoXqrs1b1Nq8Oux45ciSDBw+mffv2dOzYkcmTJ5OamsrQoUMBGDRoEDVr1mTixIkArFy5koMHD9K6dWsOHjzIs88+i91u54knnvDm2yiWw9sBiIiISIn5+vqecR7pPEuXLmXIkCFcf/31gNGLa8+ePR6OTqT802dIRKSScTjOLTGWuN+oH1YL9vwJpw5Cq1s8F19JZKZAZhKE1nAtj99mlEc2NOKMbgbJR+GrgVCjLfz1P6Ne8mGwpVMofWbPMdrH4gPJR2BaX2h+E0TUA/8waNgbfPwgK3eebt/cNUc+vxm2zzW2N34H4bWhcYHpQ+K3wbsd8vcvexoaX2kkLLs8DGu/gIuuh7hu8GbuiABrENhtMGQWRDUBWxqEFD2i2Fu8mny85ZZbiI+PZ+zYsRw5coTWrVszZ84c5yI0+/btc/krbUZGBs888wy7du0iODiYfv368emnnxIeHu6ld1C0vOFdSj6KiIhUHHFxcaxcuZI9e/YQHBxcbI+qhg0b8t1339G/f39MJhNjxoxR7ysR9BkSETmrn0dAwna48wfw8fV2NEXbMhvWTIfAqrDxB7h5upH8OpusVHgnN2n25G746CpjO/oiiGmeX+/YFvj2bqMdeoyC7iMhJR72LYfG/YxkXp6Cyc+sVPhxONRoA82ugSpxRrLz85ug7SDobMy7jS0dFk6ExlcZCbmPrgKTGao2hJrt4KLrYN8K+HOSUT+kupFgbHSF0ZMwfjMcXOP63n58EK56M3/fngMfXGLEd+d3MOMOOLkHlrzmel7v5+DPyZB+AtrcAZePzU88Otv7F2jU17iWI8fobVnQgheNL4BNPxivf30IPZ7Kr2NLNV6n9ja+b2nH4faZRgK0nPD6gjPDhw8vdpj1woULXfYvvfRSNm3aVAZRnR/n3wWUfRQREakwHnvsMQYPHkyzZs1IT09n+vTpRdabNGkSd911F126dCEyMpInn3xSC8CIoM+QiJQzqQmwcgq0vh0i6hY+brfDrj+gehsIqur+fc7WO9DhMIbG+obAmo+Mshdy5xBsfYeRfIuoZ1wjOwt2LTASa5GN3B+OmyfpkPFVK3fu3S9uxbrtV6o2eApsl8HRdRAQDlXr55/z1UDXa3x5K9TpaiTmbv/G6CFYlEP/QHa6sf1igV53J/cYycdV/4N5Y41eeXnmj4fdi433DMb7ju0EdS81koMn90BQFJitcCp3XuCN38G8Ma73/u0paH8XWANg5Qew9E3jK4/DDglbja+1X7iem3zYeN02p+j3BbDhW8z+EUB3Yz9+CxzdYGy/3rj48+aNzd/+5zPj+3u6fz41ErG+QbBzfvHXOt3CCUWXpx03Xj+/CcYlnv/PUCnxevKxMion31sRERE5B40aNWL58uUuZUOGDClULy4ujj/++MOlLG+V6zynDyF1OAr/RTIxMdGtOEXKK32GRMSjfnoIEvfBHd+B+SyLYZ3YBbMfhx2/w7oZ8Mh61+MLJsKil4ztmBYwbBHsX2Uk6SynLeq26UfjWpc9De0G55cved3oGXhknbE/9Feo08XYzvs3a9oVsH9F8XH++5nxBXDzx3DgL1j+jrF/7XtQ/zIj8VaSBU/SE2Hj99DsWgiMMMqm94OTuyGsNtizIfkQAN12TCBn0UlY+b5RLzASHttm9BAsyt6lxuv7nWHkFvALMRZjqX0xbP0V5j8HVv+iz51xu5FITdhW9PG8xCMYycaTe4zvWZ685ODZvOjZYcaW1f+jUfWTkNoB3u/i3kXWf110+Zl+Rs7HrJHQ77Wzf17KgJKPHqSOjyIiIiIiIlJu5GQb89zlJafg3Of1K6ldi4ykXb9XoF4P1/tt+sGYp27j90aC8N75xtx3SYeNnnoHVsG/X0DPscbQ0ews+PsT4/zD/0LNdpg2/UCTwz+D40pjrr74zRAWC18MgOM78u+XmNtj7q8Pjd53V7yUn3gEI4n2w/1GwqtWR6hSx5hTr8lVxnx9Xw8y6v38sPF1y2dgyzASbgVNvxIe3WTM7TepmWsPv5L4ZrDr/o8P5G837AOxHeHiB2D1dCPJGVYL0k7A13dCRH0jSXf4X/jlEWPOwYuuNxKPkN9rsABLXuIRIC0B1n0Nq6edPc5JTc7tfUHxiUdvC6gC6SeLKI8whkqfpunhmTB5ZhkEVkq2/158QrmMKfnoASbU9VFERERERETKkT8nw+/jABPc8F9oOcAo//UJWPVfaHQldPqP0dvudCnHjN5x5mISGbuXGEObw2rll31yTe7rtfDUIfAJMOauO31ePIDJLSCuO+xZ4lr++U3w5B5jQZA8Cdth9uP4HFxDY8D+VZJr77miLH0rf6jup9cVPp7X0+7AKuNr/TfQ9RFYOrlw3Rl3FH+fA6vg50fOPfF4NtvnGl8H/4GtswofPz25l3Eqf4h3Sf1wn9vhnbOqDeH49rK7X0EtboYGvY1Xs9kYfn9kLVRrBhZfIxGfmQxvtYXUY+7do90QuGqSMZ+jbzBkpeQnsQvq9Swc+jd/LkeAkBrw6EYjtnVfAyb47p7849VbGz9fed/zK18Fv2AjgV5QTEsjUV5OhuYq+egBed9b9XwUERERERERj3I44PBaY5Xbooa+HlgDB1fnJh4BHMaQ4SZXwUu5w3EBtv1qfD17yvX8PUvho37G/IQd7jKSGnlDkxN2wDvtjO3qrYx595a+ZcyxV9AbzY0ehYf+Kf59nJ54zPNqA9feW9//x+Ww+WyJRyg8R2BJFJV4PJtvhpy9TvObjGRTXrsXpd2QopOHRSUezyZvAZLihNaEpIOFy58+Cq/UNRJdXUcYczF+MwRyipi3MM9t3xg9a7+9G1oMgBY3wbHN8OcbxryXLW6Gq143emY+G5Z/XpW6+b00C7p/ubFq808PGYk8MBaIcTgg5Ujh+t1G5i8kk+f6/xqL3iRshWbXFR6CbDYbi9gU5BcCj26AjCT47Hqjd+yZjD0B2RkwIXdF7b4TjPs0uza/zgMr4b1ORg/fAZ8aq4F3HGYsPPT5AEiNh+7/Z/QSzkvy5/2BIDwWjm40Pl8mE2z4DmYONY51Gmb0aF76lvEeH1xlrOBdzij5KCIiIiIiIlJR/fu5sRpv02vgiolGL76I+kayot0Q+PDywuckHc5PlJzuzdZGIqjjf4wh0788mnufAvMTtrrNWFxk4/f55x1ea6zmXJT0E0UOYy2RMyXp3FUlDjrcC3OfLv1rF6dWB/Dxhz4vwN5lzvkXi3TVJNgyy0hIna9LHofWt8GK9yEjCVunB/jrl4/psvMVYz7JIbNgxp1wtECC7YndRiJ7xDojaZiXzHrmGHzc3+h113Os8XMHRr3gasaCL2AkHfM06mvcP3Ff/sI3BbW8FXqPL3rhlrzFbW75zPg5yEt6OxwwPjy/Xo220GU4XHSD0bZJB+G+JeAfnt87rOCK2yXh42fMtXnfn8ZQ918eKbreg6uMRKNvENz1m1HmG1S4XrUmron9Gq3zt2//+szTH9S+2PjK0+xaaH831Gxr7Ft84D+LjEWWwmqW9B2WKSUfPUldH0VERERERC48h/4xFjW58iVjJePTpSbA4lexrpzCtUBOyJNw+VP5x+122PQ91O4MoQWShHuXGb24/Av0GvtxuPG6+Sdj5eK8uREBFr9SdHyZp4ouh/weaKs+ML6KcvqKweVJq9ug8wNGj7sqcTC1d+E6cd2MZFWVOkUPo25/N6yemr//+E54NXdF6JiWRlKwSl0Y/LOR+Ek+Cq83yq/f/EZjgRp7DrzbwSi78wdjeCxA4yuN61epayTnVk6Bq98w5rmMbGQksx5cZfQ8LIrJAo6c/P3bZxpD1ME4Lz0RpvUx9jvcYyTteowy9m024kObY7trPlayjeHyd80xFlFJ3Gv0HsybEzQ4ynWxG5PJeB8mk9EbtWa7/HjPJLia8VVQr2eNHnxXTDTuN/ArI86qDYz5OS8uMOelyeS6EJDJZCQkf3kUbvzQdU7RIbOM2IqbIsAd7Ydiq3Uxc5Zv5MqGVnzmPWMkVC990vU+BRKEqZnZpGZmUy20mIV4Tncuw6PNFrj6tB6ePn7lNvEISj56hIZdi4iIiIiIXIBS4iF+C3x8tbG//Tejt1PaCWPF4B8eNJJNB1cbKzLnsix+2Ug+OnKHRP/xvHEgvDa0GQTL3jKGs4IxN90DyyErFV5vistvngUTj+XRpU/Copddy5rfBBtKsIhHdHNjIZnsDJdi21PHsMZvMHphNu6Xv+J0TAvj9ekj8Ml1xnyMecPBY1oZr0GnJcQgv8fnpU/CsY0Q1RSCIqHHU8ZqxXd+b+wXFBINTx02epv6+BpD0MFIPlZvZcz7V7A3XO/xENUYmlxtDCPudJ+RBGx/V36dwAgYlwgvVjd6mQLU6Wok15KPwLK3YcW7cOkoY1Ge04fLP3XY6GlZXBKueiuw5ib0/IKNn6l9K6BeEXN+FmQpkEaq1vTMdc+k26PGV57GV+Zv93nh7Oc37W+03+lJO4uH0lxVG2A3b8PRuB80v/as1S95ZQHHU7NY9XRPqoWcOQHpcDi4++PVWC0mejWN5t0FO3hrYBsuqhHG/Z+tITYikDFXN+O/i3eSmpnDo70bFXmdzOwcDidm8OzPG7mudU2ua1N+kpFKPnqAqZxM6CkiIiIiInLBSD9prGZsthhzpxUn7YSRlPENdP9eu5cYw537TjDuu+J9aD0Qvri18CIVBee2AyOBVZTT64ExVHXBaYmYY5uKrnsmeYtenC68jtF7782W53a909W7zHXRlyf3GgmyJa9DXFdY/JrR863bo0Zvzo3fGcmvQ/9A7+fzk48F5zoctR/8Q2HdN3Bip3Husc1Gj7+a7bAd3cLcpf/SJ68HXs12RcdmDTB69oGRAN75B7TPnS+vZjuj11xYLbjkCWO1526PGMdCoo2vPD2eNL6K4xsIsR1cy8wWGLbI2C6YJ/ALMRb3yRNRXA9HE9zwAWz+GepfbsyjaDJBaHVj2HPT/sZcjMXFcy58g6BBz3M75zw5HA4On8qgeph/ifMoSRk2dsen0rJWWKnlXhwOB4dOZVCjBHFkZttZd+gEtaoEYoJiezYeTzXmxly95yT9WlQHIMfuwGyC9QdPYcKE3eHg5TlbCPbz4Y8txr8bv208CsA17yzlp+FdmbvJ2B/SJY4Js7cAEBcZSP2oYH745xD3dK/rbL8h0/5i+S5jfs+FW+OVfKzs8n5U1fNRRERERETkPNjt8MdzUO0iI/kSVLX4ul/cAvtX5p6XYyyM4R8GFz9o9P7KscFXtxu9EWNawr0LICsZ/ELzh406HLB9njH8NK6b0VMu+iLIzoRTB4web1vnwPfDjPpJB40FWRw58Nf/PNsW7vANNpJ9N0+HrwfDzvmux/s8bww9fvaU0Wtv9TTYMrvo+Qh7jjV6miXuM3ptpsYb8/Bt/hmufRfeyJ2fr0qc0e4B4XBjbpu0uRMwGd+H+pcVXlH7hg/BboPIxvnJR/9Q47Xlzfn1Cs6TF1GfbMvWkrVDXkIprpvxlcfiA4N+zN/vPb5k1zsX55sga3at68Ileaz+UKfz+V3by95dsIPX5m5j7NXNuKtbMQnY0wyYspwtR5L5+K6OXNooCofDgclkwpZjx2op+VDr9xbu4Kd/D9E6Npz6UcG8OHszlzWO4o6L69CzqZF0ttsdTFu6m051q9Ik2kjmTvh1C1+sOuC8zvDLGnBv93qEBRq9SNOzcjiYmL/a+al0G+N+3EDbOlUY88MGkjJKPofpnVNXObe7v5Kf3H90xlrn9rSlu6kbGUTzmmHOxGOe/SfSiI04jz+ylCIlH0VERERERKR8+vtjY6XcPAM+geBoo+dY9EXGHHlLXjd6zOUlHgEWvJi/bQ2AhO3GvHp5jqyDWSON6+cJrQmdh8Nvo11j8A0xkpRF2b3Y7bdWam6caryfLiOMpKk9G768Fbo8nN+LD+DWz+HkHgiIMBKHgRGu80lGX2SsRNzpPmMhkS4Pw+/PwvHt0HMcdH7QmFcu6rSFQXo9a7yOWAu2dGPOvtMTbmebE7BggvGOb425EKVCybE7mLX+MJ3qRpCWlcPe46n0aFzEsPZc2Tl2Xpu7DYDnftlUKPn4+6ajpNty6N+qBr9vOsrr87Yx4frmbDlifBa/+/sAY3/cgJ+PmS71I5m55gA/P9SNupFFLPYCLN95nBy7g24NI7HbHbwyx0hc510PYMHWeBZsjWfV0z35ee1hnv9lk/NYh7gqDIzBJfEI8M6CHbyzYAcAzaqHsulwksvxF37ZRGpWDh8v33vG9ivKqXRbiertTkhld0JqofJv/z7AI72KHqJd1pR89ADN+SgiIiIiIpWOPcdILuUtmlEaMk6BLQOCoozeg1/dbiS3ej9nrC6b1wsuz9eD8rc73Q8r3ze25z5T/D1mFTMEu2DiEYxejKcnHqH4xOPZPPiXsYLwzALz+MV1hz1LjO3w2kYvwoIKHi+JnmONlYXzVhfO6xn6+M7CCUBrQP4cfQWHE58usiHcPTc3nm5Gj9GCi44Up0pcyeM+kwa9Suc6FzCHw0G6LYdA35KlfFbsOk6A1ULVYF9qVTF6yi3ZHs/o79bz0g0t6dYwsthzM7NzMGHik+V7eGHWZpdjX/+nMx3rRhQ6Z+Wu4wyatsql7FhyBo99s46NB085hywDdGsQyT2frAbg+veWOct//De/d+62o8aUAq/9tpWuDSK5rk0NDp/KoOfriwrde3DnOhxLziz2/QAs3pbgkngE+GvPSf7ac+b2PD3xCJCalVNEzbIxf/MxJR8rMxOlM++AiIiIlJ0ePXrQunVrJk+eXCrXGzJkCImJifzwww+lcj2R8k6foUoq5ZgxXLfp1XBwDWz41ugFF9vJmMuvALM9y5iTr0aL/MTX/r+MZFZAuOt1V0+HeeNcV13OS8Zt/81YYOVs8hKP5VVUo8Lvu88L8N9Lje1qF5Hd6wX2LvqM+vG5yb4Bn8CXA2H/CrhpGjS9Fjb9YKxyfeUrxnue+4wxVHzIL8YiLEUprXUITo9fKoSX52xlyqKd/PhgV2pWCeBkahYNo0MASEjJxFGgp9S/+xO59b8rnPvLR19OtRB/55DfO6auZO24Psz4ax9XXFSd2lXzh/EmpmXR+rl5QNE/cvM3H6Vj3Qhe+GUTs9YfZsawzrw+b6tL4jBPxxfnF74A0Ob5eSV+37PWH2bW+sM89f36YuuUpAfiY9+sPWud83FPt7rkOBxMX7qnRPXXjutDq/Fziz0eEeTLzPs6M/HXLTx0eQNqhAfw9er99Gp6hj8ylDElHz3A+aFT10cREREREakI9i43Ft0Ij80vSzsBrzU0tvfl9zhifu68eHUvhTu+g8wkLHOepv+6L2Atxvx0/V4z5k788QGjbquBUPtiiGpiJB7XfVU4htN7AZY3wTGQcqToYx2HQZ8XwewDf07KX0AkuBrc84cxNLzepcachde+ZyxQc+XLOIJrsGEn1Lnq//CxWIyh0HfNMVa29s9dVKZgz8YuDxkrIputxqrKckFasj2ekV+vZeL1LejVLJplOxKYv+UYT17RBF8fM1MW7QRg6Ed/cSK3F+HCx3qw6XASD3z+N1H+Fh5ZMZcQPx+SM13nIOw88Y9C9xv+xd8s2Z7AhNlb6NW0Grd1qs3+E+lM/n2bs46jiPzHB4t3sWbvSVbvPQnAJa8uKFypgpv1cDden7sNX4uZKkG+fLmq+H/HHu7ZkLa1w+neMAqL2UT/VjW4Ibc3Z83wAJaOuhyAQ4npdHnJ+D68eH1zwgKsfHNfZz5YtIuxVzfjg8U7+Xxl/n3a1g6nXlQw/xvU3ln2QI8Gnni7blPy0YOUexQREcF4GrWlnb1eUex249wsizFJ/bmyBpao98eQIUNYtGgRixYt4s033wRg9+7dpKSk8Pjjj7NkyRKCgoLo06cPb7zxBpGRxvCjmTNnMn78eHbs2EFgYCBt2rThxx9/5NVXX+Xjj43hfHmrJi5YsIAePXqc+3sQcfczdL6fH9BnqLI6thmWvQ2XPmEMlT2+E6ZfCTiMlXn3LoOO9xorFJ/J7kXwvDHM1+UnbNOPxldBa780vjxp9EFIOgQhMTD3afj7k7Ofc+Wrxgq/Kz+AVR8UX+/2b6HuJZCRmJ+QzRPVFPq9mr9/yWOux2u1g4Ff5O+3ud34ArAZc7o5arYDq7FgBSZTfuKxKL5Fz2knpSM1M5t3Fuzg5na1qBdlTDGQlW3njy1HubheVcIDXZO+aVnZLNtxnG4NI/G35s9t+e6CHew9nsoL17XgyKkMthxJonez6DOuprxm7wke/2YdN7ePpVF0MNl2BxaTiY2HkoiNCOBYcib3dq/H4GmrsDvgnk9Ws3tiP2770JjvtFqIH/YCiYgTBYYvf/jnLj5bYSSs4jOMGE5PPBZnyfYE5/bvm4/x++ZjZ6jtKi/xWBq+uKcTNruDwacN2S4t911a35m4BRjUuQ61IwK5u1tdRn+3jq/+OlDonItqhDFtSP4q579tPOJs96tbVufGtrVoWSuMqsF+hc5tW7sKbw1sw4uzNvHWwNbO8hrhAex56SqXuh3iIugQZwxhf/H6FozrfxFbjyTz8fI9PNbntHlYyyElHz1Ag65FREQKsKXBhBpnr1cEMxB+Pvd+6lCJfkl788032bZtG82bN+e5554DwGq10rFjR+655x7eeOMN0tPTefLJJxkwYAB//PEHhw8fZuDAgbzyyitcf/31JCcns2TJEhwOB4899hibN28mKSmJ6dOnAxARUXjOI5EScfMzdN6fH9BnqDJwOGDNdKjZHqq3NMqm94P0E7BllrFIyNqvcHadyBsSvH9F4QRiWYrrDp3+A3v+NFaYPrkH/vks/3jPsTD/ufz9a98z5qKMyp3frO8EiGyUPxdk20H5yciO/zHO9w3KT673e8WYa3LWSGP/uimQnQEnd0PXR4weiWD0ZBy2yFgVuuUA2PabcW3xqjV7TxLoa6Fp9VC3zs/OsQPgYzHzxMx1zFp/mPcX7uSpfk3YeiSFtKxsft1g9HptFRvOl/d2cs6nOPq79c5hxHMe6U6TmFD+3Z/Iq78ZC5p8vdo1YdWmdjjf3d8Fk8lEcoaNuRuPEp+SSbUQP0Z+bQz3fXnOlmJjfelX12MTZufPszjx1+LPy0s8lmcX14ugflSwS6++PE1iQujSwPjD1Z6XrqLu6FmFelu2q1OF+y6tz4GTaVzaKIo+bywmOzcb+3S/pnRvFMkLv2zm7m51CfC1YAJsOQ7umGokb29qV4thl9Qjx+4gKsQ1Wfhc/6a0N+/h2qv7kZRp57Fv1nJLh9qF4lz5VE9W7DpOuzpVSjTn5jWtanBNq3P/P97Xx0yLWmG8dnOrcz7XG5R89ARlH0VERCqUsLAwfH19CQwMJCYmBoAXXniBNm3aMGHCBGe9adOmERsby7Zt20hJSSE7O5sbbriBOnXqANCiRQtn3YCAADIzM53XE6nM9BkqBw6vhUP/QNvBxmrHJ3bB3qXGIjGzc3vijUs0Fg9JP2HsZyTCy3WKvp43E4+t74Dr3jW2m/Y3Xh0OIyFZqwNUrQ/pifnJx4f/gYh6rtfwCzGGKF90PZw6CDXbQb3LoE4Xo2dkUTrcbQxvPrEbqrcqvtdvjdZwTe6clHHdzuedSik4nprFje8bQ1d3T+x3xp6FLuelZBLs78OhxAwue20hIf4+PH9tc2atP+ysM2F24WTe2v2JDJq6ipn3dwFcFz65YvISXr2pZZHJszz/7Evkq7/2k5RuO2OysKT+t2T3eV+jrM179BKe+2UTS7Yn0L1hJLd3qk2Gzc51bWoCRhLw981HeXeB0QuxXR2jh2BBy0f15GBiGje+vxyAJU9cRq0qAS7f/yVPXsa9n6zGx2zmzs518Lda+OyeTi7XseXY6dW0GnWqBtGgWvGLaZlMJqy5XbyrBvsxfWjHIutZLWa6NyzBAk0XGCUfPcihLKSIiIgxbPOpwhOLl4TdbicpOZnQkBDM7g67dtPatWtZsGABwcGFH0R37txJnz596NmzJy1atKBv37706dOHm266iSpVqrh9T5EiufkZOu/PT9693aTPUAmsnWHMDRhb9C+xRTp10Oh9Z7Hml2UmwweXGNs/jyj+3PHhboXpovtjRvJy9bT8Mt9gyErJ3w+IgJGbweoPM++GDTOLv15ABDS/EbqPhMCqsH2uMZfk6UwmaHVrgfPC4dlTheudLqyW8QXQ/Iaz1/cPM5KLUiHYHbDjWP7PXlJ6Nv6+Zvx8LMWe43A4WHfgFDdNWUa1EH8OJqYDkJyRzSMz/i3RfVfvPUnLZ3/j5vaxhY49PnPdWc8f/V3xC6J4S7cGkbx3R1tC/a10fekPZ7v8PaY3EUG+3P3RX8zfYgy3tlpMmE0mMrPtBPlauKFtLdrHVeGShlG88ttWbu9Um3f+2MHcTUewO6BGmD9LnrycH/89SJOYUBpGh/DJXR3JzLa7DFXP06Z2FYL8fJzJx4+GdiDE3+pSJybMn5gwf6YP7UCmzU5sROH/r6qHBfDLQ93P+L6tFjMfDu5wxjpy/pR89ACtdi0iIlKAyeT+/FR2O1hzjPPdTZ64KSUlhf79+/Pyyy8XOla9enUsFgvz5s1j2bJlzJ07l7fffpunn36alStXUrdu3TKNVSo5dz9DXvz8gD5DZ3VwDXw/zNjOS6LZc2DfCjCZjRWigyLz6+9cABu/h78/Nno3XvMWpJ8EWzosLcHK0Ofr8jHQbaTxs2TPMWLJscETu8FkImfes2zbe5iGrbvg0/Z2I/EIxvBnkxla3gILJ0Ld7nDJ4/DuxUYPxHtOW8k2r6ejVDhZ2XZ8fUrn35q0rGyysu2F5lcEmL50N+N/3sQt7WuRcMjM/BWrncdem7uVT1cYqxl/e39n2tWJ4ERqFnM3HmHjoSQ+XbGXKoFWTqYZc23mJdjckZSRzdQ/y1+vw8hgXxJSjDkHN4zvy9gfN3Bx3aq0rh1OVradGqFW2r5oLPzyn0vq0aZ2FeZvPsrY/s2cCb63Brbm4S//5ZmrmhIRZHwPXr6pJdOX7uaW9rWJjQggPiWTX9Ye5uJ6VWlWI3+4+8QbjB7sU+5sh93u4GRaFj5mMxaziRva1nLWM5lMRSYe89TOTSb6mE0EnWH48mWNq7nTTFLGlHz0gIK9vB1FLfkkIiIi5Y6vry85OTnO/bZt2/Ltt98SFxeHj0/Rj0wmk4muXbvStWtXxo4dS506dfj+++8ZOXJkoeuJVHb6DJ2j4/mLGvDZjca8gpt+gL8+zC+v2d5Ixp3Y6bp4yt8fw47fIelg6cRSvZUxbDtP7+dg3jic80DWvxwuvj8/iW22wCMbjOO5Ky7bez7LttmzadC2X/7CKQAh0XDj/4zthr3yyx9aY1xHyjW73YHZfPbONTuOpdD/7T+5s3MdnurX1Fm+OyGVHLuj0HBWh8OByWQiJTObYZ+sZtnO49SLDCLDloPFYmL/CSMpGOLnw/KnehLs50NiWhb7T6Qz/udNAMxYfYDTljpyJh4B53Dc0+UlHsuLptVDcTgcbDmSDMDAjrH4Wy3c070e7y/cwWcr9vG/Qe2pVSWAK99c4jxvy/NXcOfUlfy15yQ1wwOoHRFIkJ8PlzaOYswPGwjx9yHYz4dJA1q73M9ms/Fyx2zCG3WgR5No/HwsXNHcdSqCdnUinCsv54kM9uPxvk2c+9VC/Lmr25n/UGQ2m4pcaKUk/K0W/hnTG7PZVKKfQSnflHz0AH0sREREKp64uDhWrlzJnj17CA4O5sEHH+R///sfAwcO5IknniAiIoIdO3bw1Vdf8eGHH7J69Wrmz59Pnz59qFatGitXriQ+Pp6mTZs6r/fbb7+xdetWqlatSlhYGFar9SxRiFRc+gzlSjthzLdYq33Rxw/+bfRW3LUwv2zH78ZXobqrja+ilCTx+MgGSI2HlVNg3QzXY2arsYhKylFoNdBIQP79CXR7FLqOML7OxK/4udFKxKdwjzbxvGNJGew4luJcuONMRn79L0t3JDD3kUv5evV+pi/dzVsD29CuTpVC8yo++9NG0m05/HfxLp7q15STqVms3H2C+z5bg6+PmfHXXMSq3ScI8fehU92qTJq3lZ3xqVQP8+fwqQwAdiWkFoohOTOb5uN+K50372HdG0by8dCO/HfJLueiMLd1qk1qZjZ/bD7GU1c15aZ2tfhm9QGe+t4Ydv3Cdc254+I6HE3KoNOE+QA8d21zrBZz7vEWvHBd/ly4V7eszi/rDlMtxA9/q4Wv/9MZwOX7kWN3EORrca6MXBR/C1zeOArrGYanlwdVgvTvRGWh5KOHqeOjiIhIxfDYY48xePBgmjVrRnp6Ort372bp0qU8+eST9OnTh8zMTOrUqcMVV1yB2WwmNDSUxYsXM3nyZJKSkqhTpw6vv/46V155JQD33nsvCxcupH379qSkpLBgwQJ69Ojh3Tcp4kH6DOX68lbYvxKueAmq1AWzj7FASmoCrP0SVk/1fAxhtaHdIAiPNb6um2IkPY9vz68z+oAxT+O+FdC4H+RkGUOjYzsVf12pcJIzbBxPySIu0pi64eq3/+RYcibTh3YoNFx16Y4Envt5E+OuacamQ0l897eR4L77479YvfckADdNWU6wnw/VQvy4pUMsN7arxWcr9vLnjgTndeJGzXK5bla23WWOw0+W5/dOzEs8lqU2tcP5Z18iHeMi+Pq+zkz7czeJ6Tbemm98PqYP7cDQ6X8BcOfFdViw9RgHTho9Mbe9cCULth7jpV+30KdZNLERgbSsFUaj6BD8fMyYTCaaxIQ47zXh+haF7n9Lh1iqhfjRtk4V55Dm6FB/3rilFf4+FmfisSiv3tSKZjVCueIio6diUYvrnD68WaQ8UPLRAwr+A6Dco4iISMXQqFEjli8vPETru+++K7J+06ZNmTNnTrHXi4qKYu7cuaUWn0h5d8F8hvYsNRJ6YbGu8y3Z7Ubvxf0rjf05o8o2rprt83tJXvUaNOqbf8xshvv+hMktINVYMAKrv/HV9OrcOv5aubmC+33TUVbuPo7DAVe2iOGiGmG0eNb4DH33QBda1wrnWHImAK/9tpUnZ64jPNDKE32b0KtZNLd/aPzs3va/lS7XzUs85knJzCYlM5uJv24pldWaz0egjwOr1cqp9OwS1X+4Z0MGdozl8xX7uONiY6X3vKHDfZpFExPmT2SBYcItaoXxVL+mTFm0kyuax+DrY6bvRTH0vaiYFdOBSxtF8cQVjWkaE1rkcYvZRK9m0YXKr29z9oRhgK+FB3o0OGs9kfJGyUcP0LBrEREREZFKaP1M+PZuYzss1pizsOWt0Ok/8Iobi+TUvxx2/mFsn75idFFiLzYWmvl5BOw7LdF7yeNGMvTwWmjYp/C5Vn+49XP4ciD0ef7cYxWvsuXYeeePHXRvGEn73OG0+46nMW3pbh7oUZ9qof6M/XEDh3J7En74526ua13Def4N7y2jY938YbgbDyUBcCw5k3s+Wc0NbWuW4bvJ16BaMH2aRTN301HSs3I4mJhOs+qhbDqcVKhurSoB3N2tLrviU/l0xV5ubFuDi332sTugPu8t2kW9qCD++L8ezN14hCmLdjKgfSyjvltPk5gQJg1ozYaDp7i2TQ38fCw81rdxoes3rxnm3P5peFdW7jrBTW1rYTabeLR3oxK/J5PJpAShyGmUfPQALTgjIiIiIlLBOezG3I1V6hoP+AsmwqKX8o+f2m+8LnrJtbykrnzFSFqu+xqO7zB6TR5cYxzrNhL+nGSsFJ2wzVicpvd4qNYMrAFw1xx4NjdRcvfvEFQVIuoZ+wV7PJ4utiM8vsP1FxYpE5nZOdz10V+YTSY+HNwev2Lm2vt42R5qVw10Dol2OBz8d/EuVu0+wfwtx3hz/nae7d+M1KwcXv1tKwAfLdvDPd3qOhOPeX7495DL/qrdJ4qNL2+Itadc1jiK6UM7MvHXzSzZlsAL1zcnOtSfmuEBADxxRf5CJk99v94l+bjkicsI9LU4Fy6x2x0MaB9Lvar+/D53Hw/0qEfDmBC65s5j2eeiGPrk9ky8tWNt53UKrsh8Ni1rhdOyVrjb71dEXCn56GFKPYqIiIiIVBymPUtovfd/mOf8AX9/BN3/D5pe416CsTiXjzESjwAtBxivh/7NP95zLHS4B8LO0Btt+BpI3AOxHc7t3ko8ekSGLYeX52zhioti6FSvqssxu91By2fnkpltB2DSvG083qcxS3cep12tEI5nwODpq/G1Wli4NR6ALvWr8vx1zbnjw5WF5kV8Nne154I+/HO3h96Zq5dvbMG/+08xa90hkjLyhzr/9sglpGZl8/umozzcsyFpWTncPGUZV7es4dJrcPSVTRl95Znv0a95db5YuQ+A4Zc1IDYi0OW42WyiRa0wbDZj1Wo/H3OJhiyLiPco+egBpgIDr9XxUURERESk4vD5/HrqAJxYYhQsed34Ohe1u0CPJyGmZf5w7Ih6cMOHsG8ZtBta+JwrX4LsdOgywkgQninxCBDZwPgSj8qxOzCbwO6AxLQsqgb7kZ1j56u/9uMAWtcK56e1B/nfEiP5N33pHv4Z05vr31tKuzoRvD6gFYu2xTsTjwAfLNpFbJVAnvlhQ26JD+DaK3HZzuP0fH3ROcebtxryubq/R33eX7iTiCBfvn+gCze+v4zaEYHc1qkOy3YmOHtGXt+mFrd0qM3EG1qwYOsxvlm9n+eube6cJ7Ft7SoA+FstzP+/HuccB0C3hpF8c19nakcEEh3q79Y1RKR8UfLRE/THRBERucBp2pHzpzYU/Qycn7O23/5VxryNXwyAI+tgyCwIiiqdm9/1a+GysFpQq53xVZSIejD459K5v5QKu93B7R+u4PCpDFrUDOOXdYfp3jCSJdsTznje/32zlj3H09hzPI3Ve09wa4faherkJx5Lz8qnehId6k+I/zq+XLW/0PGpg9vz5ar9vHBdc3YlpNC+TgTTl+7G18fM0K51ebxPY7LtDnx9zPz55OVYzCasFjM3tatF69hwfC1mfH3yV2K+rHG1Qitml5YOcRFnryQiFYaSjx7gMuej98IQEREpc1arFYC0tDQCAgK8HE3FlpaWBuS3qVw4LBZjLrisrCx9js7DGT9Du5fAx1e7ln10lfs3u+M7+OlhoyfijVNdj7W4GdZ/A5c84f71pcQcDgemcxxanmHL4d/9iaRkZNMwOpijSZk0qR7C9qMprNhl9Ejce9z4eTpb4hHgjy3HnNt7j6fx8pxzWxHaZHIdQVcvMohdCanEVQ1kT24cANe3qclLN7ZgwZZ4TCacvQQn3tCSepHBvDh7Mze2rcW3fx8gPNBKz6bR9GxqrLIcE2bU/c+l9Z3XM5tN+JqNtvO3us5JOahz3Dm9BxGRgpR89DT9xVpERC4gFouF8PBwjh0zfvEKDAw8518CC7Lb7WRlZZGRkYHZbD77CZWAw+EgLS2NY8eOER4e7kxEyYXDx8eHwMBA4uPjsVqtbv/sX4ifHyjhZ2jRy+d+4baDjKTlZU/Bd/fml1epCw16wsiNRZ93/QfQa/zZh1FLieTYHVjMRf+/Mnv9YR74/G861Y1gxn86sys+hQBfC9XDAth/Io3urywgMtiPP5+8zJlce3HWJueQaW+pHeTg2Zvasft4Brd3qo2/1cK+42ncOW0lgzvHcVP7Wnz9135ualeLDJudlbuPc02rGs7/X69oHlPomvdeUo97LzEWIbrj4trUqhJYqI6ISFlR8tEDCv5XqNSjiIhcaGJijF+C8hKQ58PhcJCenk5AQMB5JTErovDwcGdbyoXFZDJRvXp1du/ezd69e92+zoX8+QEIDw0hJvsQ/DEVWgyAjd8bK0H7BsOeJWc933b/Kqxpx2D+c9DxXqMHY147psbDb08Z20OLGGJdkNmixGMp2XokmZveX8ZtnWoz6sombDmSzMnULHx9zEQE+fLA538DsHL3Cd6Yt403528H4KHLG/D2HzsASEjJpMmYOYy6sgmLtsazfNdxj8RqMZvIsbv+NhgWYOVUus2l7P3bWpO1ezXdG0RyedP8Xrq1qway6PHLnPv3dK/n3L629bn9PLXJnYdRRMRblHz0gAvx4U5ERCRPXuKkWrVqzpUo3WWz2Vi8eDGXXHLJBTX82Gq1qsfjBc7X15eGDRuSlZXl9jUu1M8P5H6GZtwG2+YYBYtfNV4XTjjruQ6Tmdkt3qNPRD2Ibgz3zCtcqeMw8PGDepdBaPVSjFwAUjOzeX/hToL8fDiWnMHjfRsT6OvD+J83kpyZzQeLd7Fg6zG2HU0p9hp5iUfAmXgs6KVfz20o9OliQv158PIGjCkwd+Mt7WOZsXo/V1wUw1Utq/PUd+t57462dG+YP5foliNJpGZmc+P7ywFoUC2ITd7teCki4nFKPnqAS89HdX0UEZELlMViOe8EmsViITs7G39//wsueSJiNpvx93d/pdcL8vNzbAsk7oO9f+YnHs/mxqlQJQ5+HgGXPUV2dGuyF68+8zkWK3S457zDvVCdbV7Gx75Zy68bjjj3fS1m7u9Rn2U783spninx6I6XbmhBrSqB3DF1ZbF1mlUP5Yt7O3EiNYt6UcEA1Az3JzvHQa+m0ZhMMKRrHHUjg/C3WujfqkahazSJCSUtKxsAswlqVwlkU6m+ExGR8kfJRw9zaOC1iIiIiEjZeK9TyeuOPgB+Ifn79y81Xs+zx7bkO5GaRYYthxrh+Qsn7YxP4ZYPlnNXt7o80KMBAMkZNuZsOMLx1KwieyR+sHgXHyzeVerxdW1QlU/u6lTsHJIAn9/Tids/NBKSE29oQXigL+GBvs7jlzeJdqnftHroWe8b6OvD8tGX42sxYz7DvUVEKgslHz1Ao65FRERERMopix/0fdE18ShuW7I9nqgQP+pXDeBUFvyy7jBXtqyJr8VM2+eNIeuzHu5GVLAf/+5PZNinawB4Zc5WBrSP5dU5W5mxev8537dlrTDWHThV7HGTCRY/fhljftzAwq3xALSrU4X3b2/LW39sZ2DH2jSsFlIo8XjnxXX4dMVe6kYGcXP7WnRtEMmel64iw5ZTaAXo81E9zEjInu/0JCIiFYGSjx5gKjDwWsOuRUREREQ8JOMU2DLgj+fAGlR0nUZXwrbcRWH6ToCLH1BvgVKyMz6FO6euAmD5k5cydo0PrFnPo9+sp2pQfu/Aq976s8jzX/hlEz/8e8ite4+9uhk3TVleqPz+HvXJyrbTIa4KsRGBfDS0I/uOp/HDvwcZ3DmOsEArL1zXotjrPnftRTzSqyFVg/1cyksz8SgicqFR8tEDCj7LKPcoIiIiIlJKcrIhLQFs6eCww9ttz37OLZ8aczRKqdtxLH/exc4vL3I5djz17IslnWvicWTvRkyatw2A6uEBfHFvJ277X/4cjbMf7k6j6GB8LGaX82pXDeThng1LdA+TyVQo8SgiIudHyUcPU89HERERERE3JB2C3YvhohuMHo4pR2HdV7Ds7ZJfwxqoxGMpysq2s3L3cWJC/fl69X42H0722L1+eagb//l0Da1iw9h/Ip0mMSE80KM+n6/cS3aOg5hQf2qGB7DnpatYvecEZrOJZjXOPt+iiIiUPSUfRURERESk/PngUkg9BqcOwMoPjO1zNWpf6cdVSTgcDuwOSEjJJCrYj2y7A18fo8fg7oRUDpxM4+U5W8iw2Xn95lbc/fFqElIyS+XePw/vRv938odij+jZkI51I/hzRwLvL9yJn4+Z5jXDWDrq8kLnLnisB2aTyWWuxvZxEaUSl4iIeIaSjx7gOoWMuj6KiIiIiJyzvGTjtt/OLfHY8lbY/DPc8a16PZ7BoGmrWLI9AYDIYF8SUrKIDPYrMsF47btLS3zdFjVDWX8wqdjj93avS/OaoQztGseny/fStk4V/nNpPQJ9fejaIJKb2tUiPKD471ugr36FFRGpaPQvt4dp2LWIiIiIyHk48FfJ6178AFwxEezvgfnCWiAkx+4gJTObsNMSd/HJmZxIzaJxTAgOhwOHA9YdPOVMPAIkpGTlvp57z8awACun0o0Vm6v4OvhocDuqhgaSlGEjLTOHF2dv5tJGUTz2zVpC/X24v0cDTCYT4/pfxLj+FxW6Xv2o4HOOQUREyjclHz3AZbVrL8YhIiIiIlLxneWJ2jcYsnIXPrnkceP1Aks82u0O2j4/j1PpNhY/fhm1qwY6j93z8V+sPXCKD+5sx5/bE/h69X4ys+2lct89L13F4m3xDJpmrHj9dJscQnOTn6H+VkL9rbw9sA0AN7WrVSr3FBGRikfJRw9wHXYtIiIiIiLnJGF78cd8AiA73di+9UuIqAubf4HOD4JvYPHnVVKZ2TnMXHPA2ftw+rLdxFUNYsZf+7n94tqsPXAKgP98uua87tOgWjDHkjJIysh2Ke/eMJIXr29Ow6hADq9fdl73EBGRyknJRw8omHvUsGsRERERkRLITIYTu6BaM5j/XNF1wmvDfUth2xyofzkERRrl1ZqWXZzlyEdLd/Pi7M3YcvJ/6Zi+dI9z++nvN7h13TmPdOfVOVvpWDeCuMggPli0k1dvbkVkkB97T6Ty+6aj3Nk5DgCTycTtnepgs9k4vP583o2IiFRWSj56mEMDr0VEREREzm7alXD0DNmrgCrw0D9g8YGWA8ouLi/LzrFzKt3G9/8cZGd8KjXD/fl0xV6+GtaZn9cddkk8loYpd7SjSUwoU4d0cJb1vSjGud0yMJyWtcJL9Z4iIlK5KfnoASaNuxYREREROTdnSjyC0ePRcmH8+rJy13FiIwKpER7AsE/X8MeWwqt93/6/FRw6lXHO137t5lY89s1aACbe0ILR3xntvmJ0T8IDrfhbL6z5MkVExPMujP+9y5iGXYuIiIiIlNCJ3fnDp4vT5SEIq1k28XjZv/sTueW/K6gSaOXvMb2LTDwCJUo8Wi0ml56RUwe3p2fTaC5tFMXx1ExiqwQ6k4/VQvwwm9WJQkRESp+Sjx5QsOOjco8iIiIiIqdJTYDFr0FodZg3Dqq3LFznvj/hyHqIvgiqXVT2MZaxHcdSOJiYzuDclaNPptl48tt1JT7f32omw5a/ivVXwy6mXZ0q+OQmFE+kZlE12A+AqBA/okKM7SVPXIaPxaTEo4iIeIySj56mro8iIiIiIq5mjYRNP+bvH17revym6RDTwviqBNYfOMWT365j1JVNqBcVRFSIH1azGbPZxNer9/PEzKKTjF+vPlCi6w/sWJv/XFKPHq8tdJZdXK+qS528xOPpYiMuvBXCRUSkbCn56AGa81FERERE5AwOrD7z8eY3lE0cZeD7fw7w6AwjuToot1djaZt4g5Gk7dMsmrmbjnJd6xoeuY+IiIg7zN4OoLJTv0cRERER73r33XeJi4vD39+fTp06sWrVmRNAkydPpnHjxgQEBBAbG8ujjz5KRkb+/HrPPvssJpPJ5atJkyaefhuVywUyOuhQYroz8Xg+/HzM3NOtLquf6cXfY3rz7f2defjyBgT6WvhwUHtnvVdvbsWkAa144frK0WNUREQqB/V89BCTyXimukCeq0RERETKpRkzZjBy5EimTJlCp06dmDx5Mn379mXr1q1Uq1atUP0vvviCUaNGMW3aNLp06cK2bdsYMmQIJpOJSZMmOetddNFF/P777859Hx89VpdY/DZIPuTtKEqFI/dhv+DIp5TMbD5dvpc+F0Wz9Uhyia8V5GshNSunUPmel64qVBYRFEG7OhE80quRy1yNYQFWbmhb61zegoiIiMfpKcnDlHsUERER8Z5JkyZx7733MnToUACmTJnCrFmzmDZtGqNGjSpUf9myZXTt2pXbbrsNgLi4OAYOHMjKlStd6vn4+BATE+P5N1AZfdjzzMcvH1M2cZynrGw717zzJ9Gh/nx8V0dn+YuzNvPlqn28PGdLia/VrUEkFrOJRdviAehUN4KVu0/QvGboGc/TIjEiIlIRKPnoISaUeBQRERHxpqysLNasWcPo0aOdZWazmV69erF8+fIiz+nSpQufffYZq1atomPHjuzatYvZs2dz5513utTbvn07NWrUwN/fn86dOzNx4kRq165dbCyZmZlkZmY695OSkgCw2WzYbLbzeZvFyruup67vLmtmksu+I7oF9hptMOVkk9N3AvgGgxdjLmm7/bMvkS1HktlyJJm98Un85/N/6dEoki9X7TvrPcZc1YRBF9fm8KkMvl59gIEdY3E4HHR7NR6rxcT7t7XiwMkMYiMCyt33rzjl9eetvFO7uU9t5x61m3vUboWdS1so+eghptxx1w6NuxYRERHxioSEBHJycoiOjnYpj46OZsuWonul3XbbbSQkJNCtWzccDgfZ2dncd999PPXUU846nTp14qOPPqJx48YcPnyY8ePH0717dzZs2EBISEiR1504cSLjx48vVD537lwCAz272vC8efM8ev1z4nBwbYHdZL/q/FHjcWPHAvy+2BtRFamodnM4jOmVAFYeM2EEDZe+vgSALSUYZn15DTuRJzYwe/YGABoCq5dsA+DNzkadJX8Y9959HvF7S7n6eatA1G7uU9u5R+3mHrVbvrS0tBLXVfLRQ/IGQCj1KCIiIlJxLFy4kAkTJvDee+/RqVMnduzYwYgRI3j++ecZM8YYDnzllVc667ds2ZJOnTpRp04dvv76a+6+++4irzt69GhGjhzp3E9KSiI2NpY+ffoQGnrmobXustlszJs3j969e2O1Wj1yj3OWlQr/Gps5l47Gv+tI+pnK19Dh4tpt5e4TPPDFv7StHU6Qnw+zdh45p+t2qR/BzW1rcnmTKAJ9K9+vYeXy560CULu5T23nHrWbe9RuheWN4iiJyve/noiIiIgIEBkZicVi4ejRoy7lR48eLXa+xjFjxnDnnXdyzz33ANCiRQtSU1MZNmwYTz/9NGazudA54eHhNGrUiB07dhQbi5+fH35+foXKrVarx3+JKYt7nNWJ3fDD/RAWa+xb/LD0eBJLOUs8FnR6u93z6d9k2Ows3JZQovPH9W/G9KV7aBUbTp2IQB68rAEBvhZPhVtulIuftwpI7eY+tZ171G7uUbvlO5d2KPz0JKUi7zlKo65FREREvMPX15d27doxf/58Z5ndbmf+/Pl07ty5yHPS0tIKJRgtFiNhVNx0OikpKezcuZPq1auXUuSV0Ld3w77lsP5rYz8nM/+BuZw5nprFlzvN/LMvEYB/9yfyn09Xk2Gzn/XcG9rUdG7fcXEdFj9xGW8PbMNjfRtfEIlHERGRoqjno4iIiIhUWiNHjmTw4MG0b9+ejh07MnnyZFJTU52rXw8aNIiaNWsyceJEAPr378+kSZNo06aNc9j1mDFj6N+/vzMJ+dhjj9G/f3/q1KnDoUOHGDduHBaLhYEDB3rtfZZ78Vu9HUGJvfLbNlYcMzPgf6uYfEtrxv64gaSM7BKd+/qAVkQE+VIt1A+rRf08REREQMlHj9OCMyIiIiLec8sttxAfH8/YsWM5cuQIrVu3Zs6cOc5FaPbt2+fS0/GZZ57BZDLxzDPPcPDgQaKioujfvz8vvviis86BAwcYOHAgx48fJyoqim7durFixQqioqLK/P2Ve4f+gX8+g6wU1/KLrvdOPCVQcNGYR2b8W+Lz3r2trfGzc3UzD0QlIiJScSn56CEmkwktNyMiIiLifcOHD2f48OFFHlu4cKHLvo+PD+PGjWPcuHHFXu+rr74qzfAqr73LYPqVhcuDY+Dmj8o8nJLyMRceDh4T6o/ZBIdOZQDwwnXNeeaHDfRqGs2Hg9tjy7Grp6OIiEgxlHz0EK12LSIiIiIXrOISjwDXvF22sZzBidQsXv1tCzGhAaw7kIjN7mDdwcKrdz51VVOqBFq5c+oqAAa0j6Vbg0iqh/sDKPEoIiJyBko+eogWnBERERGRC9amn4ouv+p1aNi7bGM5g8HTVrH+4Kmz1jMB7etEEBsRQPMaYfj6mImLDPJ8gCIiIpWAko8e5lDfRxERERG50KSfKFzWdQR0uKfsYynGl6v2FZt4tJgc9Ghcjflb4gGoGuRLgK+FRY9dhrmIYdkiIiJSPCUfPUSPJCIiIiJywTmyAT7qBxkFknpNrjZeuz7ilZBOdyrNxrHkDMb+uKHI45HBvjzUKI3brm/DrA3H2HIkmc71qwIo8SgiIuIGr09O8u677xIXF4e/vz+dOnVi1apVZ6w/efJkGjduTEBAALGxsTz66KNkZGSUUbQlZ8odd61h1yIiIiJywfh6kGviEaD5DXDr5xAY4Z2Ycv297yRxo2bR6rm59H5jMbYc1wf1sVc3Y89LV7H8yR6E+xll17Wpyagrmzif7UVEROTcebXn44wZMxg5ciRTpkyhU6dOTJ48mb59+7J161aqVatWqP4XX3zBqFGjmDZtGl26dGHbtm0MGTIEk8nEpEmTvPAOiqcFZ0RERETkgnNiZ+Eyv9CyjwM4mpTBy79uoWaVAJZsT+Df/YmF6ky5ox1Vg31ZtDWeQZ3rlH2QIiIiFwCvJh8nTZrEvffey9ChQwGYMmUKs2bNYtq0aYwaNapQ/WXLltG1a1duu+02AOLi4hg4cCArV64s9h6ZmZlkZmY695OSjNXrbDYbNputNN+Oi7ykY7Yt26P3qWzy2kptdm7Ubu5Ru7lH7eYetZt71G5FU3tIhVGvh/FVxlIys+k0Yf5Z67WtE061EH86xHm3V6aIiEhl5rXkY1ZWFmvWrGH06NHOMrPZTK9evVi+fHmR53Tp0oXPPvuMVatW0bFjR3bt2sXs2bO58847i73PxIkTGT9+fKHyuXPnEhgYeP5vpBg5ORbAxJ9//snWAI/dptKaN2+et0OokNRu7lG7uUft5h61m3vUbq7S0tK8HYLI2V39BrS/q8xuZ7c7MJtNDP/ib35Zd7hE51QL8fdwVCIiIuK15GNCQgI5OTlER0e7lEdHR7Nly5Yiz7nttttISEigW7duOBwOsrOzue+++3jqqaeKvc/o0aMZOXKkcz8pKYnY2Fj69OlDaKjnhoA8/fd8MnNy6NK1Kw1jwjx2n8rGZrMxb948evfujdVq9XY4FYbazT1qN/eo3dyjdnOP2q1oeSM5RMq1yMZldquXft3Cl6v2MeWOdiVOPHbJXURGREREPKtCrXa9cOFCJkyYwHvvvUenTp3YsWMHI0aM4Pnnn2fMmDFFnuPn54efn1+hcqvV6tFfYvImpfbx8dEvS27w9PenslK7uUft5h61m3vUbu5Ru7lSW0i5tPK/rvtBUWVyW4fDwZRFxlyTA/+3osg6TWJCeO3mVrwwaxOrdp/A7oAXr29RJvGJiIhc6LyWfIyMjMRisXD06FGX8qNHjxITE1PkOWPGjOHOO+/knnvuAaBFixakpqYybNgwnn76acxmry/eLSIiIiJy4cmxwa+Pu5YFl03yMT45s9hjr9zUkj7NogkP9AXgq2Gdyc6xk5yRTZUg3zKJT0RE5ELntWydr68v7dq1Y/78/Img7XY78+fPp3PnzkWek5aWVijBaLFYAOMvnuWJc7Xr8hWWiIiIiEjp27WwcJl/uEdulWHLYVd8CmD8DnDD+8uKrPfKTS25sW0tZ+Ixj4/FrMSjiIhIGfLqsOuRI0cyePBg2rdvT8eOHZk8eTKpqanO1a8HDRpEzZo1mThxIgD9+/dn0qRJtGnTxjnsesyYMfTv39+ZhCwvckddo9yjiIiIiFRq6Ynw+U35+91GQpW4/AfiUjZo6ipW7TnBu7e1ZeyPGziemlWozv/1bsSA9rEeub+IiIicG68mH2+55Rbi4+MZO3YsR44coXXr1syZM8e5CM2+fftcejo+88wzmEwmnnnmGQ4ePEhUVBT9+/fnxRdf9NZbKJYpt+9jeeuRKSIiIiJSqv7+OH+7xQDoNc5jt8qxO1i15wQAD37xd5F1Xr6xBbd0qO2xGEREROTceH3BmeHDhzN8+PAijy1cuNBl38fHh3HjxjFunOceaERERERE5BxkJudv+4d69FZfrNpX7DFfi5kPBrXjssbVPBqDiIiInBuvJx8rKw27FhEREZFKb903sO23/H17Tqle/qVft5CcYcNkgm4NInlvwY4i6/06ojtNq3s28SkiIiLuUfLR05R9FBEREZHKxm6HtV/Cjw+4lre+rdRucTQpgymLdjr3P1tRuNfjkicuIzrUH18fr62jKSIiImeh5KOH5Pd8VPZRRERERCqZohKPlz8DsR1L7RZzNx094/HmNUOJjQgstfuJiIiIZ+hPhCIiIiIicm7Wflm4rGrDUr3FmB82FHusapAvn97VqVTvJyIiIp6hno8ekr/atZcDEREREREpbTm2wmWNriiVS2fYcnj4y3/OWGfpqMvxt1pK5X4iIiLiWer56CFacEZEREREKi17tuv+uESw+pfKpR/7Zm2hIdd+PmauaVUDgCl3tFXiUUREpAJRz0cRERERETk39gI9H+v3zP/L+3nafjSZX9YdLlT+wZ3t6NG4Gq/c1FKJRxERkQpGPR89JO/xS8OuRURERKRSOXUQDq/N37/mrVK79K6E1CLLezSuBqDEo4iISAWk5KOHmHL/+qvVrkVERESkUlnxnut+QJVSu/TT3xe/yIyIiIhUTBp27SHq+SgiIiIilV7H/4Bv0HlfZu7GI4z8ei0pmdmFjr15a+vzvr6IiIh4j5KPIiIiIiJSctbA/O22d5bKJYd9uqZQma/FzLYXryyV64uIiIj3KPnoKaUz57aIiIiISPliseZvB1U7r0vtik9h46GkIo+1rRN+XtcWERGR8kHJRw/RsGsRERERqZSyUozXyMYQEn1el7r89UXFHps0oPV5XVtERETKByUfPUQLzoiIiIhIpWNLh6VvGtsXXXdel9oVn1Jkea+m0Yy6sgk1wgPO6/oiIiJSPij5KCIiIiIiJbN6Wv528Pn1euz9xuIiy9+/oy1Wi/m8ri0iIiLlh5KPHqJh1yIiIiJS6Sx6JX87ou45n27LsfPhkt10qV+VHLvrg/Ln93TCx2xS4lFERKSSUfLRQ3JHXWvQtYiIiIhUDnv+hIxEY9s/HOr2OOdLfL16Py/P2VLksa4NIt2NTERERMox/VnRQ7TYtYiIiIhUGkmH4aOr8vdHbgbzuf8qse1IcpHlN7St6W5kIiIiUs6p56OHOTTuWkREREQqulMHXPd9A926zMHEjEJlr9/ciiuax7h1PRERESn/lHz0FOdq1yIiIiIiFVxOZv52lXOf6xEgKcPG75uPupRFBvtyY7ta5xOZiIiIlHNKPnqIc9i1so8iIiIiUtGlJ+Zv17/8nE+fvf4wD3z+t3P/qpbV+b/ejQjy068jIiIilZ3+t/cQkyZ9FBEREZHKIm+hGYCQcx8i/ceWYy774/o3o1qI/3kGJSIiIhWBFpzxMHV8FBEREZEKLzU+f/viB8759FPpNuf2iJ4NlXgUERG5gKjnoyck7uPD9P8j0deK3fGLt6MRERERETk/eQvOdH8M/IJLfNrIr//lRGoWf25PAIzh1o/2buSJCEVERKScUvLRE3JsNHLsIskUwEZvxyIiIiIicr7yko9hNUt8SnKGje/+PuhS9mTfJqUZlYiIiFQAGnbtCSajWc0adC0iIiIiFV1mCmybY2xH1C/xaYdPZRQqi40IKK2oREREpIJQ8tETcpOPFuw4lH8UERERkYps88/529EXlfi0rUeSXfYXPd4Dk1ZlFBERueAo+egJZovxggOHej+KiIiISEWWVGDodFBkiU75fdNRHvryH+f+dw90oU7VoNKOTERERCoAJR89wTns2u7lQEREREREzlPKUeO128gSn3LPJ6ud218Nu5i2tauUdlQiIiJSQSj56AmmvJ6PGnYtIiIiIhVc4n7jNaR6iarbclz/AH9xvaqlHZGIiIhUIEo+ekLenI8mBw67so8iIiIiUkE5HHDob2M7psVZqydl2Lj9w5UeDkpEREQqEiUfPSF3zkeAHIeGXouIiIhIBXVqvzHs2uwD1VudtfqEWZtZtfuEc/+Xh7p5MjoRERGpAJR89IQCq/jZc7K9GIiIiIiIyHk48JfxGt0cfAPPWv3PHQku+81rhnkiKhEREalAlHz0BFOBno856vkoIiIiIhXUgTXGa60OJapecL7z/w1q74GAREREpKLx8XYAlZIpP6erno8iIiIiUmHl9Xw8S/LRlmPny1X7OJiY7izrVC/Ck5GJiIhIBaHkoycUnPPRnuPFQEREREREzkP8VuP1LPM9vjJnC/9bstulLMRPv2qIiIiIhl17hkvPRyUfRURERKSCybHB9Ksg85SxH1ztjNVPTzxe27oGpgLzoIuIiMiFS8lHT3CZ81HJRxERERGpYPYsgb1/5u6YwD/8nE5/rE/jUg9JREREKiYlHz2hQM9Hh4Zdi4iIiEhFYy44ZNoB5uJ/bThUYJ7HPNVC/TwQlIiIiFREmojFEwoMMVHPRxERERGpcHKySlx14dZ45/bz115Ep3pV8fOxnOEMERERuZAo+egJJhN2zJixY7fbvR2NiIiIiMi5yUorcdVg//xfKS5pFEWdqkGeiEhEREQqKA279hAHRu9HR062lyMRERERETlHtpIlH48lZzDuxw3OfSUeRURE5HRKPnqIPXfexxzN+SgiIiIiFU1Wav527+eLrTbmhw2cTLMB0KNxlKejEhERkQpIyUcPceQ2rV1zPoqIiIhIRZPX87FWB+jyUJFVNh1K4reNR537a/aeLIvIREREpIJR8tFD8no+OhxKPoqIiIhIBZN2wnit3splMcWCnv9lk8v+8MsaeDoqERERqYC04IyHqOejiIiIiFRYCduM16rFJxRPpuWviP35PZ3oVDfC01GJiIhIBaTko4c4cns+arVrEREREalwErYbr5GNijx8MjWLLUeSnftdG0SWRVQiIiJSAWnYtYfk9Xx0qOejiIiIiFQkOTY4sdPYjmpcZJUP/9zl3B5zdbOyiEpEREQqKCUfPSS/56OSjyIiIiJSgSQdAns2WPwgpEbRVdKzndtNYkLKKjIRERGpgJR89BDnnI9KPoqIiIhIRZKeu2p1YASYi/51wdfHKPcxm+hSv2pZRSYiIiIVkJKPHpLX8xGH5nwUERERkQokPXel64CiF5BJyrDx+cq9ADxxRWNMxayGLSIiIgJKPnpObvIxW3M+ioiIiEhFktfzMaBKkYef+m49GTbjD+wxYQFlFZWIiIhUUEo+ekhez8fs7Oyz1BQRERERKUfS8no+hhd5+Jd1h53b9SKDyiAgERERqciUfPSU3ORjjpKPIiIiIlKRnNpvvIbVKnRo/4k0l/2G0cFlEZGIiIhUYEo+ekpu8tGWrWHXIiIiIlKBnDTmcyS8dqFDo75b59z+9O6O+PlYyioqERERqaCUfPQUs/EgZstRz0cRERERqUBSjhmvIdULHVqx64Rzu0lMaFlFJCIiIhWYko+eYjKSj3YlH0VERESkIsk4ZbwWMedjo+gQANrUDicqxK8MgxIREZGKSslHT8nt+WjPtnk5EBERERGRc5CXfPQPcyk+mZrF5sNJADzSq1FZRyUiIiIVlJKPHmKyWAElH0VERESkgnEmH8NditcfPOXcbhoTUoYBiYiISEWm5KOnmHOTjzlKPoqIiIhIBZGTDVnJxvZpyce9uStdd6obQbVQ/zIOTERERCoqJR89xeIDaM5HEREREalA0k/mb/u7LiizNyEVgOY1XYdji4iIiJyJko8eYs4ddp1ty/JyJCIiIiIiJbT87fzt3OdZgIOJ6Xz4524A6lQNLOuoREREpAJT8tFDLD6+gJF8dDgcXo5GRERERKQElr5ZZHHfNxY7txtHa75HERERKblykXx89913iYuLw9/fn06dOrFq1api6/bo0QOTyVTo66qrrirDiM/Ox2r8pdjkyCYtK8fL0YiIiIhcuM7lWRNg8uTJNG7cmICAAGJjY3n00UfJyMg4r2tWdCmZ+VMJdawb4cVIREREpKLxevJxxowZjBw5knHjxvH333/TqlUr+vbty7Fjx4qs/91333H48GHn14YNG7BYLNx8881lHPmZWXyM5KMPOSRlaNEZEREREW8412fNL774glGjRjFu3Dg2b97M1KlTmTFjBk899ZTb16yQBnxa7CGTyVSGgYiIiEhF5/Xk46RJk7j33nsZOnQozZo1Y8qUKQQGBjJt2rQi60dERBATE+P8mjdvHoGBgeUu+Zi32rUPOZxKV/JRRERExBvO9Vlz2bJldO3aldtuu424uDj69OnDwIEDXXo2nus1Kwx7gdE6cd2cm6kFej1+enfHsoxIREREKgEfb948KyuLNWvWMHr0aGeZ2WymV69eLF++vETXmDp1KrfeeitBQUFFHs/MzCQzM9O5n5SUBIDNZsNm81xS0GSyYAas5HA8OR1b1QCP3asyyfueePJ7Uxmp3dyjdnOP2s09ajf3qN2KpvYoGXeeNbt06cJnn33GqlWr6NixI7t27WL27Nnceeedbl8TvPNMes6fH1saeUvM2BwmyD3v4AljlesgXwsXx4VX+p8//bvjHrWbe9Ru7lPbuUft5h61W2Hn0hZeTT4mJCSQk5NDdHS0S3l0dDRbtmw56/mrVq1iw4YNTJ06tdg6EydOZPz48YXK586dS2Cg51bqa3P0GLUBH7JZ8OdKEjZp0ZlzMW/ePG+HUCGp3dyjdnOP2s09ajf3qN1cpaWleTuECsGdZ83bbruNhIQEunXrhsPhIDs7m/vuu8857Nrd51dvPZNCyT8/1uxU+uVu/zrvDxwm41eF7adMgIUgczazZ8/2TJDlkP7dcY/azT1qN/ep7dyjdnOP2i3fuTyPejX5eL6mTp1KixYt6Nix+OEfo0ePZuTIkc79pKQkYmNj6dOnD6GhoR6LzfTTr3BiKT7Yqd2sJf3a1vTYvSoTm83GvHnz6N27N1ar9ewnCKB2c5fazT1qN/eo3dyjditaXq85KX0LFy5kwoQJvPfee3Tq1IkdO3YwYsQInn/+ecaMGeP2db3xTHrOn5+Uo7AeHCYzV/brD7lzO36z5gBs2kT9GlXp16+9R2ItT/TvjnvUbu5Ru7lPbecetZt71G6FncvzqFeTj5GRkVgsFo4ePepSfvToUWJiYs54bmpqKl999RXPPffcGev5+fnh5+dXqNxqtXr0BybHxxcw5nxMtTn0w3mOPP39qazUbu5Ru7lH7eYetZt71G6u1BYl486z5pgxY7jzzju55557AGjRogWpqakMGzaMp59+2u3nV289k57bPYw5H00WP6y+vs7SBduOA9C2TpUL6mdP/+64R+3mHrWb+9R27lG7uUftlu9c2sGrC874+vrSrl075s+f7yyz2+3Mnz+fzp07n/Hcb775hszMTO644w5Ph+keS+6CM6ZsLTgjIiIi4gXuPGumpaVhNrs+IlssFgAcDsd5Pb+We7Z049UnP/EYn5zJ75uNROs1rTSSR0RERM6d14ddjxw5ksGDB9O+fXs6duzI5MmTSU1NZejQoQAMGjSImjVrMnHiRJfzpk6dynXXXUfVqlW9EfbZmY2HVCs5nFDyUURERMQrzvVZs3///kyaNIk2bdo4h12PGTOG/v37O5OQZ7tmhTWtr/Fqy3AWLdhyDIcDmtcMpXFMiJcCExERkYrM68nHW265hfj4eMaOHcuRI0do3bo1c+bMcU7ivW/fvkJ/fd66dSt//vknc+fO9UbIJWM2ej5asJOk5KOIiIiIV5zrs+YzzzyDyWTimWee4eDBg0RFRdG/f39efPHFEl+zwspINF5z8lflzuv12KtpBX9vIiIi4jVeTz4CDB8+nOHDhxd5bOHChYXKGjdujMNRzleP9jHm9PEni6QMJR9FREREvOVcnjV9fHwYN24c48aNc/uaFVLekOsCHA4HK3YZ8z1e3qRaWUckIiIilYRX53ys1PyMVQtDTGma81FEREREyrf0xEJFCSlZJGVkYzKhIdciIiLiNiUfPcThHw5AKGkcT83ybjAiIiIiImdyYFWhor3HUwGoERaAn4+lrCMSERGRSkLJR0/xDwMg1JTKocT08j9MXEREREQuXLuX5G8PnAFAQoox92N0qJ83IhIREZFKQslHT/E3hl2HkkaGzc4J9X4UERERkfKu9e3Q+ArAGHYNUDVYyUcRERFxn5KPHuIIiAAg0pwMQHxK5pmqi4iIiIh4T3aG8RpRz1n0zA8bAAjxKxdrVIqIiEgFpeSjpwRHA1CFJCzkcDxFPR9FREREpJzKyX1W9TF6ORacMig80NcbEYmIiEgloeSjpwRWxY4FMw4iOeWcM0dEREREpNzJ6/no4w/kD7kGeOKKxt6ISERERCoJJR89xWQm02rM+1jNlKiejyIiIiJSfmXnPqtajF6OeStd1wwPwN+qla5FRETEfUo+elCWTwgAVUzJHE9Vz0cRERERKaecPR+NYdd7jqcBEBcZ6K2IREREpJJQ8tGDsizBAISTop6PIiIiIlJ+nTbn477cno91qgZ5KyIRERGpJJR89KAsHyP5GGFKdpk3R0RERESkXMnOHaVjce35WCdCPR9FRETk/Cj56EF5yccqphQOnEzzcjQiIiIiIsXISz76+JGdY2f5ruMAxEWq56OIiIicHyUfPSh/2HUyO+NTsOXYvRyRiIiIiEgRcvKTj4cSM4hPzsRsgksaRnk3LhEREanwlHz0oLyej1VNKdhyHCSkaNEZERERESmHbOnGq08ASRk2AKJC/Ajw1UrXIiIicn6UfPSgvNWuo3yMCbu16IyIiIiIlEtZxvMqvoHO5GOIv9WLAYmIiEhloeSjB2XmJh/jOIwJOydSlXwUERERkXLIljs/uTWQD5fsBiAp3ebFgERERKSyUPLRg04ENcJhthLtiKeWKZ7jqRp2LSIiIiLlTPpJyM4wtn2D+GPLMQCOJevZVURERM6fko8elGPxh+BqAESQzOFTGV6OSERERETkNFMuyd+2Bjo3a4YHeCEYERERqWyUfPS0gAgAwk2pHDiZ7uVgREREREROc2qfc3P90fxpgqYP7eCNaERERKSSUfLRwxwB4QCEk8z+E2neDUZERERE5AzWHTrl3K4fFezFSERERKSyUPLR03J7Pkaakjiono8iIiIiUp44HC67iWnGIjPXtKqBxWzyRkQiIiJSySj56GGOiAYANDAd5EBiOo7THvBERERERLzGVuCP472e5WSqMew6JszfSwGJiIhIZaPko4c5ohoDUN98iKxsu/OvySIiIiIiXpeZlL/d9RES041n1fBAq5cCEhERkcpGyUdPC6sFQE3zSQCOJmvFaxEREREpJ7IzjVefADCZOHzK6AkZFeznxaBERESkMlHy0cMcITUAqMYJTNg5mpTp5YhERERERHLZs41Xi9HTcdvRFAAaRod4KyIRERGpZJR89LTgaACsZBNGKseS1PNRRERERMqJHGOOR8w+JKZlEZ9s/KG8QTWtdC0iIiKlQ8lHT7NYwRoIQIgpjWPJ6vkoIiIiIuVETu585BYrO44ZvR5rhgcQ7OfjxaBERESkMlHysSz4hQIQSrp6PoqIiIhI+WHPSz76Oodcq9ejiIiIlCYlH8uCv5F8DDGlac5HERERESk/cnLnfDT7OHs+KvkoIiIipUnJx7KQ2/OxJgkc02rXIiIiIme0YMECb4dw4cib89Fida50XTsi0IsBiYiISGWj5GNZ8A0C4GafRer5KCIiInIWV1xxBfXr1+eFF15g//793g6ncssbdm22OhebiQrx82JAIiIiUtko+VgWYloAYMJBfHImDofDywGJiIiIlF8HDx5k+PDhzJw5k3r16tG3b1++/vprsrKyvB1a5ZM37Npi5WjuCJ1qSj6KiIhIKVLysSw07ANAFZLJyrGTmGbzckAiIiIi5VdkZCSPPvoo//77LytXrqRRo0Y88MAD1KhRg4cffpi1a9d6O8TKI7fnY6bDwv4T6ZhNUKdqkJeDEhERkcpEyceyEFgVgEhzMgDHkjX0WkRERKQk2rZty+jRoxk+fDgpKSlMmzaNdu3a0b17dzZu3Ojt8Cq+3DkfM3KMXwsaVAvWsGsREREpVUo+loWgSADCSMGHbOdk3iIiIiJSNJvNxsyZM+nXrx916tTht99+45133uHo0aPs2LGDOnXqcPPNN3s7zIovd9i1DQsA4QG+3oxGREREKiEfbwdwQQiqBtYgLLZU6piOcihRK16LiIiIFOehhx7iyy+/xOFwcOedd/LKK6/QvHlz5/GgoCBee+01atSo4cUoK4l/PwPAknESgBB//XogIiIipUtPF2XBbIbIBnB4LXGmIxxMTPN2RCIiIiLl1qZNm3j77be54YYb8PMreghwZGQkCxYsKOPIKhmHA3YtBKBK8lYAQgOsXgxIREREKiMlH8tKUBQAVUwp6vkoIiIicgbz588/ax0fHx8uvfTSMoimEstKLVQUqp6PIiIiUso052NZ8Q8HjHkfD57UnI8iIiIixZk4cSLTpk0rVD5t2jRefvllL0RUSdnyR+NMa/guACH+6vkoIiIipUvJx7ISEA5AmCmVg4lKPoqIiIgU54MPPqBJkyaFyi+66CKmTJnihYgqqbyej9Yg1vsYc2qGBqjno4iIiJQuJR/LirPnYyoJKZk4HA7vxiMiIiJSTh05coTq1asXKo+KiuLw4cNeiKiSyuv56BtIUroNgFD1fBQREZFSpuRjWSnQ8zEz205KZrZ34xEREREpp2JjY1m6dGmh8qVLl2qF69KUlZt8tAaSnGE8m2rBGRERESltGldRVgKqABBhNh7yElKyNKeOiIiISBHuvfdeHnnkEWw2G5dffjlgLELzxBNP8H//939ejq4SseUnH5MyjJ6PIVpwRkREREqZni7KSu6w66oWY77HhJRM6kYGeTEgERERkfLp8ccf5/jx4zzwwANkZWUB4O/vz5NPPsno0aO9HF0lkpt8tFsD2XvE2K4e5u/NiERERKQSUvKxrOQOuw43GRN7xydnejEYERERkfLLZDLx8ssvM2bMGDZv3kxAQAANGzbEz8/P26FVLrkLzmTgR7oth2A/H+pFBns5KBEREalslHwsK7k9H0NIAYyejyIiIiJSvODgYDp06ODtMCqvjFMApFuM0TjVw/wxm03ejEhEREQqISUfy0puz8dAewrgIEE9H0VERESKtXr1ar7++mv27dvnHHqd57vvvvNSVJVMRiIAKSajt2PVYF8vBiMiIiKVlVa7Liu5PR99HNkEkEl8StaZ64uIiIhcoL766iu6dOnC5s2b+f7777HZbGzcuJE//viDsLAwb4dXeaQnApBEXvJRw9pFRESk9Cn5WFZ8g8BsdDQNI1XDrkVERESKMWHCBN544w1+/vlnfH19efPNN9myZQsDBgygdu3a3g6v8kg/CcDOZOMZtX6U5nsUERGR0udW8vHjjz9m1qxZzv0nnniC8PBwunTpwt69e0stuErFZHL2fgwzKfkoIiIiUpydO3dy1VVXAeDr60tqaiomk4lHH32U//73v16OrhLJTALgQLoVgE51I7wZjYiIiFRSbiUfJ0yYQEBAAADLly/n3Xff5ZVXXiEyMpJHH320VAOsVAKqAFDFlKLko4iIiEgxqlSpQnJyMgA1a9Zkw4YNACQmJpKWlubN0CoXWwYAJ20WAKoEas5HERERKX1uLTizf/9+GjRoAMAPP/zAjTfeyLBhw+jatSs9evQozfgql5AYOL6daE6wNllzPoqIiIgU5ZJLLmHevHm0aNGCm2++mREjRvDHH38wb948evbs6e3wKo/sdABOZhrJx/BAqzejERERkUrKreRjcHAwx48fp3bt2sydO5eRI0cC4O/vT3p6eqkGWKmE1QKghukE6bYcUjOzCfLTguMiIiIiBb3zzjtkZBi98p5++mmsVivLli3jxhtv5JlnnvFydJVItjESJ9VuJB2VfBQRERFPcCvz1bt3b+655x7atGnDtm3b6NevHwAbN24kLi6uNOOrXEJrAhBrOQE5kJCSqeSjiIiISAHZ2dn88ssv9O3bFwCz2cyoUaO8HFUlZTM6DWTgS7CfDwFWi5cDEhERkcrIrTkf3333XTp37kx8fDzffvstVatWBWDNmjUMHDiwVAOsVMKM5GNtnxMAnEyzeTMaERERkXLHx8eH++67z9nzUTwo22jjTKy0qR2OyWTyckAiIiJSGbnV7S48PJx33nmnUPn48ePPO6BKLTRv2PVxAE6mat5HERERkdN17NiRf//9lzp16ng7lMotN/mY4fAlNtTfy8GIiIhIZeVW8nHOnDkEBwfTrVs3wOgJ+b///Y9mzZrx7rvvUqVKlVINstIIrQFApCOv56OSjyIiIiKne+CBBxg5ciT79++nXbt2BAUFuRxv2bKllyKrZDKSjBd8CfHXfI8iIiLiGW4lHx9//HFefvllANavX8///d//MXLkSBYsWMDIkSOZPn16qQZZaQRHGy/2JCzkcCRJw4lERERETnfrrbcC8PDDDzvLTCYTDocDk8lETk6Ot0KrPBL3QUYiYAy7DvbXPOQiIiLiGW49ZezevZtmzZoB8O2333L11VczYcIE/v77b+fiM1KEwAgwWTA7coggiZ3HUr0dkYiIiEi5s3v3bm+HUPntXuLcTHIEEqrko4iIiHiIW08Zvr6+pKWlAfD7778zaNAgACIiIkhKSiq96CobswWCIiHlKFGmU+w5ruSjiIiIyOk012MZyM4fgXOcMIL9lHwUERERz3DrKaNbt26MHDmSrl27smrVKmbMmAHAtm3bqFWrVqkGWOn4h0PKUcJMqRxI1rBrERERkdN98sknZzye94dvOQ/pxhzkv/j0AiAmTAvOiIiIiGe4lXx85513eOCBB5g5cybvv/8+NWvWBODXX3/liiuuKNUAK52AcABCSeVYUqZz7iIRERERMYwYMcJl32azkZaWhq+vL4GBgUo+lob0RAAOZPhjMkHbOlowUkRERDzDreRj7dq1+eWXXwqVv/HGG+cdUKWXY6xw/ZTPF/yW1ZGkjGzCArS6oIiIiEiekydPFirbvn07999/P48//rgXIqqE0oyej6ccwTSODiFUq12LiIiIh5jdPTEnJ4dvv/2WF154gRdeeIHvv//erZUH3333XeLi4vD396dTp06sWrXqjPUTExN58MEHqV69On5+fjRq1IjZs2e7+zbK3qF/AKhjPgZAvIZei4iIiJxVw4YNeemllwr1ihQ3pRsJ3pMEUzsi0MvBiIiISGXmVs/HHTt20K9fPw4ePEjjxo0BmDhxIrGxscyaNYv69euX6DozZsxg5MiRTJkyhU6dOjF58mT69u3L1q1bqVatWqH6WVlZ9O7dm2rVqjFz5kxq1qzJ3r17CQ8Pd+dteEfjfrA1P1l6LCmTBtVCvBiQiIiISMXg4+PDoUOHvB1G5ZCbfEx0BGsUjoiIiHiUW8nHhx9+mPr167NixQoiIiIAOH78OHfccQcPP/wws2bNKtF1Jk2axL333svQoUMBmDJlCrNmzWLatGmMGjWqUP1p06Zx4sQJli1bhtVqPCTFxcW58xa85/JnYOtsUkzBABxLzvRyQCIiIiLly08//eSy73A4OHz4MO+88w5du3b1UlSViN0O+1cAkEgwtZR8FBEREQ9yK/m4aNEil8QjQNWqVXnppZdK/ECYlZXFmjVrGD16tLPMbDbTq1cvli9fXuQ5P/30E507d+bBBx/kxx9/JCoqittuu40nn3wSi8VS5DmZmZlkZuYn+JKSkgBj4nKbzVaiWN2Rd+1C97AEYAX8MGI6cirNo3FUNMW2m5yR2s09ajf3qN3co3Zzj9qtaJW9Pa677jqXfZPJRFRUFJdffjmvv/66d4KqTA7/49xMcISq56OIiIh4lFvJRz8/P5KTkwuVp6Sk4OvrW6JrJCQkkJOTQ3R0tEt5dHQ0W7ZsKfKcXbt28ccff3D77bcze/ZsduzYwQMPPIDNZmPcuHFFnjNx4kTGjx9fqHzu3LkEBnp+fpt58+a57Fuzk+kHWB02fMhm1dotVD+1yeNxVDSnt5uUjNrNPWo396jd3KN2c4/azVVaWpq3Q/Aou93u7RAqt5Rjzs0djpqEBSr5KCIiIp7jVvLx6quvZtiwYUydOpWOHTsCsHLlSu677z6uueaaUg2wILvdTrVq1fjvf/+LxWKhXbt2HDx4kFdffbXY5OPo0aMZOXKkcz8pKYnY2Fj69OlDaGiox2K12WzMmzeP3r17O4eIA5CdCesfBCCQTIKjGtCvXwuPxVHRFNtuckZqN/eo3dyjdnOP2s09arei5Y3kEHFL7nyPa/3aQYZJPR9FRETEo9xKPr711lsMHjyYzp07O38RsNlsXHvttUyePLlE14iMjMRisXD06FGX8qNHjxITE1PkOdWrV8dqtboMsW7atClHjhwhKyuryF6Xfn5++Pn5FSq3Wq1l8ktMofv4+IDZB+zZBJDJtmMp+mWqCGX1/als1G7uUbu5R+3mHrWbe9Rurip7W9x444107NiRJ5980qX8lVde4a+//uKbb77xUmSVRG7y8YTDmIM8VMlHERER8SCzOyeFh4fz448/sm3bNmbOnMnMmTPZtm0b33//fYlXnvb19aVdu3bMnz/fWWa325k/fz6dO3cu8pyuXbuyY8cOl6E427Zto3r16iUe7u11JhP4BgEQZMpg29FksnM0tEhEREQkz+LFi+nXr1+h8iuvvJLFixd7IaJKJjf5eDzHeCZVz0cRERHxpBL3fCw4dLkoCxYscG5PmjSpxNccPHgw7du3p2PHjkyePJnU1FTn6teDBg2iZs2aTJw4EYD777+fd955hxEjRvDQQw+xfft2JkyYwMMPP1zSt1E++AZDximCTBnY7XAyzUZUSOHemSIiIiIXouLmEbdarRpyXhrSTgAQn2PMf67ko4iIiHhSiZOP//zzz9krYaxGWFK33HIL8fHxjB07liNHjtC6dWvmzJnjXIRm3759mM35nTNjY2P57bffePTRR2nZsiU1a9ZkxIgRhYbklHu5PR+j/bJZnw4nUrOUfBQRERHJ1aJFC2bMmMHYsWNdyr/66iuaNWvmpagqkdyej8dsAQBEBus5VERERDynxMnHgj0bS9Pw4cMZPnx4kccWLlxYqKxz586sWLHCI7GUmdzkYzX/HEiH46mZQIh3YxIREREpJ8aMGcMNN9zAzp07ufzyywGYP38+X375peZ7LA25ycdERzDVw/zV81FEREQ8yq0FZ+Q8+RqTe0f5ZgNGz0cRERERMfTv358ffviBCRMmMHPmTAICAmjZsiW///47l156qbfDq/hyk48nCaZxjP4ALiIiIp6l5KM35PZ8rOprA5R8FBERETndVVddxVVXXeXtMCqn3OTjKUcwHaOVfBQRERHPcmu1azlPfsZDXpRPKgDHU5R8FBEREcnz119/sXLlykLlK1euZPXq1V6IqJJJTwQgkWBqhAd4NxYRERGp9JR89IbIxgDUyd7z/+3dd3hUVf7H8ffMZNI7qUCA0DsISkTAsnSwoK4goigqNrBhRVdUdIW1oD9dFddF0dUVdO2CSFFQkSZI770loaaQkGSSub8/LpkwJkAYmMyEfF7Pk+fee+659557mOjJd04B1PNRRERE5HgjRoxg165d5dL37NnDiBEjfFCic0hJMRRmA5BlhBETVn5VcREREZGzScFHX4g3g49xRbuB0gVnRERERARg7dq1dOjQoVz6eeedx9q1a31QonNIQZZrN4cwain4KCIiIl6m4KMvRCQBEOY4BGjYtYiIiMjxgoKCyMzMLJeenp5OQMDpT1n+5ptv0qBBA4KDg0lLS2Px4sUnzHvppZdisVjK/Rw//+Qtt9xS7nyfPn1Ou1w+kW+2P3MJpQQbsQo+ioiIiJcp+OgL4QkABBceBAwNuxYRERE5Tq9evRg9ejTZ2dmutKysLJ544gl69ux5WveaOnUqo0aN4umnn2bZsmW0a9eO3r17s2/fvgrzf/HFF6Snp7t+Vq9ejc1m47rrrnPL16dPH7d8n3zyyem/qC/kme+934gCUPBRREREvE6rXftCWDwAtpICQilk/5FADMPAYrH4uGAiIiIivvfyyy9z8cUXU79+fc477zwAli9fTmJiIv/5z39O614TJkxg+PDhDBs2DICJEycybdo03nvvPR5//PFy+WNjY92Op0yZQmhoaLngY1BQEElJSadVFr+QmwHAPiMagJhQBR9FRETEuxR89AV7KGABDCJthWTkB7PzUD71a4X5umQiIiIiPlenTh1WrlzJxx9/zIoVKwgJCWHYsGEMHjwYu91e6fsUFRWxdOlSRo8e7UqzWq306NGDBQsWVOoekyZN4vrrrycszL2dNnfuXBISEoiJieEvf/kLzz//PLVq1TrhfQoLCyksLJvnOycnBwCHw4HD4aj0O52O0vsef39r9l5slAUfLUYJDkeJV55fXVVUb3JqqjfPqN48p7rzjOrNM6q38k6nLhR89AWLBewh4MinWWwAGfthx0EFH0VERERKhYWF0bVrV+rVq0dRkTlFzffffw/AlVdeWal7HDhwgJKSEhITE93SExMTWb9+/SmvX7x4MatXr2bSpElu6X369OGaa64hNTWVLVu28MQTT9C3b18WLFiAzWar8F7jxo3j2WefLZc+c+ZMQkNDK/U+npo1a5Zrv+WeBTQB9h8LPk6fPt2rz67Ojq83qTzVm2dUb55T3XlG9eYZ1VuZ/Pz8SudV8NFXjgUfY4OcAOQWFPu4QCIiIiL+YevWrVx99dWsWrUKi8VSbnqakpKq6ak3adIk2rRpQ6dOndzSr7/+etd+mzZtaNu2LY0aNWLu3Ll07969wnuNHj2aUaNGuY5zcnJISUmhV69eREZGeqX8DoeDWbNm0bNnT1ePUdvX38I+s+fj5W2S6NevrVeeXZ1VVG9yaqo3z6jePKe684zqzTOqt/JKR3FUhoKPvhIQAkBsoBl0zClQ110RERERgPvvv5/U1FTmzJlDamoqixYt4tChQzz00EO8/PLLlb5PXFwcNput3MrZmZmZp5yvMS8vjylTpjB27NhTPqdhw4bExcWxefPmEwYfg4KCCAoKKpdut9u9/keM6xmGAas/A8zg4wWptfQH1ElUxb/NuUj15hnVm+dUd55RvXlG9VbmdOpBq137it0MPsbYzW/uc44q+CgiIiICsGDBAsaOHUtcXBxWqxWbzUbXrl0ZN24c9913X6XvExgYSMeOHZkzZ44rzel0MmfOHDp37nzSaz/77DMKCwu58cYbT/mc3bt3c/DgQZKTkytdNp/I3u3aXWk0JDxI/RBERETE+xR89BV7MABRdrPn4+Z9R3xZGhERERG/UVJSQkREBGD2Xty7dy8A9evXZ8OGDad1r1GjRvHuu+/ywQcfsG7dOu6++27y8vJcq18PHTrUbUGaUpMmTWLAgAHlFpE5cuQIjzzyCAsXLmT79u3MmTOHq666isaNG9O7d29PXrfqFOW5drcYdQhT8FFERESqgFocvmI3JxZPCTcPF2075MPCiIiIiPiP1q1bs2LFClJTU0lLS+PFF18kMDCQf/3rXzRs2PC07jVo0CD279/PmDFjyMjIoH379syYMcO1CM3OnTuxWt2/j9+wYQO//vorM2fOLHc/m83GypUr+eCDD8jKyqJ27dr06tWL5557rsJh1X7FYQYf9xhmQDUiWH8KiIiIiPepxeErAWbPxzYJgQBk5BSUm0xdREREpCb629/+Rl6eGSgbO3Ysl19+Od26daNWrVpMnTr1tO83cuRIRo4cWeG5uXPnlktr1qwZhmFUmD8kJIQffvjhtMvgF4rMVSmPGmaQtF6sd1fZFhEREQEFH30n9Ng3zs4sIJaiYidHCouJCNbEpSIiIlKzHT98uXHjxqxfv55Dhw4RExOjL2rPhMMMPuZhfgmeouCjiIiIVAHN+egrUXUBCDyyl7BAGwAHjxT5skQiIiIifis2NlaBxzN1bM7HowRxX/cmPi6MiIiI1BQKPvrKseAj2bupFW4OfTlwpNCHBRIRERGRc9qx4GO+EUR0iEbbiIiISNVQ8NFXwuLNbd4B4sLNeR8PqOejiIiIiHhL5moADhhRRCr4KCIiIlVEwUdfCYszt/kHXD0fD+ap56OIiIiIeIHTCas/B2C6sxNRCj6KiIhIFVHw0VdCjwUf8w4QH2EGHzNzFHwUERERES84ehjy9gMw39mGRvFhPi6QiIiI1BQKPvpKeIK5PXqY1Ghz0fFtB/J8WCAREREROWflHwQg2wjFZg+kQS0FH0VERKRqKPjoK6G1wB4GGLQMzQZgu4KPIiIiIuINx4KPh40I6sWGYrVq5XARERGpGgo++orFAjENAEh2ZgCwP1fDrkVERETEC44eAuAwZvBRREREpKoo+OhLITEARNsKAHPBGcMwfFkiERERETkXHdoKQLoRS90YBR9FRESk6ij46EuBZsMvwuoAwFFikHO02JclEhEREZFzUeYaANY766nno4iIiFQpBR99yR5ibpwFRIfaAcjIKfBliURERETkHGQc2AjARqMuzZIifFwaERERqUkUfPQl+7FvnR351I0xA5G7D+f7sEAiIiIics4xDIz9ZvBxO8l0rB/j4wKJiIhITaLgoy8d6/mI4yh1o81A5O7DR31YIBERERE55+Ttw1qUS4lhwRnTkGC7zdclEhERkRpEwUdfKu35WJSnno8iIiIi4hWWg5sB2G3E07ROnI9LIyIiIjWNgo++5Bp2fdQVfHz3l204nVrxWkRERETODsvBTQBsNZLp0SLRx6URERGRmkbBR18KLOv5mNawlit5X26hjwokIiIiIuecfWsB2GLUpmXtSB8XRkRERGoaBR99KTja3BZk0SI5ksjgAADSszXvo4iIiIicJRt/AGCxs7lrtI2IiIhIVVHw0ZdCjq00mH8IgCaJEQBkZBf4qkQiIiIici4xnFiPZACwMaApoYEBPi6QiIiI1DQKPvpSaKy53bUQnCUkRQUDkK7go4iIiIicBfaSPCxGCQAB4VpsRkRERKqego++VNrzEWDbPJIjzeBjRo6CjyIiIiJy5oKKcwDIMsKIiQz3cWlERESkJlLw0ZfiW5TtZ+9x9Xzck6U5H0VERETkzAUV5wJw0IgkPiLIx6URERGRmkjBR1+yBUCHoeZ+bjqpcWEAbNl3xIeFEhEREZFzRaDD7Pl4kEjiwxV8FBERkaqn4KOvhSea2yP7aJZkLjizZf8RHCVOHxZKRERERM4FpcOuDxqRJEdrpWsRERGpego++lpQpLktzKVOdAjhQQE4Sgy2HcjzbblEREREpNoLLzRXuj5oRHJJ03gfl0ZERERqIgUffS3I7O1IYQ4Wi4XGCeZE4Bp6LSIiIiJnKiFnFQArjYYkaM5HERER8QEFH30tuKznI0DdGHM4jBadEREREZEzFeTIAmCJszlRIXbfFkZERERqJAUffa102HVBNgB1js3FszerwFclEhEREZFzQXEBgU7zC+2iwBgCbGr6i4iISNVTC8TXXHM+mpOBJ0cFA7BXPR9FRERE5EzkHwTAYdiwhET7tiwiIiJSYyn46Gt/GnZd+1jPxxlrMsgpcPiqVCIiIiJS3R1rX+YSQkpsmI8LIyIiIjWVgo++VrrgTEEOGAZ1js35CPDfRTt9VCgRERERqfZKigAowk5qvIKPIiIi4hsKPvpa6bBrpwOKC2iZHOk6tSlTK16LiIiIiGcsJeYoGocRoJWuRURExGcUfPS1wHDAYu4X5mKxWHj5unYA7MvVojMiIiIi4iFXz8cAYkIDfVwYERERqakUfPQ1q9V96DWQGGl+M52ereCjiIiIiHjIeaznIwFEh9p9XBgRERGpqRR89Adhceb2SAYAqXHmnDzbD+RRWFziq1KJiIiISHVWOuwaG1EhCj6KiIiIbyj46A9iUs3toa0A1IkOISrETrHTYOv+PB8WTERERESqrWPDrosJICJYwUcRERHxDQUf/UFMA3N7eAcAFouFlFhz1eu9WUd9VCgRERERqdaO9XwsIoDQQJuPCyMiIiI1lYKP/iAiydzm7XMlJUUeCz5q3kcRERER8cSxno8Ow0aIXcFHERER8Q0FH/1BeIK5PVIWfKxfKxSADRk5viiRiIiIiFR3JWULzqjno4iIiPiKgo/+ICLZ3O5a7GokXtAgFoDF2w75qlQiIiIiUo0VO471fCSAYAUfRURExEcUfPQHDbqCLRCOHoKDWwDoUC8agM37jpBXWOzDwomIiIhIdeQoKgTMOR817FpERER8RcFHfxAYVrbi9ZEMABIig0mKDMZpwJq9GnotIiIiIqen2GEGH52WAOw2NftFRETEN9QK8RcRieY2N9OV1LZuFAArd2f5oEAiIiIiUp2VBh8Na4CPSyIiIiI1mYKP/iL82IrXx3o+ArRLiQZgypJdGIbhg0KJiIiISHXlLDGn7imxKPgoIiIivqPgo7+ooOdjvzbmQjSb9x1hQ2auL0olIiIiItWU0+kEwGJRk19ERER8Ry0Rf1Ha8zE33ZWUGhfGxU3jAfhl4wFflEpEREREqinDWWJu1eQXERERH1JLxF9EHAs+5u13S+7WOA6ApTsOV3WJRERERKQacwUf1fNRREREfEgtEX8REmNuj7oHGVNiQwGYsSZD8z6KiIiISKVp2LWIiIj4A79oibz55ps0aNCA4OBg0tLSWLx48QnzTp48GYvF4vYTHBxchaX1khMEHxMig1z7P6zJQERERESkMoxjwUesftHkFxERkRrK5y2RqVOnMmrUKJ5++mmWLVtGu3bt6N27N/v27TvhNZGRkaSnp7t+duzYUYUl9pITBR8jyoKPmzKPVGWJRERERKQaKx12jXo+ioiIiA/5vCUyYcIEhg8fzrBhw2jZsiUTJ04kNDSU995774TXWCwWkpKSXD+JiYlVWGIvKQ0+OvKhsGxl67oxoa79wmJnVZdKRERERKopw1DwUURERHwvwJcPLyoqYunSpYwePdqVZrVa6dGjBwsWLDjhdUeOHKF+/fo4nU46dOjACy+8QKtWrSrMW1hYSGFhoes4JycHAIfDgcPhOEtvUl7pvSv9DFsoAdENsGRtp3jdNIxW17pOPdyzCS/P2sQ/f9rMvZemYrVavFFkv3Da9SaA6s1TqjfPqN48o3rzjOqtYqoPqYzSYddacEZERER8yafBxwMHDlBSUlKu52JiYiLr16+v8JpmzZrx3nvv0bZtW7Kzs3n55Ze56KKLWLNmDXXr1i2Xf9y4cTz77LPl0mfOnEloaGi59LNt1qxZlc7bMrAFTdjO7l+msGJHiCv94EELYAPglU9m0Crm3F945nTqTcqo3jyjevOM6s0zqjfPqN7c5efn+7oIUg0YWnBGRERE/IBPg4+e6Ny5M507d3YdX3TRRbRo0YJ33nmH5557rlz+0aNHM2rUKNdxTk4OKSkp9OrVi8jISK+V0+FwMGvWLHr27Indbq/UNZaVufDt99SLgjr9+rnSz88t5P0X5wGwzZLMI/3ae6PIfsGTehPVm6dUb55RvXlG9eYZ1VvFSkdyiJyMYRybskfBRxEREfEhnwYf4+LisNlsZGZmuqVnZmaSlJRUqXvY7XbOO+88Nm/eXOH5oKAggoKCyqXb7fYq+SPmtJ4THgeAtSAL63HX1Ikt25+1bl+N+OOrqv59zjWqN8+o3jyjevOM6s0zqjd3qgupjNIFZyxa7VpERER8yKctkcDAQDp27MicOXNcaU6nkzlz5rj1bjyZkpISVq1aRXJysreKWXVCY81t/qFypzo3rOXa/23LgaoqkYiIiIhUU6XDrrHYfFsQERERqdF8/jXoqFGjePfdd/nggw9Yt24dd999N3l5eQwbNgyAoUOHui1IM3bsWGbOnMnWrVtZtmwZN954Izt27OD222/31SucPaUrXh/NKnfq1UHtXfsj//tH1ZRHRERERKovDbsWERERP+DzOR8HDRrE/v37GTNmDBkZGbRv354ZM2a4FqHZuXMn1uOGihw+fJjhw4eTkZFBTEwMHTt25LfffqNly5a+eoWzJ+RYz8fCbCgpBlvZP09iZNnQ8UN5RVVdMhERERGpZkrnfNSCMyIiIuJLPg8+AowcOZKRI0dWeG7u3Llux6+++iqvvvpqFZTKB4KjyvYLsiAsznVosVhc+y2TvbdQjoiIiIicIzTno4iIiPgBtUT8iS2gLACZt7/c6U/vNOfBXJuew6y1meXOi4iIiIiUKu35aGjORxEREfEhBR/9TUG2uZ3zXLlTLWuX9Xgc/uHvVVUiEREREamGShecUc9HERER8SW1RPzVhmnlksKD3EfJFxaXVFVpRERERKS6MRR8FBEREd9TS8TfdH3Q3NbuUOHp2aMuce2P/nxVVZRIRERERKohi1H6RbWa/CIiIuI7aon4m6Z9zO3RQxWebpwQ7tr/4o89VVEiEREREamODAMAp1a7FhERER9SS8TfRNY2tzl7oaS4wiyXNI137TudRlWUSkRERESqGcuxYddq8ouIiIgvqSXibyLrQkAIlBRB1o4Ks7xzU0fX/qx1WvVaRERERMqzULratcXHJREREZGaTMFHf2O1QnQ9cz97V4VZgu021/7bc7dURalEREREpJop7floaNi1iIiI+JBaIv4oJNrcfngVFBdVmGVAe3N49vJdWbwxZxOGoeHXIiIiInK8Y8FHbKfIJyIiIuI9Cj76o6CIsv1t8yrMMuiCeq79V2ZtZNWebG+XSkRERESqEcuxL6c17FpERER8ScFHf+QoKNu3VvxNdbOkCLfjo0Ul3iyRiIiIiFQzrjkf1eQXERERH1JLxB8d3la2f3wg8jixYYG8O/R813FOQcUrY4uIiIhIzeRa7Vo9H0VERMSHFHz0RxfcVrZfmHvCbD1bJrr2h3/4uzdLJCIiIiLVTNmCM5rzUURERHxHwUd/dOE9YAs09wtzfFsWEREREamWNOxaRERE/IFaIv7IHgJtrjP3TyP4+PnS3RQVO71UKBERERGpVrTgjIiIiPgBBR/9VVicuT2y/6TZmiSEu/Yf+mwFz367xpulEhEREZFqwmIcW5DQoia/iIiI+I5aIv4qora5XfQ2lDhOmO3D2zq5HX+8aCfGsW+5RURERKTmsmC49kRERER8RcFHfxWeULa/f8MJsyVHhfDC1W3c0j74bbuXCiUiIiIi1UXpgjNOLTgjIiIiPqTgo79qfnnZ/uFtJ816Q1o9fnn0MtfxM9+u9VapRERERKSacC04o2HXIiIi4kNqifirgEBoe725v2vRKbOnxIa6HWdkF3ijVCIiIiLVzptvvkmDBg0IDg4mLS2NxYsXnzDvpZdeisViKffTv39/Vx7DMBgzZgzJycmEhITQo0cPNm3aVBWvcloshoZdi4iIiO8p+OjPGnc3t7uWVCr7/Mf/4tr/ZdPJF6oRERERqQmmTp3KqFGjePrpp1m2bBnt2rWjd+/e7Nu3r8L8X3zxBenp6a6f1atXY7PZuO6661x5XnzxRV5//XUmTpzIokWLCAsLo3fv3hQU+NeXv38kXM2LjkHsD67v66KIiIhIDabgoz+Lqmtu8ypuHP9ZnegQ7rykIQC/bz/srVKJiIiIVBsTJkxg+PDhDBs2jJYtWzJx4kRCQ0N57733KswfGxtLUlKS62fWrFmEhoa6go+GYfDaa6/xt7/9jauuuoq2bdvy4YcfsnfvXr766qsqfLNTWxXfn7dKruJwcIqviyIiIiI1WICvCyAnEXZs0Zkjle/F2LFeDABTf9/Fle1r06VxnDdKJiIiIuL3ioqKWLp0KaNHj3alWa1WevTowYIFCyp1j0mTJnH99dcTFhYGwLZt28jIyKBHjx6uPFFRUaSlpbFgwQKuv/76Cu9TWFhIYWGh6zgnJwcAh8OBw+E47XerjOKSEgAMp9NrzzgXldaV6uz0qN48o3rznOrOM6o3z6jeyjudulDw0Z+FHQscFuVC3oGy45O4tFnZKtlD/r2I5WN6Eh0a6K0SioiIiPitAwcOUFJSQmJiolt6YmIi69evP+X1ixcvZvXq1UyaNMmVlpGR4brHn+9Zeq4i48aN49lnny2XPnPmTEJDQyu44sxt32EFrOzYuZPp07d75RnnslmzZvm6CNWS6s0zqjfPqe48o3rzjOqtTH5+fqXzKvjoz4Kjyvan3AC3zTzlJYEBVoZ3S+XdX8wVsqetSmdImub5ERERETldkyZNok2bNnTq1OmM7zV69GhGjRrlOs7JySElJYVevXoRGRl5xvevyKrv18PenTSoV49+/Vp65RnnIofDwaxZs+jZsyd2u93Xxak2VG+eUb15TnXnGdWbZ1Rv5ZWO4qgMBR/9meW4lQkrseJ1qVE9m/HvX7dhGPDkl6u5vG1tokL0yyEiIiI1S1xcHDabjczMTLf0zMxMkpKSTnptXl4eU6ZMYezYsW7ppddlZmaSnJzsds/27duf8H5BQUEEBQWVS7fb7V77I8ZiNad3t9ls+kPJA978tzmXqd48o3rznOrOM6o3z6jeypxOPWjBGX835H/m1hYEhlGpS0ICbbx+/Xmu4/d+3eaNkomIiIj4tcDAQDp27MicOXNcaU6nkzlz5tC5c+eTXvvZZ59RWFjIjTfe6JaemppKUlKS2z1zcnJYtGjRKe8pIiIiUhMp+Ojv6ncxtyWFUJBd6cuuaFebh3o2BeD/5mzihzUnnoNIRERE5Fw1atQo3n33XT744APWrVvH3XffTV5eHsOGDQNg6NChbgvSlJo0aRIDBgygVq1abukWi4UHHniA559/nm+++YZVq1YxdOhQateuzYABA6rilSqt9Gvr4wfTiIiIiFQ1Dbv2d4GhEBQJhTmQtx9Coit96eXtavPKrI0AfPb7bnq3OvnwIhEREZFzzaBBg9i/fz9jxowhIyOD9u3bM2PGDNeCMTt37sRqdf8+fsOGDfz666/MnFnxfNuPPvooeXl53HHHHWRlZdG1a1dmzJhBcHCw19/ndBiVHDUjIiIi4k0KPlYH4Qlm8DE3HeKaVPqy1Lgwbu+ayr9/3caynYcpcRrYrPrqW0RERGqWkSNHMnLkyArPzZ07t1xas2bNThq4s1gsjB07ttx8kCIiIiJSnoZdVwdxzczt8v+e9qV3XtKIYLuVQ3lFXP3WfIpLnGe5cCIiIiLizywady0iIiI+pOBjddD+BnO75stKLzpTKj4iiBGXNgZg5e5sGj/5PSVODcEREREROdeVNhsVehQRERFfUvCxOmh0mbktLoBFE0/78tu7NaR2VNkcRF3G/8hPG/ax82D+2SqhiIiIiPgpdXwUERERX1LwsToIDCvbn/E4ZO08rctDAm38+PClruOMnAKGvb+Ei1/6iV2HFIAUERERORdprIuIiIj4AwUfqwvrcWsDLZl02pcH2238+thlhNhtbunXTVxwpiUTERERET9UumiORQOvRURExIcUfKwu7l4AzS8397f97NEt6saEsu65Pm5pGTkFrNqdfaalExERERE/U9rzUcOuRURExJcUfKwu4ptC3xfN/fTlUJjr8a1eHdTO7fhQfpHrm3EREREREREREZGzRcHH6iSqDoTWAsMJh3d4fJurz6vLhIFlAcib31tM6ujpfLzI83uKiIiIiH/RatciIiLiDxR8rG4i65jbQ1vO6DZXn1enXNqTX64+o3uKiIiIiP9wjWtR9FFERER8SMHH6iaytrn9dCjkHfD4NhaLhfeHXVAu/f4pf2gItoiIiIiIiIiInBUKPlY3ye3L9j+65oxudVmzBOY8dIlb2tfL95I6ejoFjpIzureIiIiI+JhWuxYRERE/oOBjddPq6rL99BVnfLv6saE0SQgvl75mr1bAFhEREanOtNq1iIiI+AMFH6ubqD/N1egoOKPbBdis/PDAxax+trdb+rVvL6DB49PIKXCc0f1FRERERERERKTmUvCxugmKcD/O2nnGt7RaLYQHBRAWaCt37t8/bz3j+4uIiIhI1dNq1yIiIuIPFHysju5dVrafteOs3fbdoeeXS/v0991n7f4iIiIiUnWMYwOvNexaREREfEnBx+qoViNIvdjc//ivsP3Xs3LbixrHsfKZXkwY2M6VlpFTwLSV6Wfl/iIiIiIiIiIiUrMo+FhdHdlftj+5PxQeOSu3jQy2c02Hurx5QwdX2oj/LqP3qz9zy/uLmbMu86w8R0RERES8q2zYtbo+ioiIiO8o+Fhd9XvJ/fiXl8/q7bu3SCDEXjYH5IbMXOZu2M9tH/x+Vp8jIiIiIt5Rutq1Yo8iIiLiSwo+Vlep3eDu38qOf331rN4+2G5j1TO9Kjz36ZJdZ/VZIiIiInL2Gcap84iIiIh4m4KP1VliK/fjD6+CEsdZu32AzcrEGzvQNDGcmzvXd6U/+vlKHpy6nIETFzB3w76z9jwREREROfvU8VFERER8ScHH6q7toLL9rXPhy7vO6u37tE5m5oOX8NTlLd3Sv/xjD4u3H+KW95dwKK/orD5TRERERM6G0tWuFX4UERER31Hwsbq7/E/DrVf/zyuPCbBZWTD6LxWeu/M/mgdSRERExN+ULTgjIiIi4jsKPlZ3gWHl03Ys8MqjkqNCmPFAN27vmuqWvmT7YZo/9T1TFu/0ynNFRERERERERKR6UvDxXPR+H6/dunlSJH+7vCVL/9aDt4Z0cKUXOJw8/sUqGjw+jbfmbmbaynSvlUFERERETq10vRmNuhYRERFfUvDxXHDzdxDfokofWSs8iH5tkrnj4oblzr04YwMj/ruMCbM2VmmZRERERKSMhl2LiIiIP1Dw8VyQ2g2Gz3FPW/MVOJ1ef/QtFzUgOSqYYHv5j9LrczaxaOtBr5dBRERERERERET8U4CvCyBnSWAY9HwOZj1lHn92M7QbDFdP9Opja0eHMO+Ry7DbLKxLz6Xf67+4nR/0r4W0qRNFZk4B4cEBTL2jM/ERQV4tk4iIiIiAodWuRURExA+o5+O5pMt90P7GsuMVn1RJ78fAACsWi4WWtSP59M7O1I4Kdju/ak82+3IL2bo/jwv+Ppvnvlvr9TKJiIiI1HSlw65FREREfEnBx3PNgDfdj38YXaWP75Qay/T7u1U4DLvUpF+38eKM9VVYKhERERERERER8QUFH891iybCPy+ATbOq7JHRoYF8f//FnF8/5oR53pq7BUeJk12H8jlwpLDKyiYiIiJSU2i1axEREfEHmvPxXDTkc/j42rLjAxvh47/CM9lVVoTUuDD+d/dFGIbBku2H2X4gj0c/X+mWp8mT37v2+7dJ5s0hHaqsfCIiIiLnPKN0zkcfl0NERERqNPV8PBc16QF9/uHrUgDmBOedUmMZeEEKH97aibTU2ArzTVuVzugvVmJociIRERGRs0LNKhEREfEH6vl4rup0B/zxH8hc7euSuFzcNJ6Lm8azP7eQC/4+u9z5TxbvYuaaTP6SYCFqy0EaJ0YSExpIWJA+piIiIiKesqCujyIiIuI7ftHz8c0336RBgwYEBweTlpbG4sWLK3XdlClTsFgsDBgwwLsFrI6sVrhjHrQ+bvj1xG5QmOu7Mh0THxHEx7enVXjuYF4Rn22zccvkpXT9x0889OmKKi6diIiIyLlBcz6KiIiIP/B58HHq1KmMGjWKp59+mmXLltGuXTt69+7Nvn37Tnrd9u3befjhh+nWrVsVlbQasgXARfeWHWeshHF1Yd23UJDju3IBXRrHMffhS9nwfB+2j+/PkLR6FeabsSaDOesyWb0nmxveXcgfOw9T4jTIzCmo4hKLiIiIVC8adi0iIiL+wOfBxwkTJjB8+HCGDRtGy5YtmThxIqGhobz33nsnvKakpIQhQ4bw7LPP0rBhwyosbTWU2KZ82tQb4cu7qr4sf9IgLoygABsAf7+6DZ8Mv7DCfLd98DuXv/Erv205yC3vL+FvX60m7YU5/LblQFUWV0RERKRaUsdHERER8SWfTqZXVFTE0qVLGT16tCvNarXSo0cPFixYcMLrxo4dS0JCArfddhu//PLLSZ9RWFhIYWGh6zgnx+zx53A4cDgcZ/gGJ1Z6b28+o9KeNIN0tkndsWYcG8a8YRrF62dgNOruw4K5O79eJHd2rc/3f2ynQ+NkvlqRUS5P9lEHnyzeCcDYb9bw39svICLYXtVF9Tt+9XmrRlRvnlG9eUb15hnVW8VUH1IZBqWrXSv8KCIiIr7j0+DjgQMHKCkpITEx0S09MTGR9evXV3jNr7/+yqRJk1i+fHmlnjFu3DieffbZcukzZ84kNDT0tMt8umbNmuX1Z1RW3aDOdKRsDsWAKYOY3uYtYvM2kRnZ3i8mBGoJtGwLsJuvTvHxXJ95hA5//4nrUkvomqRxReBfn7fqRPXmGdWbZ1RvnlG9ucvPz/d1EaQa0LBrERER8QfVahnh3NxcbrrpJt59913i4uIqdc3o0aMZNWqU6zgnJ4eUlBR69epFZGSkt4qKw+Fg1qxZ9OzZE7vdT3rmpdeB9ya6JfVbdQ8AJb3/gfP823xRKjfH19sPFxQx9ffdjLysETkFDt75eRufLNld7prPttkIS6rH4XwH365M58VrWnNV+9oYhsGDn60iLjyQv/Vr7oO3qTp++XmrBlRvnlG9eUb15hnVW8VKR3KIiIiIiPg7nwYf4+LisNlsZGZmuqVnZmaSlJRULv+WLVvYvn07V1xxhSvN6XQCEBAQwIYNG2jUqJHbNUFBQQQFBZW7l91ur5I/YqrqOZWS0PSEp2y/vYats+/ngSxlt9tpVjuUMVdGAxAbEcLYAW2IDA3knXlby+WfvGCna//hz1eTmhBBiD2AaavModt929TGUeKkW5P4Kim/r/jV560aUb15RvXmGdWbZ1Rv7lQXUhla7VpERET8gU8XnAkMDKRjx47MmTPHleZ0OpkzZw6dO3cul7958+asWrWK5cuXu36uvPJKLrvsMpYvX05KSkpVFr/6CY6E23+E4T/CdR+4n8tNh392goxVvilbJdhtVkb3bcH28f1PmffatxfQ7/Wy+UCv/9dCbpq0mF2HNExNREREaggNuxYRERE/4PPVrkeNGsW7777LBx98wLp167j77rvJy8tj2LBhAAwdOtS1IE1wcDCtW7d2+4mOjiYiIoLWrVsTGBjoy1epHup2hDododUASL3Y/dyBDTCxK+z9wydFOx2vDmoHQJ3oEJonRQDQus6ph9G/PHMDe7OOUlzi9Gr5RERERPyFOj6KiIiIL/l8zsdBgwaxf/9+xowZQ0ZGBu3bt2fGjBmuRWh27tyJ1erzGOm5afAUWPAWbJjmHnD8321w+2wIifHbcTpXn1eXtNRaJEcFYxhwOL+IWuFB9Jwwj037jpzwuq+X7+Xr5Xtdx3de0pDH+zTXKpAiIiJyztFq1yIiIuIPfB58BBg5ciQjR46s8NzcuXNPeu3kyZPPfoFqisAwuOQRM8B4fPDx0BZ4MRU63Qlt/gr71kKHm/0uEFk7OgQwi1Ur3JzXc8odF/LZ0t2s3ZtDdKidDxfsOOk93pm3lXfmbSU61E5WvoPBnVK4rFkC//5lG68MbEdKrPdXRBcRERHxhtLVrv2rBSciIiI1jV8EH8XH2vwVdi0CZwlsKZt/k8XvmD8A0fWh0WW+Kd9pqBUexF2XlC069ES/FvSYMI/dh4+e9LqsfAcAnyzexSeLdwHH5onsXJ+GcWH0amUugGQYhnoPiIiISLWgKR9FRETEHyj4KBDTAIZ8BkX58H4fSF9RPs9/BsCYw1DNhsAH221MGNielbuzWLztEDPXZvK3/i34ZPFOtuzPO+m1e7KOMv779eXSnxvQmnqxoew+nM+QtPreKrqIiIjIWaHvTUVERMSXFHyUMoGhcOfP8ExUxed3LoAGXcx9w6g2LdlOqbF0So3lhrR6rNmbQ8d6MdzerSEFjhK+X53Og1MrCLaexFNfrXbtO50GV51Xh8hg+9kutoiIiMgZMY6Nu64eLTYRERE5V1WvbmxSNQKCK04vzDG3676DlxrB5tlVV6azIDQwgAsaxGK1mk3wYLuNq8+ry12XNKJBrVDeGtLhtO/51NdrGPb+EgzD4MUZ6xk1dTk5BY6zXXQRERGR06Zh1yIiIuIP1PNRyrtnIbzevnz6J9eDxQqG0zz+6FoYMBHaD67S4p1tj/dtzuN9mwOwfXx/0rOPcs/Hy8gvLGFDZu4pr1+64zBPfrWa/y7aCcAXf+wB4LE+zRnWpQE/rMmg0OFk4AUp3nsJERERkROpJqNVRERE5Nyk4KOUF5sKd8yDwlw4uAm+e7DsXGngsdRXd0FiK0huW7Vl9KLkqBC+vKcLBY4SbvtgCTarlZ837j/pNaWBx+P9Y8Z6/jGjbM7Ibk3jSI4KcR1nZBfw4oz1DL2oAe1Tos9a+UVERERAq12LiIiIf1DwUSpWu725rXehe/CxIu90g3uXwZ5lUJAFnYZ7u3RVIthu4+PbLwTMxWdsFgtZR4tYuuMwXRrFcenLc0/rfk9/vYYNmbncclED/tqxLn/7ajWz12XyxR972D6+vxfeQERERERERETEtxR8lJOz2eGxHbDjNziwEWY/XXG+N46bL7HehZDUpmrKV0XqRJs9FpOigmmeFElxifMUV5Q3c20mAM9+u5Znv13rdu7dn7cCMGttJlGhdv51U0csGiIlIiIiZ4GaFCIiIuJLCj7KqYVEQ/N+QD84/1YYf4q5C3f8BhHJEBZXFaXziQCblQ9v7UR+UQk9WyYyYdYGGieEk1tQzO7DR2mcEE5aaiyXvDS3Uvf7+/R1bsdTluyidnQIjmInbetGERsWyMo92bSrG43Nqr8gRERE5NTKVrtW20FERER8R8FHOT3BkfDwZsjbB9t+hhmPl8/z/aPmz5VvwHk3mV+3O0tg00zYuQDqd4Wmvaq+7GfZxU3jXfuP9G5e7nxpgx/g/WEXMGddJh8tLD83ZEVGf7HK7bh5UgTrM8zFb5omhvP2jR1pGBfGuvRc3vl5C/de1tCTVxAREZFzmFa7FhEREX+g4KOcvvB48yexFUTVhak3Vpzvm3th+qNQfNQ9ff7/wTPZ5v6hrfDzy9Dlfohv5t1yVzGLxcLsUZeQfdRBx/oxXNYsgWevbE2jJ6af9r1KA48AGzOP0P2VeTzYoyn//GkTjhKDr5fv5e/nm+dzChx8vyqdb1bsZcSljQkMsPLHzixu75aqodwiIiI1kP73LyIiIr6k4KOcmRZXwAOrYNdi+Py28uf/HHgstWIK/Pg8ZO8yj7f8CA+trzhvNdY4Idzt2Ga18MwVLdl+MJ/Jv213S+/ZIpEZazIqfe9XZ290O355pY23N//M7qwCV9r8zQdd+0F2K0M7Nzi9FxAREZFqS6tdi4iIiD9Q8FHOXHQ9iEqBo4ch/xDMGw/GKRZk+fJO9+PcdHgmCuslo4EWXiuqP7ilSyoAnRvV4uvle3j2ytZYLBAXHsTW/Ud4fto6hndryL7cAjJzCnhheuWCsoeLLBwuKjjh+TFfr+GiRrVonBBR7pxhGBQWO9l5KJ9G8eGaV1JEROQcYGjgtYiIiPgBBR/l7LBYoNNwc//Sx2DzbPjoWvc8t0yHyf1OehvbvHFY2r9vflW/8QdIaGEGN89BvVsl0btVkltaw/hw3rvlAre0ro3j6f/GL7RPiWb8NW2ZumQX783f5tEze0z4mSYJ4QTYrKxLz6F/22T6t0nmno+XufLc95fGjOrVjPUZOUxbmY7TMLi5cwMigu18tnQX3Vskulb/FhEREf/l6vmo7xRFRETEhxR8FO9o3AOaXw7rvzOPH98JwVHQ+lpY/flJL22/8z2s81bB/AlgC4Kn9oHTCY482LkI8g9Au+ur4CX8Q8vakax/rg8BVis2q4UxV7Tkkd7N2JN1lDV7s4mPCOKGdxdV+n6b9h1x7U9bmc60lelu51//cTOLtx9i4dZDrrQ3f9rC0M71+XDBDt76aQsLn+gOwOo95tyd8zbup0lCOL3+FEwVERERf6Doo4iIiPiOgo/iPYM+ghWfQHJ7M/AI8Nf3Thl8rHfoF5j/i3lQUghvpsH+Pw09/nok3L/cXPAGYP8Gc6h3wrk5ZDsowOZ2HBJoo3FCuGtOycm3dOSN75bQ8/zmNIyPYOHWQyftHRkUYKWw+MRD448PPJb6cMEOADJyzKHds9dmcvuHv7vl2TauHzkFxUSF2Cv3YiIiIuI1GnQtIiIi/kDBR/EeiwXa31A+vedzMPsZiKlvrnYNJ+8R+efAI4DTAUsmQcYqSEmDn54305/MAHvNGxLcpVEtsps46delAXa7nQ71Y9iQmUP9WmEMPD+F9inRpGcf5f3526kVFsgV7WoDMOnXbUz69fSHcM/buL9c4BEgdbS5knezxAhmPNBNq2uLiIj4koZdi4iIiB9Q8FGqXpf74ILbwSiBZR9Cy6vMHoyGE9Z8Wfn7/DrB3G6eVZaWtQvim5YdH80CZzGExIDVBiXF5nMDgs7Kq/iruPAgPr79Qre05KgQnujn3jP0qctbsuNgHrPX7Tut+9/83uKTnt+QmUvq6Ok0TginSUI436/OICrEzrcju7JidxZ/n7aON4ecR8f6sa5r8ouKGf/9egacV4cQu4248CAKi0uoGxN6WmUTERERd4o9ioiIiC8p+Ci+EXgsoNR5RFlar7+7Bx/jmsF5Q+DgZjNIWRlvXgBtB0G3h82A5j/qm+lWOzy0oWzBmzt/gYBA92tLHDBtFNS9ANoPMYOVNcDIvzRh4dZDhAbaaBQfzqRbzsdqsdDz1XnEhQfxzo0deW7aOr5dsfe077153xE2H5tjMvuog4tf+sl17tq3FzCqZ1PSUmPpWD+GlmN+AMqGd5f646mexIT96d9KRERETql0tWv1fBQRERFfUvBR/EdUHRzDf+aXX36lW5+rsUebQ4M5sh82zoQjGZW7z8qp5s/xnA54qWHZ8Z7fwZEP+Yeh7XXw80vw47Gh28s+hN2/wxX/Z/bGPMeDkO1Toln5dC+sVve/TH586FKsFgs2q4UJA9sRaLPy+bLdbnlS48K4qFEttu7PY8HWg6f97AmzNp4yz3nPzaJlciT7cgu59y+NaZYUQXhQAA3iwvhi2W6ubFeb6FD34OTyXVl88Nt2HuvTnKSo4NMul4iIyLnA0KSPIiIi4gcUfBT/ktCS3JDtEBZflhYeby4uk3/QHEad1NpMfyaqLE+3h+CXVyr/nPf7lu3/Pgl2LnA/v+wD2DQTco+tBB1RG7o+YAYjI5Kh1QAzvSAHMtdA/c6Vf7Yf+nPgEcBus7rtvzKwHa8MbMfyXVlkZB+lT+tkt/wrd2dxy/tLuLVLA37eeIDdh/PZm11wVsq3Nj0HgKe/WVPu3Jiv1zDjgW4kRARz/5Q/+GvHutw/ZTkAxU6DNwafx/YDeazZm8Onv+/izosb8s7PW7nrkkacXy/yrJRPRETEn1k08FpERER8SMFHqR7sIeYw6tLVrQG6j4E5Y839toPglwl4tK7jnwOPpUoDjwC5e+H7R487+QF8dov78xLbwJDPzPklLZby80qu+xY2zYJ+L5nnSorNdFsAbP8VjmSaC+/4ufYp0ZASXS69bd1olj3VEzCHch9v875c5m08QFpqLFe9OZ8WyRHcfUljlmw/xOTftp9xmfq89otr/5dNB1z7367YS4nTyfRVZb1m523c79rOe6jbGT9bRETEX5W2UjTsWkRERHxJwUepvro8CMntITAM4pvBAyth61wIS4BPBpl5GveAmFRY8u7ZffZnN5dPy1wFE5qb+3HNzGcvmgh9xsH2X8zgI0BsQ7jwHnj7InPuyzvmweT+5rnE1ua7nGMaJ0TQOCECgHmPXEpUiJ2IYDv92yZz4EghM1Zn8PQVLflrxxRCAm3c+O9F/Lr5wCnuWjnHBx7/7JJXfuHCBCs/f7ma1nWiGXRBCnabla3789h24AgfLtjBxsxcQgMD6NsmibDAAO7r3oT5mw+w81A+gzvVA8DpNCh2GgQGWE/4LBERkaqmYdciIiLiDxR8lOrLaoXG3cuOo+tBh6Hm/s3fQa3GEJlstrxLCs25HOt3havfhtfanPzeiW3MYKKnDmwwf+BPPSaB2U+bP6Xmji/bP7QVbHb4/jHzXWJSITjKHALe/HKISDTz5R2A0FrmMHCLFXL2ElaQjmX5x9BxqFk3furPq1e/Mfg8LH/qkvH+sAtYuTubG95dyOBO9WifEs2GzFwmzttCWmosoYEBHC0qoVFCGB8t3HlG5Vm4zwr79vL5sr08++3aE+Qq4p15WwHo0SKRIf9eBEBSZDABNgvjpq9n16F8Zj90CXHhQfx38U4+WbSTR/o0Y8WuLG7rmkpEsB2ATZm5HDhSROdGtVx3P3CkkLjwc3sFdhER8R11fBQRERFfUvBRzk2pxw2ntVjgyjfMn1IjfzfniOz2kBncw2IOrd65CEKizUBfYKi52E1uOoTFwfppkL0blr4PBdlnr6zzjgs+Tr0RnMeGY2+a6Z5v288w8APY9gt8cHlZemRd7Dm76QGwDigpgAvvKv+cnYsgpkFZANNP/DnwCOYckx3rx7Di6V4EBVhdeR7r07xc3qAAG5N+3cb59WO4qXN9Pv19FyMua8zbc7e4DcE+W/q9XjbEe9jkJW7n0l6YQ1x4EAeOFJrn3zfPr9mbQ53oEEICbbw9dwsA393blZW7s1mbns1HC3cy/po2XN+pHrkFDr5ZsZeGceEYGFzUKO6sv4OIiNQMpatda9y1iIiI+JKCj1IzxTWBqye6p4XHQ3K78mnhxxa/6TTc3PZ4Bg5sNFfI3vKTOc/ju5ednXKVBh4rsvYryNkLP4x2T89xX4GaGY/Bmi/g5m/huwdhx3zoeAvMfgbqdoLBn5jB1D/LP2TOO5nQ4gxf4uwJtp96pfGnLm/JU5e3dB1f1b4OABc1iqOwuIR3f97KyzM3UjsqmNH9WlArLJDpq9O55aIGvPvzFqb+vqfC+7apE8WqPacfZC4NPB5v1trMcmmXv/Gr2/HjX6zikyW7qBsTwrSVZfONfjOyC23rRvPj+kye+GI1L/61LV0bx3HZK3PZcTCfiTd2KLf4j4iICODRVNgiIiIiZ5uCjyKny2Ix52W89t/mkG6LBZ7Ya/ZIbHgJ7Ft39oKRfzahkoHBXYvg+YSy49nPmNvdi+GlRtBxGBzYZA5Hv+lLOHoY3jjfPB6xBOKbnvz+xUXmsPTQWrBzIbQcYC6i42c9K4ICbNxzaWP+0jyRZkkR2I6t6n1RYzP4+vxVrUgp3EH3Sy+mRZ0YDMNgwZaDNEoIJzEymMLiEv6zYAdHCosZ3Kke/f7vFw7mFXmtvCt2ZbFiV5Zb2pX/nI/NaqHEaf4FOfS9xdzeNZUdB/MBuOujZbxyXTvyHSVc0iSeerVC+XTJLsZ+t5a7L21Ep9RYLmgQC8DPG/fTPCmChMjgk5Zj9Z5sftl0gFsuakBI4KkDwCIi4p9cC874tBQiIiJS0yn4KHImSoNtgWHQrI+5X6cD9H4BwhMhsjb8+hr0HQ95ByE4EqwBZi9Dewh8cYc5N6Q9FIKjIfvM5i+stKXvl+2Pq+t+btkHcHg71LsQLroXdv8OM0ZD8VHo/jQ06Qkzn4TF/yq75ss7ofVf4a+TKn7eHx/D0slw3WSIqlOW/uursOpzuPkb2LUY9v4Bba6DuMbww5PmcY9nIeWC8vfc+IM5FL3Hs+aK4QDFhWbv0cAwVzar1ULL2pEnrIqUcGicEA6YQ8BLA5NgBi9v79bQdfz53Rfx+o+buLVLKsF2K/lFJazak82TX64ud9/H+jTnHzPWn/C5p6M08Fjq379uczt+6LMVrv1HejfjpR/M+UZLt/3aJLkW3qkbE8JPD19KXmExQ/69iL6tk7jn0sbM3biPCxrE8sninbww3Sx3UbGTVrUj6dokztUL9VBeETsP5FJUUvb8AkdJpXqpioiIb/jZd4MiIiJSwyj4KOINnUeU7de/yNzGlgWxqNXI3N7zm/t1OXshcw3U6Wjuz3jcXCn7z27/ET68Copyz265ARb809yu/w5m/s393Md/PfF1q/8HV/0TbIFmADDg2AIqWbvg63vM/VdbmsHC1Z9D0z7w84tm+ncPwNqvzf154+GeRWXl+OpuGLkEsnaaC+1k74KivLJ7xjaE+ObmnJwL3zTTrnzDXLCnKA82zYKGl5pzeeYfMoO8pQvylDjMRXtO5NA2c07QULPnYIO4MCYMbO+WpW3daK7tUJegACsfLdrJU1+t5q0hHejdKonsow6iQuzkFxVzx8UNeXHGBtrWjaJbk3j6vf4Lh/KKuK1rKp8u2UVwoI39ueWHbJ+u0oDj8Y5f8Xv34aO0e3Ym+ceih2v25jBx3laOFJYf8v/q7I0ANE+KYOKNHck66mDEx8vYk3UUCGB+4SoiQwP5cMEOXvxrW3q3TCIiOAADeH3OJhrGh7mGwYuISNUztNy1iIiI+AEFH0X8SWRt8wfMgNct38HupeYK2FvmmMOnA0Kgbkd4YjdkroW3O2OEJ7E9uBV1r3wCe9Y2+OJ28x6pF8NlT8J7vaum/H9POlb2WtD3Rdi3Fhb+aW7N0pW+M1aWpZUGHku9lVa2f3ATPBt94mdOG1U+7Zt7zUDlnGfL0qLrmQHMjsPgitfAMLB9NICemZugV3ew293vkbMXXm9vvsujW93PHdlnBiWPBVhLe/3dlFaPm1KPQEwUWC083td9gZznBrR27c9/9DKsJXkEhUa55qz8bfMBJv68lbV7c3il1Va6bH2N/4t5gjc2xpz4/T2Qf3y3Ragw8Hi89Rm5XPry3HLpX60om5vy0f+t5FFWcvV5dbigQSz/N2cTAFe0rc3fvl5NSYnB+GvbsGV/HgeOFHJhw1rsPJjPmr3Z9Gmd5LbwkNNpYLWqm46IyJnSsGsRERHxBwo+ivi7uh3NbVIbiGsGiWWLq5DYEp7JptjhYOX06dRNbgf1zjdX+14/Dc67CQIC4d5lZo/ByDrmEOrNs8zrr/sAPrv57Jc5/yB8ftvZv+/pOD7wCGbgEcwh5wFBsHkO1oObCAV4McU8d/W/4JeXwWKD1teYafkHwek0e0uWFMN7vWDPUjOwe9NXUHTk2IrpwObZZu/QhpfB0K/cn+84Cuu+NRf0iW1EyNy/w8K34Y65kNwWctK5KHcOFw0ZYM7B+dq1ADyUO4KHLrqZ+S2eYl1GLu/+spXMnEJ6t0rkggax9GuTzEXjfyz3+vERQezPLSSYQgZGrCat10Be/GI+3a1/8FFJD4pwD7ZebF1BC8tOBth+5QnH7fxhNPGo2r/8Yw9f/lG2iE/DJ6a79lvViWTM12sAGNypHtNXpZN91OF2fbcmcSzYcpAeLRKJDAng09/NBZUWPdGdxOPmqnSUOJm5JpNuTeOICApwC14WFpcQFFDxMPCcAgdb9+fRrm5UhSuti4ici/TfOxEREfElBR9FqguLBZr3q1zeiCS44LjgX61GZUO9h3wGPz4HcU2hxZVledLugt7jYP6rMGesufJ3YS4c2gqpl8C2ee7PCAyHbqPMvNXNookVp395R9n+T38v2x97rOdhXFNzpXMw55scaw7HZuCH0Kw/LPm3ebz1JzPYmb27bNj9jNHuc20e/5wbpsJnt8CuhfD1iPJ5ln1Al1X/o0tKJ/rfMJ7FWw/Qv+hLApb/AMb1WC3NCTCKebH9fvpf8VfsYTEcLSrhiz92c+XuCUSsmgxbNnBpvQzCMn/njqZH+KHJMwQFWHnvy+nYKeHDwH+4Hvd+4Iu0L3wXgHYp0eUWwTleK8s2Xrf/kw9LerHM2YRVRsMT5l3y7bt0sMSxzGjKJ4srnt/0l00HAHCu+5ZYSzpwBWAh7YU5XNSoFr9tOVjhdRc3jWfijR0Y/K+FrNidzRuDz+PSZvG88eNm2qdE8868LfRsmcic9fv4Y2cW8RFBfHRbGs2SIlifkUOA1UJMaCBz1u2jb5skIoLtHMrJI2/Vd6Sc358iWyjvzd9G71ZJpMaFVVgGERF/o1HXIiIi4g8UfBSpaSwW6D6m7HjwFPjjI7j4EbN3X7eHoMuD5jmjBApyIKyWeewsgR3zIaGlOVdiWLwZoIxINnsDrpxq5qvf1ewxuH8dXPyoGajbtdA8F1kHzh8Gc8ebc0PGNjQDnAANulU8xyVAYIR35rg8HaWBxz/7dGj5tNfalO0/vqviwCPAxhnmgjyl9XMijjzY+hPJW9O46vj0H59jXXIzgg5tgPXA+ofhoQ2E7FnGkIxpsOojM9/67ygNmSVt+5Kbr3oOVk7l+qDnyj0q2pJHNLnMebwvETtm4cxcz7yIfoROv5dFzhb8YTRmrxFHHcsBngt4j1RrJs9aPwCge+FL7DASmWR/mXVGPcYXD6aRZS99rEt4xP4pAKkFH2FgBQziyeIG24986+zMDiOREqxcal3OvwJfBWCBsyUrjMbYKDlh4BHMlbw7j/mcwbYfyaQLL/6wnns/+cMtz4rd2QB0tq6h89E19Hstn16t6/D96gyCKKKQQABmr8vkhrR6dP5vS2ItDn7/YwC/BXSi1Z7PGPj97Vz/lwsY3KketaNDWLrjMAePFJIYGUxCZBAhdhtr9ubQsX4MBY4SokMDy5XVMAxKnIZr9XUREW/RsGsRERHxBwo+itR0zfqaP8crXZAFa1ngEcBqM4cbH6/HM2X7V79jLvBSu725mnfhEYhMBp4s/9yLHykbzvzpUHP+ykEfwcpPIaUTfHAlFGaX5R8+B3YuMBfkaTsIcva4B/3C4iFvf9mxxQbDvoflH8G67+DoobJzdTtBfFMz6FoVxqec/Hzp4jkeCjr0p0VmXml26otea33S08uD74TXyo578xLYoJut/Mrex5sT9AgH6/Wm1s6VXMJKhrYNJ3TtFLc8w2w/EM5RRtn/50p7kM8rvF+0JY/nbZMYYJvP/Y4RzHF2POGzJwW+zPnWjdwR8B2f5VzCFMtf2GYkl8v3SaDZq3Wnkcj/Vl9CZ+saPrSPZ3zx9Uwq6c/MtZmsXbeaX4PMIeHnH/iK8/kKbDCG/7Bh3lws8+dwVchLrMgKcd23TWwJo3mf+CMbCLbuYbTzAe6771H25xaydNVqmjQ0e4Xe9u9fSc5exthR9xEcVBacLCp2Ehhw7HcvJ91cJMl+7P4Zq+D9flCYQ8Z13xHYII0tn46mjWUrwUP+W5YPzK5OJQ5zyoWKbJ4Nm2ZDz7EV59mxAOKbuRZaOqkFb5o9fm/+FqLqmmklxWUr0FdHxUXu9XJkn7lQ1YnqU6Qa0KhrERER8aVq/NeBiPgdiwWa9io7Doo4ef7SIOfAD82AicUCaceGPj+yGSxWWPc11O9iDiWPPz6odn7ZbttBcM2/zP2Vn0KtxlCng3lcL81c/bow1xwqvnMBJLaG4EiK63ejcPpTBN40BXtyGyg+CrYg2PM7TO5fdv/E1pBZQdAtIhly08un13C1dv7g2v9z4BFgjP0/lb5XP+siBgXMBeBd+wQaFn5Me8tmNhp1ycecAzKRQ3we9Ax1LeaQ7VjLEe4MmMadAdN4q/hKppd04jn7ZH52tmFGSSfXvetZMgmiyBWMfMr+Ma2t2yk07Fx/7Jl/doVtIVfYzF6qXxfcxnO2IXxU0pMo8vg2/9iQ+WMf61etr3H7BButrdt4IOALPl18CY8W38nXgQ/RzrqVwxO/ZktAXf4dORL7+i+JJB97lxE8lhYMb5if30frf0bXDq258suurjIkfXY5fyl8mR+Djg3zX/u1Oby/MBcSW8FH15qf1zvmmZ9lawD7d2/mrSOXcPdlTUn4yJxPlJgGcOFdZnDtrc5QUgQNLzHnJq3TkZLb5pT1zty1GFZ/AV0fhIhEM80w4Icnjr1sK3gmG/Yuh/f7wsUPw0X3n7UgZHhBuvm7FlvPfE97qPlliLPE3JY6ethclMsebAZBc9Mh+ljw/+eXzHe7/hOIOsEq7Ie3w9td4Lwboe8/4MBm+GdHc+oJwwnWALjpy5NHcg7vAFvgsS9exF+8+eabvPTSS2RkZNCuXTveeOMNOnXqdML8WVlZPPnkk3zxxRccOnSI+vXr89prr9Gvnzn9yTPPPMOzz7rPLdysWTPWr1/v1fc4XVrtWkRERPyBgo8i4h/+/Md8aS+j1tee+JrHtsOG76HFFWVpbQdWnLc0EFo6ByNgtLqW2TtC6JfUFgLsZc9s0BXGHDIDG6VpjqPmPI6Za8w5IzuPhJZXmnl+e91cFbv2eeYQ89KAzL3LYNkHMP//3MvSuKe56M3676DO+WaACKDt9dDvRSjKN3tldrzZDHbkZsC6b2DpB5C718ybkgb5h8zVwM9hg44LAlotBtuDb3Adl9Q5n8L8XEIPb6jgStM9Ad9wT8A3AJxn3cz9AV+6zt0X8BX3BXzllv9q2/zTKt9T9o95yv7xCc//O/AV1/7AgHl84exGO6s5zUDM4ZXEsJJX90+ndP2f7xZs4cMFEQw9Fk+7b/vd3LbxYa4Mcr/vj0EPlx18eadrd21Cf1rum2MeTChbbT0eeBo4f8Hb/F66bs+Mxziy6lvC9/xadq9135rbPUtpMWYGD3WN587CyfDHsYDxiv+y+cbfSdr5DeG/PO9eqH80MHsgO/LNuWDnjDW/OMjZAxeOMH8/8vaZgbygcPOaNV+Zc6T2faninoUlxVh/+z+6r3sO1j1Wlt7wUnNF+8zV5sJZrQbAnmXw7mWQ2Ab++h682QkwzC8fYhvCj8fK+8vLcLk5rJ+9f5i/w+krzCDs4e3mIlKLJkJ0vbLf5ePnvN2/AdZ/a163eQ4c3mZ+UdLjWbMX+Y/PwZovoe+L7nPvis9MnTqVUaNGMXHiRNLS0njttdfo3bs3GzZsICEhoVz+oqIievbsSUJCAv/73/+oU6cOO3bsIDo62i1fq1atmD17tus4IEDNahEREZGKqJUkItVXSAy0v+HU+Txhtbn3qLKHmD0v45uVrYRdmq/rg2XHcc0gLMEMYEYmm0Nbuz9tBjQWvm3OjXndBxAYWnZN6fDzUsFRcMkjZcehsebK5m2ug3cuNssw5H9m76/M1eZK6EV5ML4exDc359AsKTSvHbHE7A22dDJ0ud/s3fmvSyt4X7tr1W1XgBPM3nGHt1euzq7+l1nODwdA/oHKXXMGbHt+J/TU2fzKlMDnT3r+cpv73J91LQd4OOCzSt+/5b5pJz3/e/Ddbsdugcc/mWF9gIYLM9wTC7Jp/O8TrIR+9LD5c7wdx4K53z/iluxseTXWsDhYYi5s5Fz2EdZGl5o9Dms1Nj/TAPNfw/ZT+XlJ2Tq3bP+zm2HJcfPFZq6CNy8oO//NvdCoe9nx7++ZPRNPtPBUqdLA45+9lVZx+ld3uR+X9r4Wn5swYQLDhw9n2LBhAEycOJFp06bx3nvv8fjjj5fL/95773Ho0CF+++037Hbzm4EGDRqUyxcQEEBSUpJXy362aLVrERER8SUFH0VEzqaAQGh7nXua1WYGFC8t/0eued5acfqf1Wpk9va02cvSarc3t8GR8NSBsqGoP/0dCnMgronZq7TecQGTix+Fn18093s9D2l3mz23SsvxTFRZ3rsXAAYUF5oLCs14HGfr61iZHUZb+w6sFisc3GzOr1k6lPWBVbBhOnx+rNfXiMWwZBIsfsdc0Oiie8EeBkcyyhbmsQXBFa9Bq6vhm/vM9wgIMoOmZ9v5t5oBqFLHL3p0hj4s7okTC4ucLXg78P9OfUEl9LQtPSv3OV0NrRmnzuQh69ov3Y+NYnMuys1mL7LRtf/NCz0TsfxYQeCxIidaqKrUljnux6cKPJ6p4Cizp6f4XFFREUuXLmX06NGuNKvVSo8ePViwYEGF13zzzTd07tyZESNG8PXXXxMfH88NN9zAY489hs1W9qXUpk2bqF27NsHBwXTu3Jlx48ZRr169E5alsLCQwsJC13FOTg4ADocDh8Nxpq9aIafTHHbtLCnx2jPORaV1pTo7Pao3z6jePKe684zqzTOqt/JOpy4UfBQRqU6ODzyWOxdQtu3x9InzXfIYNO5hBkcqGup6y3RY8V/o+VxZD83AMOh0J6SkURLblB0z59CqXz+s9grKExhqDpcvyjPny4xvZs6fd+FdEN2gLMgZXQ/u/Nkcsh6eVFb+a98tu1ft8+Db+6HjMOj3srnieeYaOLTNDGYWHjGHvYLZ87L1NfD9oxAaZy5c1LgHFGRDQZa5ja4PQZHmUP2pN0GLK81hue90g31roe9LGCs+wVL3AoisDa2uJisomfumLOfvxhuk7PqGYmsg/4p/guE9O2D/6EpXUY9eN4X+9f/C+/O3E3Aon6INbxJIcbnq+Q/9uInpbml7iGdW8XncEjDzhP9sDsOG3VLiOn7JfhfZ+YU8bz/BSuqAExtHjQDCLIUnzOOPxu29HT7wdSnOQFi8r0sgxxw4cICSkhISExPd0hMTE084P+PWrVv58ccfGTJkCNOnT2fz5s3cc889OBwOnn7a/G9rWloakydPplmzZqSnp/Pss8/SrVs3Vq9eTURExfMdjxs3rtw8kQAzZ84kNNQ7/bgPZ9kACytWrIDdy73yjHPZrFmzfF2Eakn15hnVm+dUd55RvXlG9VYmPz+/0nktRg2biTonJ4eoqCiys7OJjIz02nMcDgfTp0+nX79+riE7cmqqN8+o3jyjevNMldabYcDeZZDQylxEpCLZe8wh+IFn8Md7QQ7k7IWE5ifOU3jEnL+z/Q0Qm3rsumxzYZPQ2HLzlhbt34p98VtY9q0FeyjFrf/Kp+sMruhxMRFvtjSL3nMCUXG1ISYVI64JRz4cRMT28g2akmaX82Lkk7zzyzZiyeGt7gE0ufAK7vp4GXUi7VxbPI1lgR2JiQjHvuD/GGSby4yogfR98B2+Xr6X37YcoCjnAK/tvKbcvRsUfMxXgWNob90CwCJnc8Y5bqC9dTO32r6nntVcRb7QCCDIYgZTryx8jr62xdwd8C3POm4ihELiLdkMCzAXG/q25ELmO1uzwtmI74NGl3vm6bil6FG2Gsk8FfARQRTxQvEQZgSdoBcxsMeoxdTiyygigMft5oJHW5zJ/GK/iFtKylZVv6PoQX5xtiE1EqYX3VruPt/GDafpBT1p9v0J5pE9iYLAWPbftYaUWO9NDFBV7Znqbu/evdSpU4fffvuNzp07u9IfffRR5s2bx6JFi8pd07RpUwoKCti2bZurp+OECRN46aWXSE+veJGxrKws6tevz4QJE7jttorn+qyo52NKSgoHDhzw2r/hde8sZPnuHF4f2Jq+bWp75RnnIofDwaxZs+jZs6faB6dB9eYZ1ZvnVHeeUb15RvVWXk5ODnFxcZVqj6rno4iI+C+LBep0PHmeE61cfDqCI82fkwkKh788+afroirOCwTGN4T+L7uODYeDsB3TCY5OgMuehKOHibrwZlePTwsQMeQj2DjDXHX63e5waAs07YNt8MeMBq5oX4d6tUKJDDYbPJ/dVbqA0gV0AwqLS3gwK5Kj9V/l1q5mgHTAeXUYcN6xOto1C4qOcHjZV8Ss+YDc8FRWPt6byPyW5Ex/msNNB1Gv8cVc/Hs6nRvFEZ/yGsPe+IysAxnUb3Uhgev+x5ySDhwkipXFDZlYfAXZmIvHvHxdO/r871sCcbDSaOR67xuLRvNR4Dgmhd3Ovla3sfCXWXwdNMZ1fqmzCfcVjSTYUsT3gY8TeFzvToBtRhI7jUSGOx4qS3MmkmrNBOC+opG8HvhPdhtx3Fr0CBuNFFe+75yd2WvUwokVW1EJf1gTWeJszl7iXHnW5sDH/RZw3Y8XE4g5dOQlx0De3H0Z9vQSNh1rW84s6UivY0Pg/13cl0G2uURYjrru833JBfS1LQFgztHGHN12yKvBR6mcuLg4bDYbmZmZbumZmZknnK8xOTkZu93uNsS6RYsWZGRkUFRURGBg+R7j0dHRNG3alM2bN5+wLEFBQQQFBZVLt9vtXvsjpnSuxwBbgP5Q8oA3/23OZao3z6jePKe684zqzTOqtzKnUw8KPoqIiFS1Sx6tON0ebK7cDHDLd7DxB2h3vet06zonDnYCBAXYeGvISYK1KZ0AiGn0F7jsPiLCEyDYDsENibzxP5SGX0f1KgvEvnP/QEqcBusycrhm9WUA/PLoZdisFlbuzuKuj5YBcHnbZHq3up21e3OYvS6Td38xh8Nffe2N0OExbjsWBHkgp5B/re7PHQHTMCLr8kbka+zZnA0GPNB0Fi9c3YbJU6YSuHUmuUYoO4wkHmpTzPcHYlibngvA4KK/0dO2lL1GLbpfdQuNvu5CibP8QI7dRtnw5xJsfO3sWmG1PDl9G+9ZXuCegG94s/gqthpmDzFHicH/Wa6mpWUndzseoMRRFowaXzyYGI7QzrqF2c4ONLfscgUfn3TcxvvxYSf+d5AqExgYSMeOHZkzZw4DBgwAwOl0MmfOHEaOHFnhNV26dOG///0vTqcT67FpIjZu3EhycnKFgUeAI0eOsGXLFm666SavvIenatTwJhEREfFbCj6KiIj4o8jacP4w790/rnGlsgUGmMGX9nWjubZDXerFhrp69B3OL3LlC7bbCLbbSGtYi7SGtbiqfR22HsjjynbuQz3TGtbi6eUDyTRieOqWh5gUncqRwmKy8ouoFxuKxWLhgVtvosBxA/tzCxkVYWf69Ol8dk0arZ41F6TJoBb/KenF9vH9AbghzVzkY9XubKJC7CzadpD2KdHsyTrK8A9/x1FikBIbwj+uaUur2lF8vWIPY75e41auLUYdHnK4rwYO8GrxdeXSAIoJYD/RzHaawd71Rj3OL3ibw4RTgo2G8eGVql/xvlGjRnHzzTdz/vnn06lTJ1577TXy8vJcq18PHTqUOnXqMG7cOADuvvtu/vnPf3L//fdz7733smnTJl544QXuu+8+1z0ffvhhrrjiCurXr8/evXt5+umnsdlsDB482CfveCKlkytpsWsRERHxJQUfRURE5JSsVguvDGznltaqdhSP921OclT5+Thb14mqsKfmdR3rApCW2gNiw7EBUSF2okLch20E222kxIa6VtELDLByf/cm/Lh+HweOFDLyL+WDp23qms+rV8sMjjZJjGDT3/uVyze0cwMCbVZW7M7m+9XpZOW7r9T31pAO3PPxshNVhUtggJVmiRFEhgQwf/NBDmA+v0vjWuXeR3xn0KBB7N+/nzFjxpCRkUH79u2ZMWOGaxGanTt3uno4AqSkpPDDDz/w4IMP0rZtW+rUqcP999/PY4895sqze/duBg8ezMGDB4mPj6dr164sXLiQ+Hj/XGxIsUcRERHxJQUfRURExGN3XdLo1JmOE2CzMrhTPY+e9WDPpjzYs6lH1/7Z9Z3qcX0neOHq1qzPyKVJQjjp2QXsP1JIh3oxfHpnZwa+swCAVrUjWbM3B4CNz/fliS9X0bVxHFe1r+2aU2/N3mzW7M2hY/0YGqnXo98ZOXLkCYdZz507t1xa586dWbhw4QnvN2XKlLNVNK8yNPBaRERE/ICCjyIiIlJjWSwWWiSbc1ymHDekvFNqrGtY9+G8Iv729WoGnp9CYICVl69rV+4+rWpH0ar2yefkFKlqLZIiOJKdTXSoeuKKiIiI7yj4KCIiInISMWGBvHlDB18XQ+S0PX9VK6ZP30HH+jG+LoqIiIjUYNZTZxERERERERERERE5fQo+ioiIiIiIiIiIiFco+CgiIiIiIiIiIiJeoeCjiIiIiIiIiIiIeIWCjyIiIiIiIiIiIuIVCj6KiIiIiIiIiIiIVyj4KCIiIiIiIiIiIl6h4KOIiIiIiIiIiIh4hYKPIiIiIiIiIiIi4hUKPoqIiIiIiIiIiIhXKPgoIiIiIiIiIiIiXqHgo4iIiIiIiIiIiHiFgo8iIiIiIiIiIiLiFQo+ioiIiIiIiIiIiFco+CgiIiIiIiIiIiJeoeCjiIiIiIiIiIiIeIWCjyIiIiIiIiIiIuIVCj6KiIiIiIiIiIiIVwT4ugBVzTAMAHJycrz6HIfDQX5+Pjk5Odjtdq8+61yievOM6s0zqjfPqN48o3rzjOqtYqXtmNJ2jVQ/VdEm1e+PZ1RvnlG9eUb15jnVnWdUb55RvZV3Ou3RGhd8zM3NBSAlJcXHJRERERE5M7m5uURFRfm6GOIBtUlFRETkXFCZ9qjFqGFfmTudTvbu3UtERAQWi8Vrz8nJySElJYVdu3YRGRnpteeca1RvnlG9eUb15hnVm2dUb55RvVXMMAxyc3OpXbs2Vqtm0amOqqJNqt8fz6jePKN684zqzXOqO8+o3jyjeivvdNqjNa7no9VqpW7dulX2vMjISH0wPaB684zqzTOqN8+o3jyjevOM6q089Xis3qqyTarfH8+o3jyjevOM6s1zqjvPqN48o3pzV9n2qL4qFxEREREREREREa9Q8FFERERERERERES8QsFHLwkKCuLpp58mKCjI10WpVlRvnlG9eUb15hnVm2dUb55RvYl4Tr8/nlG9eUb15hnVm+dUd55RvXlG9XZmatyCMyIiIiIiIiIiIlI11PNRREREREREREREvELBRxEREREREREREfEKBR9FRERERERERETEKxR8FBEREREREREREa9Q8NEL3nzzTRo0aEBwcDBpaWksXrzY10XyqXHjxnHBBRcQERFBQkICAwYMYMOGDW55Lr30UiwWi9vPXXfd5ZZn586d9O/fn9DQUBISEnjkkUcoLi6uylepUs8880y5OmnevLnrfEFBASNGjKBWrVqEh4dz7bXXkpmZ6XaPmlZnAA0aNChXbxaLhREjRgD6rJX6+eefueKKK6hduzYWi4WvvvrK7bxhGIwZM4bk5GRCQkLo0aMHmzZtcstz6NAhhgwZQmRkJNHR0dx2220cOXLELc/KlSvp1q0bwcHBpKSk8OKLL3r71bzqZPXmcDh47LHHaNOmDWFhYdSuXZuhQ4eyd+9et3tU9BkdP368W56aVG8At9xyS7k66dOnj1uemvh5EzlTapOWUXvUM2qPekbt0cpTm9QzapN6Rm1S31Hw8SybOnUqo0aN4umnn2bZsmW0a9eO3r17s2/fPl8XzWfmzZvHiBEjWLhwIbNmzcLhcNCrVy/y8vLc8g0fPpz09HTXz/G/oCUlJfTv35+ioiJ+++03PvjgAyZPnsyYMWOq+nWqVKtWrdzq5Ndff3Wde/DBB/n222/57LPPmDdvHnv37uWaa65xna+pdbZkyRK3Ops1axYA1113nSuPPmuQl5dHu3btePPNNys8/+KLL/L6668zceJEFi1aRFhYGL1796agoMCVZ8iQIaxZs4ZZs2bx3Xff8fPPP3PHHXe4zufk5NCrVy/q16/P0qVLeemll3jmmWf417/+5fX385aT1Vt+fj7Lli3jqaeeYtmyZXzxxRds2LCBK6+8slzesWPHun0G7733Xte5mlZvpfr06eNWJ5988onb+Zr4eRM5E2qTulN71HNqj54+tUcrT21Sz6hN6hm1SX3IkLOqU6dOxogRI1zHJSUlRu3atY1x48b5sFT+Zd++fQZgzJs3z5V2ySWXGPfff/8Jr5k+fbphtVqNjIwMV9rbb79tREZGGoWFhd4srs88/fTTRrt27So8l5WVZdjtduOzzz5zpa1bt84AjAULFhiGUTPrrCL333+/0ahRI8PpdBqGoc9aRQDjyy+/dB07nU4jKSnJeOmll1xpWVlZRlBQkPHJJ58YhmEYa9euNQBjyZIlrjzff/+9YbFYjD179hiGYRhvvfWWERMT41Zvjz32mNGsWTMvv1HV+HO9VWTx4sUGYOzYscOVVr9+fePVV1894TU1sd5uvvlm46qrrjrhNfq8iZw+tUlPTu3RylF79OxQe7Ry1Cb1jNqknlGbtGqp5+NZVFRUxNKlS+nRo4crzWq10qNHDxYsWODDkvmX7OxsAGJjY93SP/74Y+Li4mjdujWjR48mPz/fdW7BggW0adOGxMREV1rv3r3JyclhzZo1VVNwH9i0aRO1a9emYcOGDBkyhJ07dwKwdOlSHA6H22etefPm1KtXz/VZq6l1dryioiI++ugjbr31ViwWiytdn7WT27ZtGxkZGW6fr6ioKNLS0tw+X9HR0Zx//vmuPD169MBqtbJo0SJXnosvvpjAwEBXnt69e7NhwwYOHz5cRW/jW9nZ2VgsFqKjo93Sx48fT61atTjvvPN46aWX3IZR1dR6mzt3LgkJCTRr1oy7776bgwcPus7p8yZyetQmPTW1RytP7dEzo/ao59QmPXvUJq08tUm9I8DXBTiXHDhwgJKSErf/SQAkJiayfv16H5XKvzidTh544AG6dOlC69atXek33HAD9evXp3bt2qxcuZLHHnuMDRs28MUXXwCQkZFRYb2WnjsXpaWlMXnyZJo1a0Z6ejrPPvss3bp1Y/Xq1WRkZBAYGFjufx6JiYmu+qiJdfZnX331FVlZWdxyyy2uNH3WTq30PSuqh+M/XwkJCW7nAwICiI2NdcuTmppa7h6l52JiYrxSfn9RUFDAY489xuDBg4mMjHSl33fffXTo0IHY2Fh+++03Ro8eTXp6OhMmTABqZr316dOHa665htTUVLZs2cITTzxB3759WbBgATabTZ83kdOkNunJqT1aeWqPnjm1Rz2nNunZoTZp5alN6j0KPkqVGjFiBKtXr3abKwZwmyOhTZs2JCcn0717d7Zs2UKjRo2quph+oW/fvq79tm3bkpaWRv369fn0008JCQnxYcmqj0mTJtG3b19q167tStNnTaqCw+Fg4MCBGIbB22+/7XZu1KhRrv22bdsSGBjInXfeybhx4wgKCqrqovqF66+/3rXfpk0b2rZtS6NGjZg7dy7du3f3YclE5Fyk9mjlqT165tQeFV9Sm/T0qE3qPRp2fRbFxcVhs9nKrfCWmZlJUlKSj0rlP0aOHMl3333HTz/9RN26dU+aNy0tDYDNmzcDkJSUVGG9lp6rCaKjo2natCmbN28mKSmJoqIisrKy3PIc/1mr6XW2Y8cOZs+eze23337SfPqslVf6nif7b1lSUlK5RQuKi4s5dOhQjf8MljbyduzYwaxZs9y+Ya5IWloaxcXFbN++Hai59Xa8hg0bEhcX5/Z7qc+bSOWpTXpiao+eGbVHT4/ao2dGbdIzozbpmVOb9OxR8PEsCgwMpGPHjsyZM8eV5nQ6mTNnDp07d/ZhyXzLMAxGjhzJl19+yY8//liuC3JFli9fDkBycjIAnTt3ZtWqVW6/6KX/AW3ZsqVXyu1vjhw5wpYtW0hOTqZjx47Y7Xa3z9qGDRvYuXOn67NW0+vs/fffJyEhgf79+580nz5r5aWmppKUlOT2+crJyWHRokVun6+srCyWLl3qyvPjjz/idDpdDejOnTvz888/43A4XHlmzZpFs2bNztnhBqWNvE2bNjF79mxq1ap1ymuWL1+O1Wp1DeGoifX2Z7t37+bgwYNuv5f6vIlUntqk5ak9enaoPXp61B49M2qTek5t0rNDbdKzyLfr3Zx7pkyZYgQFBRmTJ0821q5da9xxxx1GdHS020plNc3dd99tREVFGXPnzjXS09NdP/n5+YZhGMbmzZuNsWPHGr///ruxbds24+uvvzYaNmxoXHzxxa57FBcXG61btzZ69eplLF++3JgxY4YRHx9vjB492lev5XUPPfSQMXfuXGPbtm3G/PnzjR49ehhxcXHGvn37DMMwjLvuusuoV6+e8eOPPxq///670blzZ6Nz586u62tinZUqKSkx6tWrZzz22GNu6fqslcnNzTX++OMP448//jAAY8KECcYff/zhWgFv/PjxRnR0tPH1118bK1euNK666iojNTXVOHr0qOseffr0Mc477zxj0aJFxq+//mo0adLEGDx4sOt8VlaWkZiYaNx0003G6tWrjSlTphihoaHGO++8U+Xve7acrN6KioqMK6+80qhbt66xfPlyt//ela5299tvvxmvvvqqsXz5cmPLli3GRx99ZMTHxxtDhw51PaOm1Vtubq7x8MMPGwsWLDC2bdtmzJ492+jQoYPRpEkTo6CgwHWPmvh5EzkTapO6U3vUM2qPek7t0cpRm9QzapN6Rm1S31Hw0QveeOMNo169ekZgYKDRqVMnY+HChb4ukk8BFf68//77hmEYxs6dO42LL77YiI2NNYKCgozGjRsbjzzyiJGdne12n+3btxt9+/Y1QkJCjLi4OOOhhx4yHA6HD96oagwaNMhITk42AgMDjTp16hiDBg0yNm/e7Dp/9OhR45577jFiYmKM0NBQ4+qrrzbS09Pd7lHT6qzUDz/8YADGhg0b3NL1WSvz008/Vfh7efPNNxuGYRhOp9N46qmnjMTERCMoKMjo3r17ufo8ePCgMXjwYCM8PNyIjIw0hg0bZuTm5rrlWbFihdG1a1cjKCjIqFOnjjF+/PiqekWvOFm9bdu27YT/vfvpp58MwzCMpUuXGmlpaUZUVJQRHBxstGjRwnjhhRfcGjSGUbPqLT8/3+jVq5cRHx9v2O12o379+sbw4cPLBUhq4udN5EypTVpG7VHPqD3qObVHK0dtUs+oTeoZtUl9x2IYhnE2elCKiIiIiIiIiIiIHE9zPoqIiIiIiIiIiIhXKPgoIiIiIiIiIiIiXqHgo4iIiIiIiIiIiHiFgo8iIiIiIiIiIiLiFQo+ioiIiIiIiIiIiFco+CgiIiIiIiIiIiJeoeCjiIiIiIiIiIiIeIWCjyIiIiIiIiIiIuIVCj6KiPiJuXPnYrFYyMrK8nVRRERERKQGUntURLxBwUcRERERERERERHxCgUfRURERERERERExCsUfBQROcbpdDJu3DhSU1MJCQmhXbt2/O9//wPKhqBMmzaNtm3bEhwczIUXXsjq1avd7vH555/TqlUrgoKCaNCgAa+88orb+cLCQh577DFSUlIICgqicePGTJo0yS3P0qVLOf/88wkNDeWiiy5iw4YN3n1xEREREfELao+KyLlIwUcRkWPGjRvHhx9+yMSJE1mzZg0PPvggN954I/PmzXPleeSRR3jllVdYsmQJ8fHxXHHFFTgcDsBspA0cOJDrr7+eVatW8cwzz/DUU08xefJk1/VDhw7lk08+4fXXX2fdunW88847hIeHu5XjySef5JVXXuH3338nICCAW2+9tUreX0RERER8S+1RETkXWQzDMHxdCBERXyssLCQ2NpbZs2fTuXNnV/rtt99Ofn4+d9xxB5dddhlTpkxh0KBBABw6dIi6desyefJkBg4cyJAhQ9i/fz8zZ850Xf/oo48ybdo01qxZw8aNG2nWrBmzZs2iR48e5cowd+5cLrvsMmbPnk337t0BmD59Ov379+fo0aMEBwd7uRZERERExFfUHhWRc5V6PoqIAJs3byY/P5+ePXsSHh7u+vnwww/ZsmWLK9/xDcHY2FiaNWvGunXrAFi3bh1dunRxu2+XLl3YtGkTJSUlLF++HJvNxiWXXHLSsrRt29a1n5ycDMC+ffvO+B1FRERExH+pPSoi56oAXxdARMQfHDlyBIBp06ZRp04dt3NBQUFuDT5PhYSEVCqf3W537VssFsCc/0dEREREzl1qj4rIuUo9H0VEgJYtWxIUFMTOnTtp3Lix209KSoor38KFC137hw8fZuPGjbRo0QKAFi1aMH/+fLf7zp8/n6ZNm2Kz2WjTpg1Op9Ntzh4REREREVB7VETOXer5KCICRERE8PDDD/Pggw/idDrp2rUr2dnZzJ8/n8jISOrXrw/A2LFjqVWrFomJiTz55JPExcUxYMAAAB566CEuuOACnnvuOQYNGsSCBQv45z//yVtvvQVAgwYNuPnmm7n11lt5/fXXadeuHTt27GDfvn0MHDjQV68uIiIiIn5A7VEROVcp+Cgicsxzzz1HfHw848aNY+vWrURHR9OhQweeeOIJ1zCT8ePHc//997Np0ybat2/Pt99+S2BgIAAdOnTg008/ZcyYMTz33HMkJyczduxYbrnlFtcz3n77bZ544gnuueceDh48SL169XjiiSd88boiIiIi4mfUHhWRc5FWuxYRqYTSlf8OHz5MdHS0r4sjIiIiIjWM2qMiUl1pzkcRERERERERERHxCgUfRURERERERERExCs07FpERERERERERES8Qj0fRURERERERERExCsUfBQRERERERERERGvUPBRREREREREREREvELBRxEREREREREREfEKBR9FRERERERERETEKxR8FBEREREREREREa9Q8FFERERERERERES8QsFHERERERERERER8Yr/B9gYmHikWT9vAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_loss_accuracy_evolution(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 1s 2ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred_nn = model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_nn.argmax(axis=1), normalize=None)\n",
    "cmd = ConfusionMatrixDisplay(cm, display_labels=['good', 'standard', 'poor'])\n",
    "cmd.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        good       0.88      0.96      0.92      8003\n",
      "    standard       0.90      0.73      0.81      8004\n",
      "        poor       0.87      0.95      0.90      8004\n",
      "\n",
      "    accuracy                           0.88     24011\n",
      "   macro avg       0.88      0.88      0.88     24011\n",
      "weighted avg       0.88      0.88      0.88     24011\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_nn.argmax(axis=1), target_names=['good', 'standard', 'poor']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Guardado de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset ML\n",
    "X_res.to_csv(path_output + 'X_train.csv', index=False)\n",
    "y_res.to_csv(path_output + 'y_train.csv', index=False)\n",
    "\n",
    "# # dataset NN, prueba adicional\n",
    "# X_res.to_csv(path_output + 'X_train_nn.csv', index=False)\n",
    "# y_res.to_csv(path_output + 'y_train_nn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # checkeo de orden de variables previo almacenamiento\n",
    "# ordinal.inverse_transform([[0.0], [1.0], [2.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = dict(zip(credit_score_order, [0.0, 1.0, 2.0]))\n",
    " \n",
    "# Serializing json\n",
    "json_object = json.dumps(dictionary, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open(f\"{path_output}true_label.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # @title Convert ipynb to HTML in Colab\n",
    "# # Upload ipynb\n",
    "# from google.colab import files\n",
    "# f = files.upload()\n",
    "\n",
    "# # Convert ipynb to html\n",
    "# import subprocess\n",
    "# file0 = list(f.keys())[0]\n",
    "# _ = subprocess.run([\"pip\", \"install\", \"nbconvert\"])\n",
    "# _ = subprocess.run([\"jupyter\", \"nbconvert\", file0, \"--to\", \"html\"])\n",
    "\n",
    "# # download the html\n",
    "# files.download(file0[:-5]+\"html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
